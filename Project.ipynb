{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_abstract_from_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    abstract = ''\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        if 'abstract' in text.lower():\n",
    "            abstract_start = text.lower().index('abstract')\n",
    "            abstract = text[abstract_start:]\n",
    "            \n",
    "            # Find the next section or delimiter\n",
    "            next_section_index = text.lower().find('introduction', abstract_start)\n",
    "            if next_section_index == -1:\n",
    "                next_section_index = text.lower().find('keywords', abstract_start)\n",
    "            if next_section_index == -1:\n",
    "                next_section_index = text.lower().find('Zusammenfassung', abstract_start)\n",
    "            if next_section_index == -1:\n",
    "                next_section_index = len(text)\n",
    "                \n",
    "            abstract = abstract[:next_section_index]\n",
    "            break\n",
    "\n",
    "    return abstract\n",
    "\n",
    "def extract_abstracts_from_folder(folder_path):\n",
    "    abstracts = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.lower().endswith('.pdf'):\n",
    "            abstract = extract_abstract_from_pdf(file_path)\n",
    "            abstracts[filename] = abstract\n",
    "\n",
    "    return abstracts\n",
    "\n",
    "# Provide the path to the folder containing the PDF files\n",
    "pdf_folder_path = 'papers'\n",
    "\n",
    "# Extract abstracts from PDFs in the folder\n",
    "abstracts = extract_abstracts_from_folder(pdf_folder_path)\n",
    "\n",
    "# Print the abstracts\n",
    "# for filename, abstract in abstracts.items():\n",
    "#     print(f'Filename: {filename}')\n",
    "#     print(f'Abstract: {abstract}')\n",
    "#     print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x75c6fd for key /Lang\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start scanning test\\20210806 DJ Daniel Jacob DISS.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2 as pdf\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    reader = pdf.PdfFileReader(file_path,strict=False)\n",
    "    fulltext = []\n",
    "    print(f\"Start scanning {file_path} \")\n",
    "    for page_num in range(reader.getNumPages()):\n",
    "        page = reader.getPage(page_num)\n",
    "        text = page.extractText()\n",
    "        fulltext.append(text)\n",
    "\n",
    "    return fulltext\n",
    "\n",
    "def extract_text_from_folder(folder_path):\n",
    "    abstracts = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.lower().endswith('.pdf'):\n",
    "            fulltext = extract_text_from_pdf(file_path)\n",
    "            abstracts[filename] = fulltext\n",
    "\n",
    "    return abstracts\n",
    "\n",
    "pdf_folder_path = 'test'\n",
    "#extract_text_from_pdf('20170120 SN Sergey Nasekin DISS.pdf')\n",
    "\n",
    "\n",
    "extract_text_from_folder(pdf_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D i m e n s i o n F l e x i b l e a n d Ad a p t i ve\n",
      "S t a t i s t i c a l L e a r n i n g\n",
      "D I S S E RTAT I O N\n",
      "zur Erlangung des akademischen Grades\n",
      "doctor rerum politicarum\n",
      "(Doktor der Wirtschaftswissenschaft)\n",
      "eingereicht an der\n",
      "Wirtschaftswissenschaftlichen Fakultät\n",
      "der Humboldt-Universität zu Berlin\n",
      "von\n",
      "Kainat Khowaja\n",
      "geboren am 19.09.1994 in Thatta\n",
      "Präsidentin der Humboldt-Universität zu Berlin (kommissarisch):\n",
      "Prof. Dr. Peter Frensch\n",
      "Dekan der Wirtschaftswissenschaftlichen Fakultät:\n",
      "Prof. Dr. Daniel Klapper\n",
      "Gutachter: 1. Prof. Dr. Wolfgang Karl Härdle, Ph.D.\n",
      "2. Prof. Dr. Weining Wang, Ph.D.\n",
      "Tag des Kolloquiums:2Acknowledgments\n",
      "Before I conclude this important chapter of my life, I would like to appreciate the\n",
      "support of many individuals who have contributed in various ways to make this\n",
      "achievement possible. First and foremost, I would like to express my heartfelt gratitude\n",
      "to my first supervisor Prof. Dr. Wolfgang Karl Härdle, who guided me throughout\n",
      "the course of last three years and sustained a research environment around me that\n",
      "enabled my scientific growth beyond expectations. I would also like to thank my second\n",
      "advisor, Professor Weining Wang, for her meaningful interactions at key moments while\n",
      "allowing me to work independently the majority of the time.\n",
      "Several other professors contributed expertise to advance my research, for which I\n",
      "am highly grateful. Noteworthy to mention are Prof. Dr. Sergej Sizov, Prof. Cathy\n",
      "Yi-Hsuan Chen, Prof. Chen Huang, Prof. Erwan Scornet, and Prof. Meng-Jou Lu.\n",
      "I would also like to thank my colleagues at IRTG for their friendship and valuable\n",
      "suggestions during weekly meetings and constant research input for the whole duration\n",
      "of my PhD. An honorary mention to Dr. Raphael Reule for taking care of all the\n",
      "administrative matters.\n",
      "Most importantly, I am grateful for my family’s unconditional and endless support,\n",
      "without which I wouldn’t be where I stand today. I am also indebted to my friends in\n",
      "Germany and abroad; each one of them have contributed in their own way to make\n",
      "this possible.\n",
      "Finally, I gratefully acknowledge the financial support from the Deutsche Forschungsge-\n",
      "meinschaft via IRTG 1792 “High Dimensional Nonstationary Time Series”, Humboldt-\n",
      "Universität zu Berlin.\n",
      "Signing off\n",
      "K2\n",
      "iiiAbstract\n",
      "As an interdisciplinary research, this thesis couples statistical learning with current\n",
      "advanced methods to deal with high dimensionality and nonstationarity. Chapter 2\n",
      "provides tools to make statistical inference (uniformly over covariate space) on the\n",
      "parameter functions θ(x)from Generalized Random Forests identified as the solution\n",
      "of the local moment condition. This is done by either highdimensional Gaussian\n",
      "approximation theorem or via multiplier bootstrap. The theoretical aspects of both of\n",
      "these approaches are discussed in detail alongside extensive simulations and real life\n",
      "applications. In Chapter 3, we extend the local parametric approach to time varying\n",
      "Poisson processes, providing a tool to find intervals of homogeneity within the time\n",
      "series of count data in a nonstationary setting. The methodology involves recursive\n",
      "likelihood ratio tests and has a maxima in test statistic with unknown distribution. To\n",
      "approximate it and find the critical value, we use multiplier bootstrap and demonstrate\n",
      "the utility of this algorithm on German M&A data. Chapter 4 is concerned with\n",
      "creating low dimensional approximation of high dimensional data from dynamical\n",
      "systems. Using various resampling methods, Principle Component Analysis, and\n",
      "interpolation techniques, we construct reduced dimensional surrogate models that\n",
      "provide faster responses as compared to the original high fidelity models. In Chapter 5,\n",
      "we aim to link the distributional characteristics of cryptocurrencies to their underlying\n",
      "mechanism. We use characteristic based spectral clustering to cluster cryptos with\n",
      "similar behaviour in terms of price, block time, and block size, and scrutinize these\n",
      "clusters to find common mechanisms between various crypto clusters.\n",
      "Keywords: nonparametric statistics, multiplier bootstrap, random forests, statistical\n",
      "learning, local parametric approach, machine learning, high dimensionality, nonstation-\n",
      "arity\n",
      "iiiivZusammenfassung\n",
      "Als interdisziplinäre Forschung verbindet diese Arbeit statistisches Lernen mit aktuellen\n",
      "fortschrittlichen Methoden, um mit hochdimensionalität und Nichtstationarität umzuge-\n",
      "hen. Kapitel 2 stellt Werkzeuge zur Verfügung, um statistische Schlüsse (einheitlich\n",
      "über x∈ X) auf die Parameterfunktionen θ(x)von Generalized Random Forests zu\n",
      "ziehen, die als Lösung der lokalen Momentenbedingung identifiziert wurden. Dies\n",
      "geschieht entweder durch die hochdimensionale Gaußsche Approximationstheorie oder\n",
      "durch Multiplier-Bootstrap. Die theoretischen Aspekte dieser beiden Ansätze werden\n",
      "neben umfangreichen Simulationen und realen Anwendungen im Detail diskutiert.\n",
      "In Kapitel 3 wird der lokal parametrische Ansatz auf zeitvariable Poisson-Prozesse\n",
      "ausgeweitet, um ein Instrument zur Ermittlung von Homogenitätsintervallen innerhalb\n",
      "der Zeitreihen von Zähldaten in einem nichtstationären Umfeld bereitzustellen. Die\n",
      "Methodik beinhaltet rekursive Likelihood-Ratio-Tests und hat ein Maximum in der\n",
      "Teststatistik mit unbekannter Verteilung. Um sie zu approximieren und den kritischen\n",
      "Wert zu finden, verwenden wir den Multiplier-Bootstrap und demonstrieren den Nutzen\n",
      "dieses Algorithmus für deutsche M&A Daten. Kapitel 4 befasst sich mit der Erstellung\n",
      "einer niedrigdimensionalen Approximation von hochdimensionalen Daten aus dynamis-\n",
      "chen Systemen. Mithilfe der Resampling-Methoden, der Hauptkomponentenanalyse\n",
      "und Interpolationstechniken konstruieren wir reduzierte dimensionale Ersatzmodelle,\n",
      "die im Vergleich zu den ursprünglichen hochauflösenden Modellen schnellere Ausgaben\n",
      "liefern. In Kapitel 5 versuchen wir, die Verteilungsmerkmale von Kryptowährungen\n",
      "mit den von ihnen zugrunde liegenden Mechanismen zu verknüpfen. Wir verwenden\n",
      "charakteristikbasiertes spektrales Clustering, um Kryptowährungen mit ähnlichem\n",
      "Verhalten in Bezug auf Preis, Blockzeit und Blockgröße zu clustern, und untersuchen\n",
      "diese Cluster, um gemeinsame Mechanismen zwischen verschiedenen Krypto-Clustern\n",
      "zu finden.\n",
      "Schlagworte: nichtparametrische Statistik, Multiplier-Bootstrap, Random Forests,\n",
      "statistisches Lernen, lokaler parametrischer Ansatz, Machine Learning, Hochdimension-\n",
      "alität, Nichtstationarität\n",
      "vviContents\n",
      "1 Introduction 1\n",
      "2 Uniform Confidence Bands for Generalized Random Forests 5\n",
      "2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n",
      "2.2 Model and Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n",
      "2.3 Uniform Confidence Bands . . . . . . . . . . . . . . . . . . . . . . . . . 11\n",
      "2.3.1 Multiplier Bootstrap Procedure . . . . . . . . . . . . . . . . . . 11\n",
      "2.4 Numerical Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n",
      "2.4.1 Effective Weights and Infeasible Observations . . . . . . . . . . 14\n",
      "2.4.2 Pointwise Confidence Intervals with Bootstrap Test Statistic . . 15\n",
      "2.4.3 Uniform Confidence Bands . . . . . . . . . . . . . . . . . . . . . 18\n",
      "2.5 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n",
      "2.5.1 Labor Force Participation . . . . . . . . . . . . . . . . . . . . . 19\n",
      "2.5.2 Credit Reform . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n",
      "2.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n",
      "2.7 Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n",
      "2.7.1Forest Specification and Assumptions Required for Pointwise\n",
      "Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n",
      "2.7.2 Detailed Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n",
      "3Data Analytics Driven Controlling: bridging statistical modeling and\n",
      "managerial intuition 34\n",
      "3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n",
      "3.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n",
      "3.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n",
      "3.3.1 Basic Idea . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n",
      "3.3.2 Stochastics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n",
      "3.3.3 Local Parametric Approach . . . . . . . . . . . . . . . . . . . . 41\n",
      "3.3.4 Multiplier Bootstrap . . . . . . . . . . . . . . . . . . . . . . . . 42\n",
      "3.3.5 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n",
      "3.4 Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n",
      "3.4.1 Simulation study . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n",
      "3.5 Use case study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n",
      "3.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n",
      "3.7 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n",
      "4 Surrogate Models for Optimization of Dynamical Systems 60\n",
      "4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n",
      "4.2 Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n",
      "4.3 Mathematical Framework . . . . . . . . . . . . . . . . . . . . . . . . . 64\n",
      "4.3.1 Optimal Control Problem for Dynamical Systems . . . . . . . . 64\n",
      "4.3.2 Surrogate Models for Optimization Problems . . . . . . . . . . . 66\n",
      "viiviii CONTENTS\n",
      "4.4 Enhanced Surrogate Models . . . . . . . . . . . . . . . . . . . . . . . . 71\n",
      "4.4.1 Iterative Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 73\n",
      "4.5 Application of POD-RBF Method on Dynamical Systems . . . . . . . . 74\n",
      "4.5.1 Model 1: Science Policy . . . . . . . . . . . . . . . . . . . . . . 75\n",
      "4.5.2 Model 2: Population Dynamics . . . . . . . . . . . . . . . . . . 79\n",
      "4.5.3Model 3: Quality Control in Production and Process Management 83\n",
      "4.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n",
      "4.6.1 Limitations and Future Work . . . . . . . . . . . . . . . . . . . 88\n",
      "5Blockchain Mechanism and Distributional Characteristics of Cryptos 92\n",
      "5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n",
      "5.2 Data Source and Description . . . . . . . . . . . . . . . . . . . . . . . . 95\n",
      "5.2.1 Underlying Mechanism . . . . . . . . . . . . . . . . . . . . . . . 95\n",
      "5.2.2 Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n",
      "5.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n",
      "5.4 Empirical Evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n",
      "5.4.1 Clustering with Crypto Prices . . . . . . . . . . . . . . . . . . . 102\n",
      "5.4.2 Clustering with Actual Block Time . . . . . . . . . . . . . . . . 104\n",
      "5.4.3 Clustering with Actual Block Size . . . . . . . . . . . . . . . . . 106\n",
      "5.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n",
      "5.6 Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108List of Figures\n",
      "2.1 Effective weights based on GRF for various DGP . . . . . . . . . . . . 14\n",
      "2.2Infeasible observations and their convergence to the true values as the\n",
      "number of observations increase . . . . . . . . . . . . . . . . . . . . . . 15\n",
      "2.3Density plot of the bootstrap test statistic and the density plot of\n",
      "standard normal distribution . . . . . . . . . . . . . . . . . . . . . . . . 16\n",
      "2.4Location parameter θ0= 0.9, the estimated parameter for each replica-\n",
      "tion and corresponding pointwise CIs using bootstrap test statistic and\n",
      "standard normal distribution . . . . . . . . . . . . . . . . . . . . . . . . 16\n",
      "2.5Power curve of the bootstrap test statistic and standard normal distri-\n",
      "bution for a simulation setup . . . . . . . . . . . . . . . . . . . . . . . . 17\n",
      "2.6Bootstrap CIs for the DGP, where the quantile RF is trained and\n",
      "evaluated for several test points. The plots show the true parameter,\n",
      "estimated parameter and pointwise CIs for bootstrap test statistic . . . 18\n",
      "2.7Power curve of the bootstrap test statistic and standard normal distri-\n",
      "bution; the coverage of true parameter in bootstrap UCB and bootstrap\n",
      "pointwise CIs with different minimum node sizes . . . . . . . . . . . . . 20\n",
      "2.8Bootstrap CIs for the DGP y=sin 8x+ε, where GRF regression forest\n",
      "is trained with n= 1000andσ= 0.1, and evaluated for 200 test points.\n",
      "The plots show the true parameter, estimated theta, pointwise CIs for\n",
      "bootstrap test statistic for four replications and UCB . . . . . . . . . . 20\n",
      "2.9Figure of pointwise CIs for labor force example taken directly from Athey\n",
      "et al. (2019) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n",
      "2.10Generalized random forest estimates for the labor force example, corre-\n",
      "sponding 95% pointwise CIs and UCB . . . . . . . . . . . . . . . . . . 23\n",
      "2.11Conditional class probability estimates for the default class obtained\n",
      "from GRF and corresponding 95% pointwise CIs and UCB . . . . . . . 25\n",
      "3.1Time series of count of M&As per month / energy sector of Germany\n",
      "with moving average curves of 1 year and 3 years . . . . . . . . . . . . 35\n",
      "3.2Distribution of count of M&As per month for the energy sector of\n",
      "Germany, and tail of distribution (95th percentile) . . . . . . . . . . . . 36\n",
      "3.3Graphical illustration of the iterative algorithm to search for the homo-\n",
      "geneous window within a time series . . . . . . . . . . . . . . . . . . . 44\n",
      "3.4Simulated series and their corresponding homogeneous windows and\n",
      "maximum likelihood estimators for geometrically increasing interval sizes 47\n",
      "3.5Simulated series and their corresponding homogeneous windows and\n",
      "maximum likelihood estimators for arithmetically increasing interval sizes 48\n",
      "3.6Time series of simulated data and one step ahead prediction with esti-\n",
      "mates from LPA, 1 year fixed window and 3 year fixed window . . . . . 49\n",
      "3.7Time series of original data of German Telecommunications, Financials\n",
      "and Energy M&As and one step ahead prediction with estimates from\n",
      "LPA, 1 year fixed window and three year fixed window . . . . . . . . . 51\n",
      "ixx LIST OF FIGURES\n",
      "3.8Autocorrelation and partial autocorrelation plots for the original data\n",
      "and differenced series . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n",
      "3.9Distribution of estimated interval length as a proportion of data points\n",
      "for (1) Financials, (2) Telecommunication and (3) Energy . . . . . . . . 53\n",
      "4.1 Comparison of various sampling techniques . . . . . . . . . . . . . . . . 67\n",
      "4.2Example of iterative algorithm of two optimization parameters with five\n",
      "iterations and recursively decreasing lengths . . . . . . . . . . . . . . . 73\n",
      "4.3 POD-RBF algorithm flowchart . . . . . . . . . . . . . . . . . . . . . . . 74\n",
      "4.4 Cumulative energy plot to determine singular values for Model 1 . . . . 77\n",
      "4.5 Actual surface vs approximated surface for Model 1 . . . . . . . . . . . 78\n",
      "4.6 Optimal surface and control functions for Model 1 . . . . . . . . . . . . 79\n",
      "4.7 Actual vs approximated surface of Model 2 . . . . . . . . . . . . . . . . 82\n",
      "4.8 Actual surface vs approximated surface for Model 3 . . . . . . . . . . . 84\n",
      "4.9 Optimal surface and optimal control plots for Model 3 . . . . . . . . . 86\n",
      "4.10 Illustration of iterative algorithm for Model 3 . . . . . . . . . . . . . . 86\n",
      "5.1 Blockchain software forks in cryptocurrency . . . . . . . . . . . . . . . 96\n",
      "5.2 Bitcoin’s difficulty adjustment toward actual block time . . . . . . . . . 97\n",
      "5.3 Time series of prices of the 18 cryptos . . . . . . . . . . . . . . . . . . . 98\n",
      "5.4 Actual block time in minutes . . . . . . . . . . . . . . . . . . . . . . . . 98\n",
      "5.5 Actual block size in megabytes . . . . . . . . . . . . . . . . . . . . . . . 99\n",
      "5.6 Visualisation of five clusters of cryptos based on the prices . . . . . . . 103\n",
      "5.7 Visualisation of five clusters of cryptos based on the block time . . . . . 105\n",
      "5.8 Visualisation of five clusters of cryptos based on the block size . . . . . 106List of Tables\n",
      "2.1 Coverage percentage of the location parameter θ0over replications . . . 17\n",
      "2.2 The coverage of the true conditional median and expected value of the\n",
      "estimate over 100 replications . . . . . . . . . . . . . . . . . . . . . . . 18\n",
      "2.3Coverage of true parameter for various DGP and different minimum\n",
      "node sizes ( h) with n= 500,grids = 20,σ= 1, and 100replications . . 19\n",
      "2.4Size performance of asymptotic CIs, bootstrap CIs, asymptotic UCB,\n",
      "and bootstrap UCB with varying training points ( n), minimum node\n",
      "size ( h), equidistant testing points ( grids) and variance ( σ) of DGP . . 21\n",
      "2.5 Description of the variables for the credit reform database . . . . . . . 24\n",
      "2.6Description of ten financial ratios that are calculated using the variables\n",
      "in credit reform database. . . . . . . . . . . . . . . . . . . . . . . . . . 25\n",
      "3.1Forecast results for 02-2020 to 04-2020 based on the adaptively selected\n",
      "MLE, fixed windows, ARIMA and most recurring window proportionally\n",
      "(w)in the distribution plots in Figure 3.9 . . . . . . . . . . . . . . . . . 54\n",
      "4.1 Details of notations used in preceding analysis . . . . . . . . . . . . . . 75\n",
      "4.2 Description of parameters for Model 1 . . . . . . . . . . . . . . . . . . 76\n",
      "4.3 RMAE for various experimental designs of Model 1 . . . . . . . . . . . 77\n",
      "4.4 Optimization results for Model 1 . . . . . . . . . . . . . . . . . . . . . 79\n",
      "4.5 RMAE for various experimental designs of Model 2 . . . . . . . . . . . 81\n",
      "4.6 Optimization results for Model 2 . . . . . . . . . . . . . . . . . . . . . 82\n",
      "4.7 RMAE for various experimental designs of Model 3 . . . . . . . . . . . 84\n",
      "4.8 Optimization results for Model 3 . . . . . . . . . . . . . . . . . . . . . 85\n",
      "5.1 Characteristics of prices of different cryptocurrencies . . . . . . . . . . 108\n",
      "5.2 Characteristics of Block time of different cryptocurrencies . . . . . . . . 109\n",
      "5.3 Characteristics of Block size of different cryptocurrencies . . . . . . . . 110\n",
      "xiChapter 1\n",
      "Introduction\n",
      "The advent of big data brought with itself the curse of dimensionality and the bane of\n",
      "non-stationarity. This created the demand for methodologies that are aware of these\n",
      "data complexities, and provide tools to deal with them in a vigorous manner. In this\n",
      "spirit, predictive algorithms in artificial intelligence (AI) and machine learning (ML)\n",
      "have advanced at an unprecedented speed in past 20 years. Their success is backed by\n",
      "their remarkable practical performance and utilization of the high-dimensional data to\n",
      "its fullest to see the unknown patterns and make accurate prediction. However, very\n",
      "little is known about the mathematical properties of these algorithms, with no clear\n",
      "guarantees, see for example the discussion in Biau and Scornet (2016). This is simply\n",
      "becausetheimportanceofstatisticalaspectsofmachinelearningisoftenneglected. This\n",
      "negligence most probably stems from a reluctance to acknowledge the non-coincidental\n",
      "connection between machine learning and classical nonparametric estimation methods.\n",
      "This is exactly the focus of this thesis: to couple the classical statistical approaches such\n",
      "as bootstrapping, interpolation, and maximum likelihood estimation with state-of-art\n",
      "techniques in order to strike a balance between theoretical understanding and practical\n",
      "performance. More precisely, this thesis assists the statistical intuition in presence\n",
      "of data complications through dimension flexible and adaptive statistical learning\n",
      "methodologies.\n",
      "The dimension flexible statistical learning methods provide ways to accommodate\n",
      "a variety of covariates, allowing to learn the most from the complexity of the high\n",
      "dimensional spaces. This includes capturing sparsity, overlaps, correlated groups\n",
      "or hierarchical structures in covariates. A very good example of dimension flexible\n",
      "methods is Random Forests (RF) algorithm introduced first by Breiman (2001b) in\n",
      "which random feature selection improves the performance in high dimensional settings.\n",
      "Another aspect of dimensional flexible statistical learning is dimensionality reduction,\n",
      "where a low dimensional projection that summarizes the maximum information from\n",
      "the data is sought. Principle component analysis (PCA) is a prime example of it.\n",
      "The adaptive statistical learning, on the other hand, caters to the non stationarity\n",
      "of time series data. The Local Parametric Approach (LPA) by Spokoiny (1998), for\n",
      "example, identifies the stationary segments in a time series where a parametric model\n",
      "12 CHAPTER 1. INTRODUCTION\n",
      "can be applied. In this dissertation, these methodologies have been extended to answer\n",
      "research questions in diverse disciplines. Indeed, one of the main contributions of\n",
      "this research is to bridge the gap between statistics and other disciplines, specifically\n",
      "economics, finance, and machine learning.\n",
      "Starting with a dimension flexible methodology, the second chapter of this thesis\n",
      "discusses the ’Uniform Confidence Bands for Generalized Random Forests’. Random\n",
      "forests are a powerful tool of nonparametric data science and have been studied\n",
      "intensively for their theoretical properties and applicability in many scientific fields.\n",
      "Among the newest insights into their asymptotics are extensions towards Generalized\n",
      "Random Forests (GRF) where the central limit theorem allows studying pointwise\n",
      "influence of features/variables. In this research, we extend these findings towards\n",
      "uniform convergence, hence allowing to check whether one observes significant effects\n",
      "over a range of feature values. We find critical values for the uniform confidence\n",
      "bands using multiplier bootstrap, since it is well known that the standard approach\n",
      "via extreme value theory has very slow asymptotics. Numerical simulations verify that\n",
      "this ’wild bootstrap’ like method provides reliable results and coverage, even in small\n",
      "samples. As a real life application, we extend the labor force example provided in Athey\n",
      "et al. (2019) and find using uniform confidence bands that the father’s low income\n",
      "doesn’t always drive the conditional local average treatment effect of mother returning\n",
      "to the labor force after having a third child. In addition, we consider a credit scoring\n",
      "application which lies at the heart of financial analysis and find that higher profitability\n",
      "doesn’t provide any financial institution a direct ticket to non-default category.\n",
      "The third chapter falls in the domain of adaptive statistical learning, and is called\n",
      "’Data Analytics Driven Controlling: bridging statistical modeling and managerial\n",
      "intuition’. We undertake this interdisciplinary research because predicting merger\n",
      "& acquisition (M&A) events is at the heart of strategic management, and yet it\n",
      "is not sufficiently motivated by data analytics driven controlling. One of the main\n",
      "obstacles in using e.g. count data time series for M&A seems to be that the intensity\n",
      "of M&A is time varying at least in certain business sectors, e.g. energy, financials and\n",
      "telecommunications. Typical models require a-priori parameter selection and mostly\n",
      "focus on US markets. This selection is often based on experience and intuition. We\n",
      "propose using a new automatic procedure to bridge this obstacle using novel statistical\n",
      "methods. It is robust to aberrant behaviour and works without the need for parameter\n",
      "specification, large data sets, assumptions such as stationarity, or even the selection\n",
      "of a training set. The automated nature eradicates the bias that human interaction\n",
      "often introduces when fitting models. We put it into action on various M&A data sets\n",
      "covering German markets and show that it generates accurate forecasts. As a side\n",
      "result, it provides guidance for an a-priori selection of fixed windows for forecasting3\n",
      "using e.g. autoregressive models. Furthermore, it can be generalized to other business\n",
      "lines, e.g. for managing supply chains, sales forecasts, or call center arrivals, thus\n",
      "giving managers new ways for incorporating statistical modeling in strategic planning\n",
      "decisions.\n",
      "In Chapter 4, we discuss a novel methodology for construction of low dimensional\n",
      "surrogate models for high dimensional dynamical systems. These models use a suitable\n",
      "orthogonal decomposition and radial basis functions to reduce the computational\n",
      "complexity of numerical solutions to optimization problems. The pre-existing reduced-\n",
      "order models result in low accuracy sometimes, due to inappropriate initial sampling or\n",
      "the occurrence of optima at vertices. We provide an improved, intelligent, data-driven\n",
      "mechanismforconstructinglow-dimensionalsurrogatemodelsusingalternativememory-\n",
      "based sampling strategies in an iterative algorithm. Furthermore, the application of\n",
      "surrogate models is extended to optimal control problems. It is shown that surrogate\n",
      "modelswithLatinhypercubesamplingdominatevariable-ordermethodsinoptimization\n",
      "computation time while maintaining accuracy. They are also shown to be robust to\n",
      "nonlinearities in the model. Therefore, these computationally efficient predictive\n",
      "surrogate models are applicable in various fields, especially for solving inverse problems\n",
      "and optimal control problems, some examples of which are shown in this paper.\n",
      "In Chapter 5, we work with multivariate time series data. We find a low dimen-\n",
      "sional characteristic based summary of the high dimensional space to investigate the\n",
      "relationship between underlying blockchain mechanism of cryptocurrencies and its\n",
      "distributional characteristics. In addition to price, we emphasise on using actual block\n",
      "size and block time as the operational features of cryptos. In order to summarize\n",
      "the information from crypto time series, we use distributional characteristics such as\n",
      "Fourier power spectrum, moments, quantiles, global optimums, as well as the measures\n",
      "for long term dependencies, risk and noise. With the hypothesis that the blockchain\n",
      "structure explains the distributional characteristics of cryptos, we use characteristic\n",
      "based spectral clustering to cluster the selected cryptos into five groups. We scrutinise\n",
      "these clusters and find that indeed, the clusters of cryptos share similar mechanisms\n",
      "such as origin of fork, difficulty adjustment frequency, and the nature of block size. This\n",
      "paper provides crypto creators and users with a better understanding of the connection\n",
      "between the blockchain protocol design and distributional characteristics of cryptos.\n",
      "To conclude, I would like to quote these words from Breiman (2001a), which, in my\n",
      "opinion, aptly summarize the philosophy of this thesis:\n",
      "The roots of statistics, as in science, lie in working with data and checking\n",
      "theory against data. I hope in this century our field will return to its roots.4 Bibliography\n",
      "There are signs that this hope is not illusory. Over the last ten years, there\n",
      "has been a noticeable move toward statistical work on real world problems\n",
      "and reaching out by statisticians toward collaborative work with other\n",
      "disciplines. I believe this trend will continue and, in fact, has to continue if\n",
      "we are to survive as an energetic and creative field.\n",
      "All codes of this dissertation are available on quantlet.de.\n",
      "Bibliography\n",
      "Athey, S., Tibshirani, J., & Wager, S. (2019). Generalized random forests [Publisher:\n",
      "Institute of Mathematical Statistics]. The Annals of Statistics ,47(2), 1148–1178.\n",
      "https://doi.org/10.1214/18-AOS1709\n",
      "Biau, G., & Scornet, E. (2016). A random forest guided tour. TEST,25(2), 197–227.\n",
      "https://doi.org/10.1007/s11749-016-0481-7\n",
      "Breiman, L. (2001a). Statistical modeling: The two cultures. Quality Engineering ,48,\n",
      "81–82.\n",
      "Breiman, L. (2001b). Random forests. Machine Learning ,45(1), 5–32. https://doi.org/\n",
      "10.1023/A:1010933404324\n",
      "Spokoiny, V. G. (1998). Estimation of a function with discontinuities via local polyno-\n",
      "mial fit with an adaptive window choice [Publisher: Institute of Mathematical\n",
      "Statistics]. The Annals of Statistics ,26(4), 1356–1378. https://doi.org/10.1214/\n",
      "aos/1024691246Chapter 2\n",
      "Uniform Confidence Bands for Gener-\n",
      "alized Random Forests\n",
      "2.1 Introduction\n",
      "Random forests (RF) are a a versatile tool, widely used in statistical learning situa-\n",
      "tions. The last decade of theoretical insights and advancements have yielded precise\n",
      "asymptotics for the nonparametric data science techniques. An important step in\n",
      "these advances towards understanding and expanding RF is the combination of GMM\n",
      "(generalized method of moments) with dimension flexible modelling. Indeed Athey et al.\n",
      "(2019) by introducing Generalized Random Forests (GRF) showed that the estimates\n",
      "obtained through GRF are consistent and asymptotically normal. The asymptotic\n",
      "theory developed there is focused on pointwise CIs. This does not allow to make\n",
      "statements about the ’global’ influence of a feature since that requires control over a\n",
      "range of input features. This is the essence of this research: we provide ’confidence’\n",
      "over a range of feature values.\n",
      "RF are a well established and an often used nonparametric estimation technique to\n",
      "study functions θ(x)e.g. the conditional mean or the quantile when given the data.\n",
      "Although, technically rooted in the 1984 CART book of Breiman et al. (1984), RFs -\n",
      "as a resampling algorithm - came only recently into the focus of asymptotic analysis.\n",
      "Consistency, asymptotic normality, second order asymptotic have been studied by many\n",
      "authors (e.g. Arlot and Genuer (2014); Biau et al. (2008); Biau (2010); Denil et al.\n",
      "(2014); Lin and Jeon (2006); Scornet et al. (2015); Wager and Walther (2016); Mentch\n",
      "and Hooker (2016); Wager and Athey (2018)).\n",
      "As a sloppy sounding summary of these asymptotic results one may state \"an approxi-\n",
      "mation technique to calibrate the data to functionals of the conditional distribution,\n",
      "RFs can be seen as locally adaptive weights smoothers.\" This one line summary though\n",
      "does not catch the full spirit of RFs since assumptions on e.g. data dependent CART\n",
      "splitting need to be made to handle the asymptotics with the currently available ma-\n",
      "chinery. Many alternative splitting criterion have been proposed in literature, however,\n",
      "with limited applicability.\n",
      "56 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "Athey et al. (2019) by introducing GRF provide another perspective to ease the\n",
      "asymptotic complications. They explain that RF can be perceived as an adaptive\n",
      "kernel method and develop a unified framework that is applicable to nonparametric\n",
      "estimation of the quantities θ(x)such as conditional means, quantiles, average partial\n",
      "effects, average treatment effect calculation or regression with instrumental variables.\n",
      "In general, we observe {(Xi, Oi)}n\n",
      "i=1, where Oi={Yi, Wi}, Yiwould be the response,\n",
      "andWimight be the treatment assignment in the treatment effect situation:\n",
      "Yi=ν(Xi) +θ(Xi)Wi+εi (2.1)\n",
      "Here ν(.)denotes the nuisance parameter, and εian error term with stochastic prop-\n",
      "erties to be defined throughout. This general form allows the flexibility in various\n",
      "statistical settings to estimate quantities identifiable via local moment conditions\n",
      "E{ψθ(x),ν(x)(Oi)|Xi=x}= 0for any x.ψθ,ν(Oi)is the score functions with expected\n",
      "score Mθ,ν(x)def=E[ψθ,ν(Oi)|X=x]that satisfies the moment conditions under cer-\n",
      "tain regularity assumptions on the density function f(x;θ)of the data (Xi, Oi)∈ X ×O.\n",
      "In other terms, the score function could be defined as the gradient of the natural loga-\n",
      "rithm of the likelihood function L(θ;x) =f(x;θ)with respect to the parameter vector\n",
      "θ.\n",
      "The aim of the score equation is to be able to create a family of nonparametric\n",
      "estimators that are stable, but also adaptable to different functional forms. Such a\n",
      "flexible technique might be useful since many calibration problems in econometrics\n",
      "involve unknown functional forms (Horowitz & Manski, 2000). An important set\n",
      "of applications in economics indeed require solving regression problems conditional\n",
      "on features, or equivalently, estimate the conditional average partial effects under\n",
      "exogeneity.\n",
      "Let us present two examples. A substantial amount of debate is currently observed,\n",
      "whethermicrofinanceprogramsareabletoalleviatepovertyandhencefueldevelopment.\n",
      "The successful introduction of this program by Mohamed Younis, Grameen Bank in\n",
      "Bangladesh, got worldwide attention and has replicated in many other developing\n",
      "countries. In this scenario Yicould be the loan taken by households, as a function ν(.)\n",
      "of characteristics like those from households (gender, education, district). Here Wiis a\n",
      "treatment dummy variable that equals 1 if participant is an old loan holder who has\n",
      "taken loans for more than one year; 0 otherwise.\n",
      "Another interesting example is given in the study of Athey et al. (2019) where the left\n",
      "hand side of the equation reflects the likeliness of a mother to return to work after\n",
      "birth of child/children as function of characteristics of say e.g. father’s income. More2.1. INTRODUCTION 7\n",
      "precisely it is put into a GRF framework where the outcome Yiis whether the mother\n",
      "did not work in the year preceding the census. The feature Wiindicates whether the\n",
      "mother had three or more children at census time. The GRF output is conditional\n",
      "local average treatment effect (CLATE), θ(x), where xcould be e.g. father’s income.\n",
      "To characterize the uncertainty that comes with any estimate, the estimate θˆ(x)is\n",
      "shown to be asymptotically normal. Hence one constructs the 95%pointwise confidence\n",
      "intervals (CI) for the causal effect.\n",
      "It is even more interesting though to look at the simultaneous coverage probability\n",
      "of a collection of pointwise CIs, i.e. along a range of x′s. This is presented here by\n",
      "constructing simultaneous confidence bands, otherwise known as uniform confidence\n",
      "bands (UCB) around the nonparametric estimates of θ(x). This way, not only the\n",
      "statistical accuracy and overall variation of the estimates can be assessed, but also\n",
      "hypothesis tests can be performed about the estimated function without access to the\n",
      "data. For example, considering the asymptotic maximal deviation of M-smoothers to\n",
      "construct the UCB, W. Härdle (1989) provide the following:\n",
      "P[︂\n",
      "(2δlogn)1/2{︂\n",
      "supx∈D⃓⃓⃓rn(x)[︂\n",
      "θˆn(x)−θ0(x)]︂⃓⃓⃓/∥K∥2−dn< a]︂\n",
      "→exp{−2 exp(−a)}\n",
      "where δ, r(t), λ(K), dnare suitable scaling parameters. J. Angrist et al. (2006) compare\n",
      "pointwise CIs with UCB in their study and explain the importance of UCBs in the\n",
      "context of conditional quantiles.\n",
      "In this paper, we undertake the task of constructing UCB for the GRF based estimates.\n",
      "For this, one checks that the estimate θˆ(x), as function of x, is uniformly converging to\n",
      "θ(x). Given data at hand one needs to pick a critical value Cαsuch that\n",
      "(GRF Aim equation)\n",
      "P(︄\n",
      "sup\n",
      "x|θˆ(x)−θ(x)|\n",
      "σn(x)≤Cα)︄\n",
      "−→\n",
      "u→∞1−α (2.2)\n",
      "The involvement of sup norm in the above equation makes it challenging to construct\n",
      "precise confidence bands for nonparametric estimates. It is well known that the limiting\n",
      "distribution of the Gaussian process ˆ︁θ(x)−θ(x)is of the Gumbel type. However, the\n",
      "standard approach via extreme value theory suffers from a very slow asymptotic with\n",
      "convergence rate of (lognθ)−1(Hall, 1991). Thus, the critical value Cαis critical in its\n",
      "construction, as we know from work on for example quantile regression (W. K. Härdle\n",
      "& Song, 2010), semi-parametric additive models (W. Härdle et al., 2015), and pricing\n",
      "kernels (W. K. Härdle et al., 2015).8 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "Motivated by these papers, we determine the critical value for equation (2.2) via\n",
      "bootstrap to obtain possibly better finite sample performance. We use a variant of\n",
      "wild bootstrap by Hardle and Mammen (1993) introduced in Spokoiny and Zhilova\n",
      "(2015) as multiplier bootstrap. multiplier bootstrap has been proven to perform well\n",
      "under model mis-specification and small samples.\n",
      "The main contribution of this research is to provide the methodology for construction of\n",
      "UCB using multiplier bootstrap. Apart from providing the theoretical properties of the\n",
      "bootstrap test statistic, we also compare asymptotic behavior of the pointwise CIs with\n",
      "the bootstrap method in a comprehensive simulation study. The same simulations are\n",
      "also used to verify that the bootstrap method gives reliable results for the estimation\n",
      "and coverage even in small samples. As a real life application, we extend the labor\n",
      "force example provided in Athey et al. (2019) and find using UCB that the father’s low\n",
      "income doesn’t always drive the conditional local average treatment effect of mother\n",
      "returning to the labor force after having third child. In addition, we consider a credit\n",
      "scoring application which lies at the heart of financial analysis and find that higher\n",
      "profitability doesn’t give any financial institution a direct ticket to non-default category.\n",
      "The rest of this paper is structured as follows. In section 2.2, we explain some\n",
      "preliminaries to explain the problem setup in detail. In section 2.3, we provide the\n",
      "model setup for bootstrap method and provide our main theoretical results to construct\n",
      "UCB. The main proofs are given in the appendix 2.7. In section 2.4, we explore the\n",
      "validity of bootstrap method in various simulation settings and implement it on various\n",
      "datasets in section 2.5. Finally, section 2.6 concludes the study.\n",
      "2.2 Model and Estimation\n",
      "Let{Yi, Xi}n\n",
      "i=1be the set of independent and identically distributed random variables\n",
      "Yi∈RandXi∈ X = [0,1]p, representing the nsampling points of scalar response\n",
      "andp-dimensional covariates. Correspondingly, we observe some relevant information\n",
      "Withat might help in learning the data-generating distribution for (Yi, Xi), e.g., the\n",
      "exogenous treatment assignment in the case of treatment effect estimation. Denote\n",
      "Oi={Yi, Wi}.\n",
      "Our purpose is to estimate and make statistical inference (uniformly over x∈ X) on the\n",
      "parameter functions (θ(x), ν(x))involved in the conditional expectation E(Yi|Xi=x),\n",
      "where θ(x)is the parameter of interest and ν(x)is an optional nuisance parameter.\n",
      "The target parameter θ(x)is identified as the solution to the local moment conditions\n",
      "E[ψθ(x),ν(x)(Oi)|Xi=x] = 0,∀x∈ X,\n",
      "where ψ(·)is some vector-valued score function. For any (θ, ν)∈ B ⊆Rk, we define2.2. MODEL AND ESTIMATION 9\n",
      "the expected score function Mθ,ν(x) =E[ψθ,ν(O)|X=x]. Throughout the paper we\n",
      "assume that (θ(x), ν(x))are continuous functions in x.\n",
      "We aim at pursuing the forest-based local estimates of θ(x)andν(x)by minimizing\n",
      "the empirical analogue of the moment equations, i.e.,\n",
      "(θˆn(x), νˆn(x))∈arg min\n",
      "θ,ν⃦⃦⃦n∑︂\n",
      "i=1αi(x)ψθ,ν(Oi)⃦⃦⃦\n",
      "2, (2.3)\n",
      "where the weights αi(x)formulated in the RF capture the frequency that the i-th\n",
      "training sample falls in the same leaf as a given query point x. In particular, given\n",
      "a set of growing trees b= 1, . . . , B, denote the set of training samples falling in the\n",
      "same leaf as xbyLb(x), which characterizes the local similarity structure. The weights\n",
      "which sum to 1 are defined as follows:\n",
      "αbi(x) =1({Xi∈Lb(x)})\n",
      "|Lb(x)|, α i(x) =1\n",
      "BB∑︂\n",
      "b=1αbi(x). (2.4)\n",
      "As argued in Athey et al. (2019), to establish the asymptotic analyses of GRF, we need\n",
      "to consider a linearized approximation to the local estimator θˆn(x)due to the fact that\n",
      "GRF estimator itself is not an average of estimates made by different trees. To be more\n",
      "specific, consider a pseudo estimator in a linear form: θ˜(x) =θ(x) +∑︁n\n",
      "i=1αi(x)ε˜i(x),\n",
      "where ε˜i(x) =−ξ⊤V(x)−1ψθ(x),ν(x)(Oi)is the (infeasible) influence function of the i-th\n",
      "sample, with V(x) =∇Mθ(x),ν(x)(x)being the problem specific curvature function, and\n",
      "ξis a vector that picks out the θ-coordinate form (θ, ν).\n",
      "Consider, for example, the simplest case of the quadratic least square loss: with the\n",
      "score function ψθ(Yi) =Yi−θ. The problem specific curvature parameter V(x) =\n",
      "∂θE{ψθ(Yi)|Xi=x}|θ=θ(x)=−1. In this case, ε˜i(x) =ψθ(x)(Yi) =Yi−θ(x)For this\n",
      "sandbox case we do not need RFs really, but can extend it to regression models with a\n",
      "higher dimensional θvector, e.g. the case of quantile estimation in a location model.\n",
      "Given θ0∈R, Yi=θ0+εi, with θ0=F−1\n",
      "Y(τ), equivalently 0 =F−1\n",
      "ε(τ), see also Ćevid\n",
      "et al. (2020) where ρ(u) =|u(τ−1{u≤0})|. Consequently we have\n",
      "ψθ(Yi) =τ−1{(Yi−θ)≤0}\n",
      "V=∂θE{ψθ(Yi)}|θ=θ0=−fY(θ0)\n",
      "ε˜i=fY(θ0)−1ψθ0(Yi) =fY(θ0)−1(τ−1{(Yi−θ0)≤0})\n",
      "Note that E(ε˜i) = 0and the infeasible estimator θ˜=1\n",
      "n∑︁\n",
      "iY˜i=θ0+1\n",
      "n∑︁\n",
      "iε˜i\n",
      "Similarly, for expectile estimation in a location model,τ\n",
      "1−τ=∫︁θ0\n",
      "−∞|y−θ0|dFY(y)∫︁∞\n",
      "θ0|y−θ0|dFY(y)and10 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "ρ(u) =u2|τ−1{u≤0}|.It follows that\n",
      "ψθ(Yi) = 2( Yi−θ){τ+1{(Yi−θ)≤0}(1−2τ)}\n",
      "V=∂θE{ψθ(Yi)}|θ=θ0= 2E(Yi−θ0)fY(θ0)(1−2τ)−2{τ+FY(θ0)(1−2τ)}\n",
      "ε˜i=−V−1ψθ0(Yi) =(Yi−θ0)(τ−1{(Yi−θ0)≤0})\n",
      "−E(Yi−θ0)fY(θ0)(1−2τ)+{τ+FY(θ0)(1−2τ)}\n",
      "As a final example, consider huberizing the loss function. The Huberizing case involves\n",
      "the loss (or neg log likelihood) ρ(u) =1{|u|≤k}u2/2 +1{|u|>k}(k|u| −k2/2)where we\n",
      "have\n",
      "ψθ(Yi) =1{|Yi−θ|≤k}(Yi−θ) +k(1{(Yi−θ)>k}−1{(Yi−θ)<k})\n",
      "V(x) =∂θE{ψθ(Yi)|Xi=x}|θ=θ(x)=−2kfY|X=x(θ(x) +k)\n",
      "+FY|X=x(θ(x)−k)−FY|X=x(θ(x) +k)\n",
      "ε˜i(x) =−V(x)−1ψθ(x)(Yi) ={2kfY|X=x(θ(x) +k)−FY|X=x(θ(x)−k)\n",
      "+FY|X=x(θ(x) +k)}−1{1{|Yi−θ|≤k}(Yi−θ) +k(1{(Yi−θ)>k}−1{(Yi−θ)<k})}\n",
      "Now, by the definition of the weights αi(x), we have\n",
      "θ˜(x) =B−1B∑︂\n",
      "b=1n∑︂\n",
      "i=1αbi(x){θ(x) +ε˜i(x)}\n",
      "⏞ ⏟⏟ ⏞\n",
      "θ˜b(x),\n",
      "which is an average of the individual pseudo-tree predictions θ˜b(x)trained on a subsam-\n",
      "ple of size s. As a result, θ˜(x)is an infinite-order U-statistic and asymptotic normality\n",
      "follows by the standard results (Efron & Stein, 1981; Hoeffding, 1948).\n",
      "Then, the core task is to show that the linearized pseudo estimator θ˜(x)approximates\n",
      "θˆn(x)closely when nis sufficiently large, namely to justify that θˆn(x)is asymptotically\n",
      "linear. We cite the Assumptions 1-6 and Specification 1 of Athey et al. (2019) which\n",
      "guarantee the pointwise consistency of the generalized random forest estimator as well\n",
      "as the pointwise linearized approximation (Theorem 3 and Lemma 4 therein) in our\n",
      "Appendix 2.7.1. On top of that, we extend the results uniformly over the grid points\n",
      "{x1, . . . , x Ln} ⊆ X, where xl’s are sampled randomly from the uniform distribution on\n",
      "XandLn→ ∞. To this end, we need a Lipschitz condition for the estimators. Let\n",
      "ϑˆn(x) =(︄\n",
      "θˆn(x)\n",
      "νˆn(x))︄\n",
      ",ϑ(x) =(︄\n",
      "θ(x)\n",
      "ν(x))︄\n",
      ".\n",
      "Assumption 2.2.1 (Lipschitz estimator) .We assume that there exist Bn=OP(1)\n",
      "which is independent of xand monotone function h:R+↦→R+such that h(δ)→0as\n",
      "δ→0,∥ϑˆn(x)−ϑˆn(x′)∥2≤Bnh(∥x−x′∥2),∀x, x′∈ X.2.3. UNIFORM CONFIDENCE BANDS 11\n",
      "Lemma 2.2.1 (Uniform approximation) .Under Assumptions 2.7.1 - 2.7.6 and 2.2.1,\n",
      "and given a forest trained according to Specification 1, we have the uniform linearized\n",
      "approximation for θˆn(x):\n",
      "sup\n",
      "1≤l≤Ln⃓⃓⃓θˆn(xl)−θ(xl)−n∑︂\n",
      "i=1αi(xl)ε˜i(xl)⃓⃓⃓=OP(︁\n",
      "max{︁\n",
      "s−πlog((1−w)−1)\n",
      "2 log( w−1)Ln(s/n)1/2, L4/3\n",
      "n(s/n)2/3}︁)︁\n",
      ",\n",
      "with max{︁\n",
      "Ln(s/n)1/2, L4/3\n",
      "n(s/n)2/3}︁\n",
      "=O(1).\n",
      "A detailed proof of the above lemma is provided in Appendix 2.7.\n",
      "2.3 Uniform Confidence Bands\n",
      "This section gives the theoretical results for valid inference on the parameter function\n",
      "uniformly over the covariate space. We now describe two ways of building uniform\n",
      "confidence band for θ(x): based on a high-dimensional Gaussian approximation theorem\n",
      "or via multiplier bootstrap.\n",
      "When xis fixed and suppose that Var(ε˜i|Xi=x)>0, the univariate asymptotic\n",
      "normality of (θˆn(x)−θ(x))/σn(x)with σn(x)of a proper order is proven in Theorem 5\n",
      "of Athey et al. (2019). Then, given any consistent estimator σˆn(x)/σn(x)P→1, the CIs\n",
      "can be constructed for each x∈ Xpointwisely as:\n",
      "lim\n",
      "n→∞E[︂\n",
      "θ(x)∈(︂\n",
      "θˆn(x)±Φ−1(1−α/2)σˆn(x))︂]︂\n",
      "=α (2.5)\n",
      "On the other hand, we observe that it would be more interesting to make uniform\n",
      "inference on the function θ(x)over the covariate space Xin many applications, as\n",
      "discussed in section 2.1.\n",
      "The approximation result in Lemma 2.2.1 makes it possible to derive the limiting\n",
      "distribution of θˆn(x)by a high-dimensional central limit theorem. Moreover, if θ(x)is\n",
      "Lipschitz continuous, the Gaussian and bootstrap approximations for the distribution\n",
      "of the maximum coordinate over l= 1, . . . , L n(forLn→ ∞) would lead us to uniform\n",
      "inference over the whole X.\n",
      "2.3.1 Multiplier Bootstrap Procedure\n",
      "It is well known that the convergence to the asymptotic distribution is very slow and\n",
      "results in low coverage probability in finite sample. Indeed it is easy to see that the\n",
      "asymptotic bands are usually narrow, hence limiting their finite sample performance\n",
      "(Song et al., 2012).\n",
      "There exists a considerable body of literature on the importance of bootstrap sampling\n",
      "in constructing the confidence bands around nonparametric estimates, see for example12 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "W. Härdle et al. (2015), W. K. Härdle and Marron (1991), W. K. Härdle et al. (2015),\n",
      "and Horowitz (2001). W. Härdle et al. (2015) also demonstrate in their paper the\n",
      "improvement of bootstrap over theoretical asymptotic band for M- and L- estimates.\n",
      "We also base our confidence bands on bootstrap for this research.\n",
      "LetSn(x) =∑︁n\n",
      "i=1αi(x)ε˜i(x),Tn(x) = Sn(x)/σn(x),ζn= (Tn(x1), . . . , T n(xLn))⊤.\n",
      "Theorem 1 of Wager and Athey (2018) derives the limiting distribution of Tn(x)\n",
      "pointwisely using U-statistics. Let qn(1−α)be the (1−α)quantile of the distribution\n",
      "of|ζn|∞. Suppose we have a consistent estimator σˆn(x)/σ(x)P→1, for each x∈ X.\n",
      "Also, assume the estimator is bounded from below, i.e., there exists c >0such that\n",
      "infx∈Xσˆn(x)≥cholds with probability 1−O(1).\n",
      "Then, the multiplier bootstrapped statistics is defined as:\n",
      "Tˆ∗\n",
      "n(x) =n∑︂\n",
      "i=1αi(x)εˆi(x){σˆn(x)}−1ei (2.6)\n",
      "andζˆ∗\n",
      "n= (Tˆ∗\n",
      "n(x1), . . . , T ˆ∗\n",
      "n(xLn))⊤, where eiare independently drawn from N(0,1). Let\n",
      "q∗\n",
      "n(1−α)be the (1−α)quantile of the bootstrapped distribution of |ζˆ∗\n",
      "n|∞. In addition,\n",
      "define T˜n(x) =∑︁n\n",
      "i=1αi(x)ε˜i(x){σˆn(x)}−1,ζ˜n= (T˜n(x1), . . . , T ˜n(xLn))⊤.\n",
      "The Gaussian counterpart for the above could be analogously defined. Let ωil=\n",
      "αi(xl)ε˜i(xl){σn(xl)}−1,ωi= (ωi1, . . . , ω iLn)⊤, and observe that∑︁n\n",
      "i=1E(ω2\n",
      "il) = 1, for\n",
      "all1≤l≤Ln. Denote Zn= (∑︁n\n",
      "i=1zi1, . . . ,∑︁n\n",
      "i=1ziLn)⊤, where (zi)n\n",
      "i=1with zi=\n",
      "(zi1, . . . , z iLn)⊤is a sequence of independent N(0,E(ωiω⊤\n",
      "i))vectors. Then cn(1−α)is\n",
      "the(1−α)quantile of the distribution of |Zn|∞.\n",
      "It is sometimes necessary to correct for the bias in the estimated parameter before\n",
      "applying bootstrap since the initial resampling technique doesn’t correctly capture it.\n",
      "In their work, W. K. Härdle and Marron (1991), propose resampling procedure based\n",
      "on a larger bandwidth than the one used originally. However, during our study, we\n",
      "have concluded that this refined bias-correcting bootstrap method is not required in\n",
      "our case, since the bandwidth conditions ensure a negligible bias asymptotically.\n",
      "Lemma 2.3.1 (Validity of the multiplier bootstrap) .Assume:\n",
      "1. There exist ς1↓0, ς2↓0such that\n",
      "P(||ζn|∞− |ζ˜n|∞|> ς1)< ς2, (2.7)\n",
      "P(P e(||ζ∗\n",
      "n|∞− |ζˆ∗\n",
      "n|∞|> ς1)> ς2)< ς2, (2.8)2.4. NUMERICAL STUDY 13\n",
      "where Peis the conditional probability conditioning on (ωi)n\n",
      "i=1, i.e., the probability\n",
      "measure induced by the random multipliers (ei)n\n",
      "i=1.\n",
      "2.|ωi1| ≤Mnfor all iandl, where Mnmay increase with n.\n",
      "3.There exist constants c1, C1>0such that (2.8)holds with ς1√logLn+ς2≤C1n−c1\n",
      "andM2\n",
      "n(log(nLn))7/n≤C1n−c1.\n",
      "Under the above assumptions sup\n",
      "r≥0|P(|ζ˜n|∞≥r)−P(|ζˆ∗\n",
      "n|∞≥r)| →0.\n",
      "The proof of lemma 2.3.1 is given in Appendix 2.7.\n",
      "Lastly, we can construct the UCB by combining the results of uniform approximation\n",
      "and multiplier bootstrap consistency. In particular, it follows that\n",
      "⃓⃓P(θ(xl)∈CI∗\n",
      "l(α),∀l= 1, . . . , L n)−(1−α)⃓⃓→0,\n",
      "where CI∗\n",
      "l(α) = [θˆn(xl)±σˆn(xl)q∗\n",
      "n(1−α)]. Moreover, recall that the first order derivative\n",
      "ofθ(x)is uniformly bounded, i.e. |θ(x)−θ(x′)| ≤C∥x−x′∥2,∀x, x′∈ Xfor some\n",
      "constant C, and assume that C∥x−xℓn(x)∥2P→0asn→ ∞, uniformly over x∈ X,\n",
      "where ℓn(x)def= arg min 1≤l≤Ln∥x−xl∥2. As a result, we have\n",
      "⃓⃓P(θ(x)∈CI∗\n",
      "ℓn(x)(α),∀x∈ X)−(1−α)⃓⃓→0,\n",
      "where CI∗\n",
      "ℓn(x)(α) = [θˆn(xℓn(x))±σˆn(xℓn(x))q∗\n",
      "n(1−α)].\n",
      "Note that if the monotonicity of θ(x)holds true, the UCB for x∈[xl, xl+1], l=\n",
      "1, . . . , L n−1canalsobeconstructedas [θˆn(xl)−q∗\n",
      "n(1−α)σˆn(xl), θˆn(xl)+q∗\n",
      "n(1−α)σˆn(xl)],\n",
      "where\n",
      "xldef= arg max {θˆn(xl) +q∗\n",
      "n(1−α)σˆn(xl), θˆn(xl+1) +q∗\n",
      "n(1−α)σˆn(xl+1)},\n",
      "xldef= arg min {θˆn(xl)−q∗\n",
      "n(1−α)σˆn(xl), θˆn(xl+1)−q∗\n",
      "n(1−α)σˆn(xl+1)}.\n",
      "2.4 Numerical Study\n",
      "This section is divided in various parts. First we want to highlights the behavior of\n",
      "effective weights (2.4) and create thereby the setup to fit quantile RFs on the infeasible\n",
      "observations. We then check the validity of the proposed bootstrap mechanism in\n",
      "various simulation settings and compare its performance with the asymptotic UCB.14 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "2.4.1 Effective Weights and Infeasible Observations\n",
      "Let us start with a simple example of n= 500points to demonstrate how the effective\n",
      "RF weights introduced earlier capture the local structures of any given function. We\n",
      "employ a function that is ideal to capture the local averaging effects of RFs, since\n",
      "it only depends on one feature X1. Consider the data generating process (DGP) for\n",
      "i= 1, . . . , nandX1=−1 + 2 i/n:\n",
      "θ(x1, x2) = max (0 ,1− |x1|/η), Yi=θ(Xi) +εi, (2.9)\n",
      "where θdenotes the mean value of the process, and where εi∼N(0, σ2)is a random\n",
      "noise term. Here, the parameters σ2andη= 0.2are assumed to be constant. The\n",
      "effective GRF weights αi(x)trained on (Xi, Yi)iare shown in Figure 2.1. The simulation\n",
      "setup shows how these effective weights from GRF adapt automatically to the missing\n",
      "X2feature effect since the effective weights start peaking close to η= 0.2and die out\n",
      "slowly after that, accurately following the nature of the function θ(x1, x2).\n",
      "Figure 2.1: αi(x)based on GRF trained on (Xi, Yi)iforσ= 0(upper panel), σ= 0.1(lower\n",
      "panel) at various values of variable X1.\n",
      "GRF_effective_weights\n",
      "To advance the understanding of ’infeasible observations’ discussed earlier, let us take a\n",
      "quantile case with ψθ(x)(Yi)=τ−1{(Yi−θ(x))≤0}in quantile regression forest simulation\n",
      "setup. Consider a function with polynomial terms θ(x) =β0+β1x+β2x2+β3x3,where\n",
      "x∼U[−c, c]. Take Y=θ(X)+ε, ε∼N(0, σ2)andβ= (0,1,0,4)⊤, c= 1,andσ= 1\n",
      "and various number of observations n= 500 ,1000,and2000.2.4. NUMERICAL STUDY 15\n",
      "The results presented in the Figure 2.2 provide easy visual verification about the\n",
      "coupling of infeasible observations with the true value, the theoretical rate which was\n",
      "discussed in section 2.3. One can observe that as the number of observations increase\n",
      "from the left to right panel, the curve of infeasible observations moves closer to the\n",
      "the blue dashed line of the true quantity. With a more empirical understanding of\n",
      "the behaviour of effective weights and role of infeasible observations in the original\n",
      "GRF study, we aim to verify the validity of and practical performance of bootstrap\n",
      "test statistic and investigate its theoretical properties using numerical simulations.\n",
      "Figure 2.2: Y=θ(X)+ε, with ε∼N(︁\n",
      "0, σ2)︁\n",
      "(black dots), θ(x) =x+ 4x3(blue dashed line)\n",
      "andθ˜(x) =θ(x) +∑︁n\n",
      "i=1αi(x)ε˜i(x)(red line) with τ= 0.5forn= 500(left), n= 1000\n",
      "(middle) and n= 2000(right) .\n",
      " GRF_effective_weights_quantileRF\n",
      "2.4.2Pointwise Confidence Intervals with Bootstrap Test Statis-\n",
      "tic\n",
      "Consider a very simple location model of quantiles with fixed θ0= 0.9, Yi=θ0+εi, εi∼\n",
      "N(0, σ2\n",
      "ε), i= 1, . . . , nwith τ= 0.5andσε= 1. Here αi(x)are estimated based on\n",
      "quantile regression forest trained on (1, Yi)i. For this setup, the bootstrap test statistic\n",
      "introduced in equation (2.6) takes the form T∗\n",
      "n=−∑︁n\n",
      "i=1Hˆ−1/2{︂\n",
      "τ−1{(Yi−θˆ)≤0}}︂\n",
      "αiei,\n",
      "with ei∼\n",
      "i.i.dN(0,1), i= 1, . . . , bandbthe number of bootstraps. This can be easily\n",
      "verified for the quantile case ψθˆ(Yi)=τ−1{(Yi−θˆ)≤0}since Vˆ=−fˆY(θˆ). This results in\n",
      "Hˆ=Var∑︁n\n",
      "i=1αi{︂\n",
      "τ−1{(Yi−θˆ)≤0}}︂\n",
      ",σˆ2\n",
      "n={︂\n",
      "fˆY(θˆ)}︂−2\n",
      "Hˆ,εˆi=−{︂\n",
      "fˆY(θˆ)}︂−1{︂\n",
      "τ−1{(Yi−θˆ)≤0}}︂\n",
      ".\n",
      "The empirical density of T∗\n",
      "n(x)over 100 replications and b= 500is shown in the density\n",
      "plot in Figure 2.3. The plot demonstrates that T∗\n",
      "n(x)approximately follows a standard\n",
      "normal distribution, which is identical to the asymptotic distribution of GRF estimate\n",
      "given in Athey et al. (2019).16 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "Figure 2.3: Density plot of the bootstrap test statistic (black line) and the density plot of\n",
      "standard normal distribution (blue line) for n= 500(left), and n= 1000(right) with 100\n",
      "replications and 500 bootstraps\n",
      " GRF_effective_weights_bootstrap\n",
      "Using{θˆ(x)−θ(x)}/σn(x)→\n",
      "LN(0,1),onecansimplygetthepointwiseCIs[︂\n",
      "θˆ(x)±Φ−1\n",
      "1−ασˆn(x)]︂\n",
      ",\n",
      "given any consistent estimator σˆn(x).Similarly, it is straightforward to construct point-\n",
      "wise CIs based on bootstrap test statistic using q∗\n",
      "1−α(x), the (1−α)quantile of |T∗\n",
      "n(x)|.\n",
      "Thus the CIs are[︂\n",
      "θˆ(x)±q∗\n",
      "1−α(x)σˆn(x)]︂\n",
      ". See, for example, the pointwise CIs using\n",
      "both the asymptotic normal distribution and bootstrap test statistic for the location\n",
      "model in Figure 2.4.\n",
      "Figure 2.4: Location parameter θ0= 0.9(red solid line), the estimated parameter for each\n",
      "replication (blue dots) and corresponding pointwise CIs using bootstrap test statistic (black\n",
      "line) and standard normal distribution (blue line)for n= 500(left), and n= 1000(right)\n",
      "GRF_effective_weights_bootstrap\n",
      "It can be observed that the average lengths of bootstrap CIs are slightly higher than\n",
      "those of asymptotic CIs. This can also be characterized in terms of coverage percentages\n",
      "of the true θ(x)given in Table 2.1. The Table highlights the performances difference\n",
      "between the bootstrap CIs and the asymptotic CIs. The bootstrap coverage is higher\n",
      "than asymptotic CIs in all cases, hence supporting the theoretical advantage of using\n",
      "bootstrap in small samples.\n",
      "It can also be concluded from the Table 2.1 that the size performance ( Pr (type l2.4. NUMERICAL STUDY 17\n",
      "n Replications θ0Bootstrap CI Asymptotic CI\n",
      "500 100 0.9 95% 91%\n",
      "1000 100 0.9 96% 91%\n",
      "500 100 0.0 97% 94%\n",
      "1000 100 0.0 98% 96%\n",
      "Table 2.1: Coverage percentage of the location parameter θ0over replications\n",
      "error|θ0= 0)) with α= 0.05andn= 500for the bootstrap test statistic is 0.03, and\n",
      "for asymptotic normal the size performance is 0.06. Furthermore, the power curve\n",
      "(1−Pr (type II error |θj̸= 0), j= 1, . . . , J) for J= 20andθj∈[0.05,1]plotted in\n",
      "Figure 2.5 shows that the bootstrap test statistic has the same power curve as the\n",
      "standard normal distribution.\n",
      "Figure 2.5: Power curve of the bootstrap test statistic (black line) and standard normal\n",
      "distribution (blue line) with n= 500andα= 0.05for the location model (left) and for\n",
      "equation (2.10) (right)\n",
      " GRF_effective_weights_bootstrap\n",
      "Consider another DGP to evaluate the performance of the bootstrap test statistic using\n",
      "a more complicated two-dimensional DGP given in equation (2.9). Here, we slightly\n",
      "modified DGP to increase the simulation complexity such that\n",
      "Xj,k,1=−0.5 +j/n 1, j= 1, . . . , n 1\n",
      "Xj,k,2= 0.1 + 0 .1k, k= 0, . . . , n 2−1, n2= 10\n",
      "Xi= (Xi,1, Xi,2)fori= (j−1) (n2+ 1) + k, j= 1, . . . , n 1, k= 0, . . . , n 2(2.10)\n",
      "Similar to the previous example, a quantile regression forest based on GRF is used. The\n",
      "size performance (given in parenthesis) of the bootstrap test statistic (0.0535) is once\n",
      "again better than that of asymptotic normal (0.077). Furthermore, the power curve\n",
      "for both the settings look analogous as shown in the right panel of Figure 2.5. The\n",
      "coverage of the true conditional median and expected value of the estimate over 10018 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "replications are given in the Table 2.2. As is immediate from the Table, the intervals\n",
      "constructed using bootstrap have higher coverage probability in all cases. These results\n",
      "further exemplify the gain of relative performance typically obtained by using the\n",
      "bootstrap technique. For visualization of the bootstrap CIs for four such replications,\n",
      "refer to Figure 2.6.\n",
      "n σ εcoverage of θ(x) coverage of E(θ(x))\n",
      "Bootstrap CI Asymptotic CI Bootstrap CI Asymptotic CI\n",
      "500 0.1 97.40 96.15 99.10 98.45\n",
      "1000 0.1 97.85 96.70 99.20 98.60\n",
      "2000 0.1 99.65 99.45 99.85 99.80\n",
      "500 1.0 92.85 89.95 93.90 92.30\n",
      "1000 1.0 93.20 89.40 93.30 91.30\n",
      "Table 2.2: The coverage of the true conditional median and expected value of the estimate\n",
      "over 100 replications\n",
      "Figure 2.6: Bootstrap CIs for the DGP given in equation (2.10), where the quantile RF is\n",
      "trained with n= 2000,τ= 0.05, and σ= 0.1, and evaluated for 100 test points. The plots\n",
      "show the true parameter (red points), estimated parameter (blue points) and pointwise CIs\n",
      "for bootstrap test statistic for four replications (black lines).\n",
      "GRF_effective_weights2D_bootstrap\n",
      "2.4.3 Uniform Confidence Bands\n",
      "In the next few simulations, the bootstrap method is extended to construct the UCB\n",
      "for the nonparametric estimates obtained from GRF. Let us begin with simple one-\n",
      "dimensional simulations and check the coverage of bootstrap confidence bands. Table\n",
      "2.3 summarizes the results corresponding to DGP of varying complexity including\n",
      "sinusoidal function with increasing periods. The sample size of 500 observations and\n",
      "100 replications are chosen to limit computing time, but ascertain that the properties\n",
      "of confidence bands across a variety of scenarios are highlighted. For comparison,2.5. APPLICATIONS 19\n",
      "the coverage of confidence bands with max of standard normal distribution are also\n",
      "reported in Table 2.3. The additional parameter hin the Table represents the minimum\n",
      "node size in the forest algorithm, and plays the role of bandwidth in the RF fits.\n",
      "DGP hBootstrap Asymptotic Bootstrap Asymptotic\n",
      "pointwise CI Uniform CB\n",
      "sin(8∗π∗x)5 87.75 88.00 82.00 83.00\n",
      "sin(5∗π∗x)5 92.10 92.35 96.00 96.00\n",
      "sin(3∗π∗x)5 92.15 92.60 96.00 97.00\n",
      "max(0 ,1− |x1|/0.2)5 92.85 92.60 96.00 96.00\n",
      "max(0 ,1− |x1|/0.2)3 91.60 91.65 95.00 95.00\n",
      "max(0 ,1− |x1|/0.2)1 90.30 90.50 90.00 87.00\n",
      "1 +x+ 2x2+ 3x35 92.15 92.55 96.00 96.00\n",
      "1 +x+ 2x2+ 3x33 91.50 91.50 96.00 95.00\n",
      "1 +x+ 2x2+ 3x31 90.30 90.35 87.00 86.00\n",
      "Table 2.3: Coverage of true parameter for various DGP and different minimum node sizes ( h)\n",
      "with n= 500,grids = 20,σ= 1, and 100replications\n",
      " GRF_1D_ucb\n",
      "We remark from the Table 2.3 that for forests with fully grown trees, the confidence\n",
      "bands obtained with bootstrap method provide better coverage. Consider, for example,\n",
      "the DGP with x∈[0,1.5]andy=sinx+ε,ε∼(0,1). The power curve and coverage\n",
      "for this DGP with changing node sizes ( h) are plotted in Figure 2.7. The left plot once\n",
      "again underlines that the bootstrap test statistics is as powerful as the asymptotic\n",
      "normal for n= 500. The plot on the right shows that for higher bandwidths and\n",
      "significance level of 0.05, the coverage of UCB is always greater than 95%. Figure 2.8\n",
      "visually demonstrates the pointwise CIs and UCB for the simulation setup x∈[0,1.5]\n",
      "andy= sin 8 x+εwith ε∼(0,0.12).\n",
      "To further evaluate the performance of the test statistics, various number of training\n",
      "points ( n), minimum node size ( h), equidistant points ( grids) and variance in the true\n",
      "function ( σ) are taken into account and corresponding size performance of asymptotic\n",
      "CIs, bootstrap CIs, asymptotic UCB, and bootstrap UCB are detailed in the Table\n",
      "2.4. The results are reassuring; in most of the cases, the size holds for bootstrap test\n",
      "statistic. In the cases where the size performance is lower than desired, taking a different\n",
      "bandwidth hor different grid size helps in reaching the desired size performance, see\n",
      "for example case 1-4.\n",
      "2.5 Applications\n",
      "2.5.1 Labor Force Participation\n",
      "Atheyetal.(2019)providestrongfoundationsforestimatinganyquantity θ(x)identified\n",
      "via local moment conditions using GRF and demonstrate its application to the US20 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "Figure 2.7: Power curve of the bootstrap test statistic (black line) and standard normal\n",
      "distribution (blue line) (left); the coverage of true parameter in bootstrap UCB (magenta)\n",
      "and bootstrap pointwise CIs (black) with different minimum node sizes ( h) (right)\n",
      "GRF_1D_ucb\n",
      "Figure 2.8: Bootstrap CIs for the DGP y=sin 8x+ε, where GRF regression forest is trained\n",
      "with n= 1000andσ= 0.1, and evaluated for 200 test points. The plots show the true\n",
      "parameter (red points), estimated parameter (blue points), pointwise CIs for bootstrap test\n",
      "statistic for four replications (black lines) and UCB (magenta lines)\n",
      " GRF_1D_ucb\n",
      "census bureau labor force participation rate 1980. The problem under considerations\n",
      "involves estimating the effect of having a third child (as a treatment) on a woman’s\n",
      "propensity to return to the labor force.\n",
      "The dataset consists of only married mothers with two or more children. Some of\n",
      "the covariates Xi∈Xfori= 1, . . . , nobservations in the dataset are age of mother\n",
      "at census, years of education of mother, race of mother, income of father etc. The\n",
      "treatment variable Ziis a binary variable, with 1 indicating that the mother has three\n",
      "or more children. The target variable Yi∈Ranswers whether or not the mother2.5. APPLICATIONS 21\n",
      "Case n grids h σBootstrap Asymptotic Bootstrap Asymptotic\n",
      "Pointwise CI Uniform CB\n",
      "1 500 20 5 1.0 0.068 0.067 0.040 0.040\n",
      "2 500 20 3 1.0 0.076 0.075 0.040 0.040\n",
      "3 500 20 2 1.0 0.089 0.083 0.060 0.060\n",
      "4 500 20 1 1.0 0.095 0.091 0.090 0.090\n",
      "5 500 20 5 0.5 0.070 0.067 0.030 0.040\n",
      "6 500 20 3 0.5 0.076 0.076 0.040 0.040\n",
      "7 500 20 1 0.5 0.099 0.093 0.100 0.100\n",
      "8 500 20 1 0.1 0.074 0.078 0.040 0.040\n",
      "9 500 50 5 0.1 0.076 0.075 0.090 0.080\n",
      "10 500 50 3 0.1 0.081 0.780 0.100 0.080\n",
      "11 500 50 1 0.1 0.100 0.090 0.190 0.210\n",
      "12 500 10 5 0.1 0.091 0.088 0.020 0.020\n",
      "13 500 10 3 0.1 0.093 0.098 0.030 0.020\n",
      "14 1000 20 1 0.1 0.090 0.089 0.050 0.060\n",
      "15 1000 20 1 10.0 0.095 0.092 0.050 0.070\n",
      "16 1000 20 10 1.0 0.059 0.060 0.010 0.000\n",
      "17 1000 20 15 1.0 0.066 0.064 0.000 0.000\n",
      "18 1000 50 15 1.0 0.064 0.061 0.000 0.000\n",
      "19 1000 100 1 1.0 0.100 0.090 0.350 0.350\n",
      "Table 2.4: Size performance of asymptotic CIs, bootstrap CIs, asymptotic UCB, and bootstrap\n",
      "UCB with varying training points ( n), minimum node size ( h), equidistant testing points\n",
      "(grids) and variance ( σ) of DGP\n",
      "re-participated in the labor force in the year before the census. In order to normalize the\n",
      "effect of auxiliary randomness in the treatment effect, the gender of first two children is\n",
      "identified as the instrument variable Wifollowing the study of J. D. Angrist and Evans\n",
      "(1998). This leads to two moment conditions E⌊Zi(Yi−Wiθ(x)−ν(x))|Xi=x⌋= 0\n",
      "andE|Yi−Wiθ(x)−ν(x)|Xi=x⌋= 0for estimation of the treatment effect θ. Here,\n",
      "the nuisance parameter ν(x)plays the role of intercept. Given the two moment\n",
      "conditions, the score function takes the form\n",
      "ψ1\n",
      "θˆ(x),νˆ(x)=Zi(︂\n",
      "Yi−Wiθˆ(x)−νˆ(x))︂\n",
      "=Zi(︂\n",
      "Yi−Yˆi)︂\n",
      "ψ2\n",
      "θˆ(x),νˆ(x)=Yi−Wiθˆ(x)−νˆ(x) =Yi−Yˆi\n",
      "V(x) =(︄\n",
      "E[ZiWi|Xi=x]E[Zi|Xi=x]\n",
      "E[Wi|Xi=x] 1)︄\n",
      "whereallquantitiesof V(x)canbeestimatedusingregressionforestandtheirpredictions\n",
      "are simply used as inputs to the GRF. Readers are recommended to see section 7 in\n",
      "Athey et al. (2019) for detailed explanation of the dataset.22 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      ".\n",
      "Figure 2.9: This figure is taken directly from Athey et al. (2019). The figure is captioned as\n",
      "\"Generalized random forest estimates (along with pointwise 95% CIs) for the causal effect\n",
      "of having a third child on the probability that a mother works for pay, as identified by the\n",
      "same sex instrument of J. D. Angrist and Evans (1998); a positive treatment effect means\n",
      "that the treatment reduces the probability that the mother works. We vary the mother’s age\n",
      "at first birth and the father’s income; other covariates are set to their median values in the\n",
      "above plots. The forest was grown with a sub-sample fraction s/n= 0.05, a minimum leaf\n",
      "sizek= 800, and consists of B = 100,000 trees\"\n",
      "The95%asymptotic pointwise CIs for GRF based conditional local average treatment\n",
      "effect (CLATE) estimates displayed in Figure 2.9 are taken directly from Athey et al.\n",
      "(2019). The study discusses that the observed treatment effect is driven by mothers\n",
      "whose husbands have a lower income. We undertake the task to check if the same\n",
      "conclusion holds under uniform inference by constructing UCB that allow multiple\n",
      "comparisons across the entire range of father’s income without compromising confidence\n",
      "levels.\n",
      "We can use Figure 2.10 to draw conclusions about the global shape of CLATE. Rather\n",
      "reassuringly, the left panel agrees to the conclusion provided in Athey et al. (2019)\n",
      "that the observed treatment effect is slightly driven by mothers whose husbands have\n",
      "a lower income. However, the right panel suggests that for the mothers of age 22, it\n",
      "can not be concluded that the treatment effect is driven by the father’s income. This\n",
      "analysis is very important when the policy makers want to analyse the treatment effect\n",
      "on the overall group, rather than just a subgroup, because even though treatment effect\n",
      "benefits exist for one small part of the group, others might not qualify for the benefits.\n",
      "In conclusion, we assert that the simultaneous CIs are indeed very useful in making\n",
      "multiple comparisons of the treatment means.\n",
      "As a second example for our study, we concern ourselves with estimation of conditional2.5. APPLICATIONS 23\n",
      "Figure 2.10: Generalized random forest estimates and corresponding 95% pointwise CIs -\n",
      "dotted dashed line. Also UCB - dashed line. The forest was grown with 100000 trees and\n",
      "sample fraction 0.05, and minimum leaf size is 800.\n",
      "probabilities for a credit default problem, indeed a very well studied problem in finance.\n",
      "The analysis for this problem is given in the next subsection.\n",
      "2.5.2 Credit Reform\n",
      "UCB can also provide new financial insights, specially on the problem of estimating the\n",
      "conditional default probability curve used for credit scoring. Credit scoring lies at the\n",
      "heart of financial analysis as it provides valuable information about the creditworthiness\n",
      "of companies, and helps prevent sudden crisis hits, the like of which were witnessed in\n",
      "2008.\n",
      "The rise in machine learning methods have also influenced financial risk analysts who\n",
      "use algorithms like RF to predict the credit risk. Even though classically used for\n",
      "classification problems, RF can also be used to predict the conditional probability\n",
      "of belonging to a specific group. In the case of a binary classification problem with\n",
      "a default outcome 1, the forests provide the probability p(x) =P(Y= 1|X=x)\n",
      "using some link function G(θ)or in simpler notation Gθ. Equivalently, Y=1(Y∗=\n",
      "θ(x) +ε >0), ε∼Gθ. Here, Gθcould be expressed in the form of logistic function\n",
      "p(x) = logistic( θ) =1\n",
      "1+exp( −θ).\n",
      "Using the likelihood function of the Bernoulli distribution, the score function is simply\n",
      "ψθ=yi−1\n",
      "1+exp( −θ), and V(x) =E(−Gθ(1−Gθ))which can be easily estimated using\n",
      "a regression forest, and ε˜i=−V−1ψθ0(Yi) =yi−Gθ0\n",
      "E(−Gθ(1−Gθ)).\n",
      "However, the conditional class probabilities from RF are obtained simply by counting\n",
      "the fraction of trees that vote for a certain class, they do not necessarily reflect the true\n",
      "conditional probabilities (Kruppa et al., 2014). Therefore, it is primal to characterize24 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "the uncertainty in them in order to reliably estimate the cost of decision rules when\n",
      "applied to an unlabeled dataset. Furthermore, UCB become especially relevant when\n",
      "limited data is available for estimation and the analysis suffer from insufficient data\n",
      "from the default category.\n",
      "Traditionally, liquidity ratios, debt management ratios, asset management ratios, as\n",
      "well as profitability ratios have been used to determine the financial well-being of the\n",
      "institutions. For our analysis, we use the same dimensions to analyse the credit risk\n",
      "and calculate ten different ratios in order to cover these dimensions. We use a unique\n",
      "dataset from the credit reform database of n= 53000 financial institutions in Germany\n",
      "from last 10 years provided by the Research Data Center (RDC) and available on\n",
      "Blockchain Research Center (BRC) of the Humboldt-Universität zu Berlin. Details of\n",
      "the variables as well as calculated financial ratios can be found in Table 2.5 and Table\n",
      "2.6 respectively. The grf::probability.forest is used to estimate the conditional class\n",
      "probabilities for default class ( label = 1).\n",
      "Variable Description Variable Description\n",
      "T2 indicator(solvent=0)\n",
      "var1 cash var2 inventories\n",
      "var3 current assets var4 tangible assets\n",
      "var5 intangible assets var6 total assets\n",
      "var7 accounts receivable var8 lands and buildings\n",
      "var9 equity var10 accrual for pension liabilities\n",
      "var11 total current liabilities var12 total long term liabilities\n",
      "var13 bank debt var14 accounts payable\n",
      "var15 sales var16 amortization depreciation\n",
      "var17 interest expenses var18 EBIT\n",
      "var19 operating income var20 net income\n",
      "var21 increase inventories var22 increase liabilities\n",
      "var23 increase cash var24 number employees\n",
      "Table 2.5: Description of the variables for the credit reform database\n",
      "In order to identify the dimension that matters the most, we use a simple weighted\n",
      "sum of how many times a feature was split on at each depth in the forest to get the\n",
      "importance measure corresponding to each ratio. Net Profitability Margin (NPM) is\n",
      "suggested as the most relevant classification dimension, and is indeed one the most\n",
      "closely followed ratios by the shareholders. NPM shows a firm’s ability to generate\n",
      "net income through its sales. Primarily, the fundamental line of defense of a company\n",
      "against debtor, market, operational, and company risk losses is its recurring profitability.\n",
      "If a company’s potential to generate income is not substantial, its ability to safeguard\n",
      "its creditors from risk is affected. Hence the NPM is considered one of the main\n",
      "determinant of the success or failure of a company. Consequently, many business2.5. APPLICATIONS 25\n",
      "Type Ratio Formula\n",
      "Debt Management Ratio Debt to Equity bank debt / equity\n",
      "Debt Management Ratio Basic Earning Power EBIT / total assets\n",
      "Asset Management Ratio Inventory Turnover sales / inventories\n",
      "Asset Management Ratio Asset Turnover sales / total assets\n",
      "Liquidity Ratio Quick Ratio cash / current liabilities\n",
      "Liquidity Ratio Net Working Capital current assets-current liabilities\n",
      "Liquidity Ratio Current Ratio current assets/current liabilities\n",
      "Profitability Ratio Return on Assets net income / total asstes\n",
      "Profitability Ratio Return on Equity net income / equity\n",
      "Profitability Ratio Net Profit Margin net income / sales\n",
      "Table 2.6: Description of ten financial ratios that are calculated using the variables in credit\n",
      "reform database.\n",
      "Figure 2.11: Conditional class probability estimates for the default class obtained from GRF\n",
      "and corresponding 95% pointwise CIs - dotted blue line. Also UCB - dotted red line. The\n",
      "forest was grown with 1000 trees\n",
      "models suggest to grants loans to the companies with higher NPM. Given the non-\n",
      "linearities and unknown high dimensional structures in financial datasets, one could\n",
      "check the validity of this hypothesis using UCB.\n",
      "With the score function ψθ=yi−1\n",
      "1+exp( −θ), and V(x) =E(−Gθ(1−Gθ))estimated\n",
      "using a regression forest, we use the test statistics 2.6 to construct the UCB around\n",
      "the conditional probability of default class shown in Figure 2.11.\n",
      "The plot in Figure 2.11 reveals that while the forests classify the firms with negative\n",
      "NMP as default with high certainty, for positive NPM, the results are rather counter-\n",
      "intuitive. It is usually assumed that higher the profitability, the better it is. However,\n",
      "the figure shows that even though for positive NPM, the default probability drops\n",
      "suddenly, there is high uncertainty in the estimated probability, with both 0 and 126 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "probability in the UCB. This reemphasizes that discriminating between good and bad\n",
      "firms based on profitability ratios alone might be misleading. The investors should\n",
      "rather actively observe the change in NPM to gain more information about a company’s\n",
      "credit risk.\n",
      "2.6 Conclusion\n",
      "RF are a powerful tool of nonparametric data science and have been studied intensively\n",
      "for their theoretical properties and applicability in many scientific fields. Among the\n",
      "newest insights into their asymptotics are extensions towards GRF where the central\n",
      "limit theorem allows studying pointwise influence of features/variables. In this research,\n",
      "we extend these findings towards uniform convergence, hence allowing to check whether\n",
      "one observes significant effects over a range of feature values. We find critical values for\n",
      "the UCB using multiplier bootstrap, since it is well known that the standard approach\n",
      "via extreme value theory has a very slow asymptotic. Numerical simulations verify\n",
      "that this ’wild bootstrap’ like method provides reliable results and coverage, even in\n",
      "small samples. As a real life application, we extend the labor force example provided\n",
      "in Athey et al. (2019) and find using UCB that the father’s low income doesn’t always\n",
      "drive the conditional local average treatment effect of mother returning to the labor\n",
      "force after having a third child. In addition, we consider a credit scoring application\n",
      "which lies at the heart of financial analysis and find that higher profitability doesn’t\n",
      "provide any financial institution a direct ticket to non-default category.\n",
      "2.7 Appendix\n",
      "2.7.1Forest Specification and Assumptions Required for Point-\n",
      "wise Results\n",
      "Specification 1. All trees are symmetric, in that their output is invariant to permuting\n",
      "the indices of training examples; make balanced splits, in the sense that every split\n",
      "puts at least a fraction wof the observations in the parent node into each child, for\n",
      "some w >0; and are randomized in such a way that, at every split, the probability that\n",
      "the tree splits on the j-th feature is bounded from below by some π >0. The forest is\n",
      "honest and built via subsampling with subsample size ssatisfying s/n→0ands→ ∞.\n",
      "In particular, we assume that sis of polynomial order s=nβfor some βmin< β < 1,\n",
      "with\n",
      "βmindef= 1−{︁\n",
      "1 +π−1log(w−1)/︁\n",
      "log((1 −w)−1)}︁−1< β < 1.(2.11)\n",
      "Assumption 2.7.1 (Lipschitz x-signal).For fixed values of (θ, ν), we assume that the\n",
      "expected score function Mθ,ν(x) =E[ψθ,ν(O)|X=x]is Lipschitz continuous in x.\n",
      "Assumption 2.7.2 (Smooth identification) .When xis fixed, we assume that Mθ,ν(x)2.7. APPENDIX 27\n",
      "is twice continuously differentiable in (θ, ν)with a uniformly bounded second derivative,\n",
      "and that V(x)is invertible for all x∈ X.\n",
      "Assumption 2.7.3 (Lipschitz (θ, ν)-variogram) .The score functions ψθ,ν(Oi)have a\n",
      "continuous covariance structure. Writing γfor the worst-case variogram and ∥ · ∥ Ffor\n",
      "the Frobenius norm, then for some C >0,\n",
      "γ(︄(︄\n",
      "θ\n",
      "ν)︄\n",
      ",(︄\n",
      "θ′\n",
      "ν′)︄)︄\n",
      "≤C⃦⃦⃦⃦⃦(︄\n",
      "θ\n",
      "ν)︄\n",
      "−(︄\n",
      "θ′\n",
      "ν′)︄⃦⃦⃦⃦⃦\n",
      "2for all (θ, ν),(θ′, ν′),\n",
      "γ(︄(︄\n",
      "θ\n",
      "ν)︄\n",
      ",(︄\n",
      "θ′\n",
      "ν′)︄)︄\n",
      "def= sup\n",
      "x∈X{︁\n",
      "∥Var [ψθ,ν(Oi)−ψθ′,ν′(Oi)|Xi=x]∥F}︁\n",
      ".\n",
      "Assumption 2.7.4 (Regularity of the score) .The score functions can be written\n",
      "asψθ,ν(Oi) =λ(θ, ν;Oi)+ιθ,ν(g(Oi)), such that λis Lipschitz-continuous in (θ, ν),\n",
      "g:{Oi} →Ris a univariate summary of Oi, and ιθ,ν:R→Ris any family of\n",
      "monotone and bounded functions.\n",
      "Assumption 2.7.5 (Existence of solutions) .We assume that, ∀x∈ X, for any\n",
      "weights αi(x)such that∑︁n\n",
      "i=1αi(x) = 1, the estimation in (2.3)returns a minimizer\n",
      "(θˆn(x), νˆn(x))that approximately solves ∥∑︁n\n",
      "i=1αi(x)ψθˆn(x),νˆn(x)(Oi)∥2≤Cmax\n",
      "1≤i≤naifor\n",
      "some C≥0.\n",
      "Assumption 2.7.6 (Convexity) .The score function ψθ,ν(Oi)is a negative subgradient\n",
      "of a convex function, and the expected score Mθ,ν(Xi)is the negative gradient of a\n",
      "strongly convex function.\n",
      "2.7.2 Detailed Proofs\n",
      "Proof of Lemma 2.2.1. The sketch of the proof follows that of Lemma 4 in Athey et al.\n",
      "(2019) with an extension of the uniformity.\n",
      "Step1:Define Ψ(θ, ν) =∑︁n\n",
      "i=1αi(x)ψθ,ν(Oi),Ψ(θ, ν) =∑︁n\n",
      "i=1αi(x)Mθ,ν(Xi),Ψ(θ, ν)−\n",
      "Ψ(θ, ν)− {Ψ(θ′, ν′)−Ψ(θ′, ν′)}=ρ((θ, ν),(θ′, ν′)). We have\n",
      "Ψ(θˆn(x), νˆn(x))−Ψ(θ(x), ν(x))\n",
      "= Ψ( θˆn(x), νˆn(x))−Ψ(θ(x), ν(x)) +ρ((θ(x), ν(x)),(θˆn(x), νˆn(x)))\n",
      "=V(x)(︄\n",
      "θˆn(x)−θ(x)\n",
      "νˆn(x)−ν(x))︄\n",
      "+{︃n∑︂\n",
      "i=1αi(x)∇Mθ(x),ν(x)(Xi)−V(x)}︃(︄\n",
      "θˆn(x)−θ(x)\n",
      "νˆn(x)−ν(x))︄\n",
      "+H,\n",
      "where the second equation is implied by a Taylor expansion on Ψ, which is twice\n",
      "differentiable in (θ, ν)with a bounded second derivative uniformly over all realizations28 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "ofαi(x)andXi. Recall the definitions ϑˆn(x) =(︄\n",
      "θˆn(x)\n",
      "νˆn(x))︄\n",
      ",ϑ(x) =(︄\n",
      "θ(x)\n",
      "ν(x))︄\n",
      ". It follows\n",
      "that\n",
      "ϑˆn(x)−ϑ(x) +V(x)−1Ψ(ϑ(x))\n",
      "=V(x)−1[︃\n",
      "H−Ψ(ϑˆn(x))−ρ(ϑˆn(x), ϑ(x)) +{︃n∑︂\n",
      "i=1αi(x)∇Mθ(x),ν(x)(Xi)−V(x)}︃{︁\n",
      "ϑˆn(x)−ϑ(x)}︁]︃\n",
      ",\n",
      "provided that V(x)is invertible for all x∈ X(by Assumption 2.7.2). Moreover,\n",
      "according to the proof of Theorem 3 of Wager and Athey (2018), the weights αi(x)are\n",
      "localized in the sense that\n",
      "E[︂\n",
      "sup\n",
      "x∈X{∥Xi−x∥2:αi(x)>0}]︂\n",
      "=O(︂\n",
      "s−πlog((1−w)−1)\n",
      "2 log( w−1))︂\n",
      ",\n",
      "which directly gives us\n",
      "sup\n",
      "1≤l≤Ln⃦⃦⃦⃦n∑︂\n",
      "i=1αi(xl)∇Mθ(x),ν(x)(Xi)−V(xl)⃦⃦⃦⃦\n",
      "F=OP(︂\n",
      "s−πlog((1−w)−1)\n",
      "2 log( w−1))︂\n",
      ".\n",
      "Step2:Next, buildingonthepointwiseconsistency ∥ϑˆn(x)−ϑ(x)∥2=OP(1)(byTheorem\n",
      "3ofAtheyetal.(2019)), wewanttoprovetheuniformconsistency sup\n",
      "x∈X∥ϑˆn(x)−ϑ(x)∥2=\n",
      "OP(1), which implies that sup\n",
      "1≤l≤Ln∥ϑˆn(x)−ϑ(x)∥2=OP(1).\n",
      "Given any η1, η2>0, by Assumption 2.2.1, we have\n",
      "P(︂\n",
      "sup\n",
      "∥x−x′∥2<δ1∥ϑˆn(x)−ϑˆn(x′)∥2> η 1)︂\n",
      "≤P(︂\n",
      "Bn× sup\n",
      "∥x−x′∥2<δ1h(∥x−x′∥2)> η 1))︂\n",
      "≤P(Bnh(δ1)> η 1).\n",
      "Since Bn=OP(1), there exist some K > 0such that P(Bn> Kη 1)< η 2, for sufficiently\n",
      "large n. By picking δ1>0such that h(δ1)≤1/K, for sufficiently large n, we have the\n",
      "stochastic equicontinuity of ϑˆn(x):\n",
      "P(︂\n",
      "sup\n",
      "∥x−x′∥2<δ1∥ϑˆn(x)−ϑˆn(x′)∥2> η 1)︂\n",
      "≤P(Bn/K > η 1)< η 2.(2.12)\n",
      "Given any η, η′>0, there exists δ >0such that for large n, by(2.12)and uniform\n",
      "continuity of ϑ(x), we have\n",
      "P(︂\n",
      "sup\n",
      "∥x−x′∥2<δ∥ϑˆn(x)−ϑˆn(x′)∥2> η/3)︂\n",
      "< η′2, (2.13)2.7. APPENDIX 29\n",
      "sup\n",
      "∥x−x′∥2<δ∥ϑ(x)−ϑ(x′)∥2< η/3< η′/2 (2.14)\n",
      "Define Bδ(xk) ={x∈ X :∥x−xk∥2< δ}. Since Xis compact, there exist finite\n",
      "collection of Bδ(x1), . . . , B δ(xK)such that X ⊂K⋃︁\n",
      "k=1Bδ(xk). Moreover, by the pointwise\n",
      "consistency, for each xk, we have\n",
      "P(∥ϑˆn(xk)−ϑ(xk)∥2> η/3)→0,asn→ ∞ .\n",
      "Thus, for large n, since Kis finite, it follows that\n",
      "P(︂\n",
      "max\n",
      "k∈{1,...,K}∥ϑˆn(xk)−ϑ(xk)∥2> η/3)︂\n",
      "≤K∑︂\n",
      "k=1P(∥ϑˆn(xk)−ϑ(xk)∥2> η/3)< η′/2.\n",
      "(2.15)\n",
      "For any x∈Bδ(xk), i.e.∥x−xk∥2< δ, we have\n",
      "∥ϑˆn(x)−ϑ(x)∥2≤ ∥ϑˆn(x)−ϑˆn(xk)∥2+∥ϑ(xk)−ϑ(x)∥2+∥ϑˆn(xk)−ϑ(xk)∥2.\n",
      "Due to(2.14), if∥ϑˆn(x)−ϑ(x)∥2> η, then either ∥ϑˆn(x)−ϑˆn(xk)∥2> ηor∥ϑˆn(xk)−\n",
      "ϑ(xk)∥2> η(or both) holds true. By combining (2.13) and (2.15), we have\n",
      "P(︂\n",
      "sup\n",
      "x∈X∥ϑˆn(x)−ϑ(x)∥2> η)︂\n",
      "≤P(︂\n",
      "max\n",
      "k∈{1,...,K}sup\n",
      "x∈Bδ(xk)∥ϑˆn(x)−ϑ(x)∥2> η)︂\n",
      "≤P(︂\n",
      "max\n",
      "k∈{1,...,K}sup\n",
      "x∈Bδ(xk)∥ϑˆn(x)−ϑˆn(xk)∥2> η/3)︂\n",
      "+ P(︂\n",
      "max\n",
      "k∈{1,...,K}∥ϑˆn(xk)−ϑ(xk)∥2> η/3)︂\n",
      "< η′,for large n.\n",
      "Since η, η′>0are arbitrary, we have shown that sup\n",
      "x∈X∥ϑˆn(x)−ϑ(x)∥2=OP(1), i.e.\n",
      "there exists ϵn→0such that sup\n",
      "x∈X∥ϑˆn(x)−ϑ(x)∥2=OP(ϵn).\n",
      "Step3:Lastly, we are left to bound the extraneous terms. By Assumption 2.7.2,\n",
      "we have ∥H∥ ≤ cϵ2\n",
      "n/2for some constant c > 0related to the uniform bound on\n",
      "on the second derivative of M. In addition, by Assumption 2.7.5, we obtain that\n",
      "sup\n",
      "1≤l≤LnΨ(θˆn(x), νˆn(x))≤Cmax\n",
      "1≤i≤nai≤Cs/n, for some C≥0.\n",
      "For a sequence of positive constants ρn, by the Union bound and Markov inequality,30 CHAPTER 2. UNIFORM CONFIDENCE BANDS FOR GRF\n",
      "we have\n",
      "P(︂\n",
      "sup\n",
      "1≤l≤Ln∥ρ(ϑˆn(xl), ϑ(xl))∥2> ρ n)︂\n",
      "≤LnP(︁\n",
      "∥ρ(ϑˆn(xl), ϑ(xl))∥2> ρ n)︁\n",
      "≤LnE(︁\n",
      "∥ρ(ϑˆn(xl), ϑ(xl))∥2)︁\n",
      "ρn.\n",
      "Applying Lemma 9 in Athey et al. (2019) with η=ϵ2/3\n",
      "ngives\n",
      "E(︁\n",
      "∥ρ(ϑˆn(xl), ϑ(xl))∥2)︁\n",
      "=O(︁\n",
      "max{︁\n",
      "ϵ1/3\n",
      "n√︁\n",
      "s/n, ε−2/3\n",
      "ns/n}︁)︁\n",
      ".\n",
      "Consequently, with properly chosen ρn, we would get\n",
      "sup\n",
      "1≤l≤Ln∥ρ(ϑˆn(xl), ϑ(xl))∥2≲Pmax{︁\n",
      "Lnϵ1/3\n",
      "n√︁\n",
      "s/n, L nε−2/3\n",
      "ns/n}︁\n",
      ".\n",
      "By combing what we have shown, we conclude that\n",
      "sup\n",
      "1≤l≤Ln⃦⃦ϑˆn(xl)−ϑ(xl)+V(xl)−1Ψ(ϑ(xl))⃦⃦\n",
      "2=OP(︁\n",
      "max{︁\n",
      "s−πlog((1−w)−1)\n",
      "2 log( w−1)ϵn, ϵ2\n",
      "n, Lnϵ1/3\n",
      "n√︁\n",
      "s/n, L nε−2/3\n",
      "ns/n}︁)︁\n",
      ".\n",
      "Meanwhile, we can similarly extend Lemma 7 of Athey et al. (2019) for the uniform case\n",
      "and obtain that sup\n",
      "1≤l≤Ln∥Ψ(ϑ(xl))∥2=OP(︁√︁\n",
      "s/nL n)︁\n",
      "by(2.11). Thus, the estimator\n",
      "ϑˆn(x)is√︁\n",
      "s/nL n-consistentuniformlyoverthecovariatespace Xgiven Ln≪(s/n)−1/2.\n",
      "By letting ϵn=√︁\n",
      "s/nL n, we have\n",
      "sup\n",
      "1≤l≤Ln⃓⃓⃓⃓θˆn(xl)−θ(xl)−n∑︂\n",
      "i=1αi(xl)ε˜i(xl)⃓⃓⃓⃓=OP(︁\n",
      "max{︁\n",
      "s−πlog((1−w)−1)\n",
      "2 log( w−1)Ln(s/n)1/2, L4/3\n",
      "n(s/n)2/3}︁)︁\n",
      ".\n",
      "Proof of Lemma 2.3.1. By Triangle inequality, we have sup\n",
      "α∈(0,1)|P(|ζ˜n|∞≥q∗\n",
      "n(1−α))−\n",
      "α| ≤ρ⊖+ρ, where\n",
      "ρ⊖= sup\n",
      "α∈(0,1)P(︁\n",
      "{|ζ˜n|∞≥q∗\n",
      "n(1−α)} ⊖ {| ζn|∞≥cn(1−α)})︁\n",
      ",\n",
      "ρ= sup\n",
      "r≥0|P(|Zn|∞≥r)−P(|ζn|∞≥r)|,\n",
      "where the symmetric difference between two sets AandBis denoted by A⊖B=\n",
      "(A\\B)∪(B\\A).\n",
      "By the asymptotic normality derived in Theorem 1 of Wager and Athey (2018), weBibliography 31\n",
      "know that ρ→0asn→ ∞. Furthermore, according to Theorem 3.2 and Corollary\n",
      "3.1 in Chernozhukov et al. (2013), we have ρ⊖=C1n−c1for some constants c, C > 0,\n",
      "which implies the desired result of multiplier bootstrap validity.\n",
      "Bibliography\n",
      "Angrist, J., Chernozhukov, V., Fernández-val, I., Lancaster, T., Lewbel, A., & Partici-\n",
      "pants, S. (2006). Quantile regression under misspecification, with an application\n",
      "to the u.s wage structure. Econometrica , 563.\n",
      "Angrist, J. D., & Evans, W. N. (1998). Children and Their Parents’ Labor Supply: Evi-\n",
      "dence from Exogenous Variation in Family Size [Publisher: American Economic\n",
      "Association]. The American Economic Review ,88(3), 450–477.\n",
      "Arlot, S., & Genuer, R. (2014). Analysis of purely random forests bias [arXiv: 1407.3939].\n",
      "arXiv:1407.3939 [cs, math, stat] .\n",
      "Athey, S., Tibshirani, J., & Wager, S. (2019). Generalized random forests [Publisher:\n",
      "Institute of Mathematical Statistics]. The Annals of Statistics ,47(2), 1148–1178.\n",
      "https://doi.org/10.1214/18-AOS1709\n",
      "Biau, G. (2010). Analysis of a Random Forests Model. Journal of Machine Learning\n",
      "Research ,13.\n",
      "Biau, G., Devroye, L., & Lugosi, G. (2008). Consistency of Random Forests and Other\n",
      "Averaging Classifiers. Journal of Machine Learning Research ,9, 2015–2033.\n",
      "https://doi.org/10.1145/1390681.1442799\n",
      "Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A. (1984). Classification and\n",
      "Regression Trees . Taylor & Francis.\n",
      "Ćevid, D., Michel, L., Näf, J., Meinshausen, N., & Bühlmann, P. (2020). Distribu-\n",
      "tional random forests: Heterogeneity adjustment and multivariate distributional\n",
      "regression. arXiv preprint arXiv:2005.14458 .\n",
      "Chernozhukov, V., Chetverikov, D., & Kato, K. (2013). Gaussian approximations and\n",
      "multiplier bootstrap for maxima of sums of high-dimensional random vectors.\n",
      "The Annals of Statistics ,41(6), 2786–2819.\n",
      "Denil, M., Matheson, D., & De Freitas, N. (2014). Narrowing the gap: Random forests\n",
      "in theory and in practice. Proceedings of the 31st International Conference on\n",
      "International Conference on Machine Learning - Volume 32 , I–665–I–673.\n",
      "Efron, B., & Stein, C. (1981). The Jackknife Estimate of Variance. The Annals of\n",
      "Statistics ,9(3), 586–596. https://doi.org/10.1214/aos/1176345462\n",
      "Hall, P. (1991). Edgeworth expansions for nonparametric density estimators, with appli-\n",
      "cations[Publisher:Taylor&Francis_eprint:https://doi.org/10.1080/02331889108802305].\n",
      "Statistics ,22(2), 215–232. https://doi.org/10.1080/02331889108802305\n",
      "Hardle, W., & Mammen, E. (1993). Comparing nonparametric versus parametric\n",
      "regression fits. The Annals of Statistics ,21(4), 1926–1947.32 Bibliography\n",
      "Härdle, W., Ritov, Y., & Wang, W. (2015). Tie the straps: Uniform bootstrap confidence\n",
      "bands for semiparametric additive models. J. Multivar. Anal. https://doi.org/\n",
      "10.1016/j.jmva.2014.11.003\n",
      "Härdle, W. K., & Marron, J. S. (1991). Bootstrap Simultaneous Error Bars for Non-\n",
      "parametric Regression [Publisher: Institute of Mathematical Statistics]. The\n",
      "Annals of Statistics ,19(2), 778–796. https://doi.org/10.1214/aos/1176348120\n",
      "Härdle,W.(1989).AsymptoticmaximaldeviationofM-smoothers. Journal of Multivari-\n",
      "ate Analysis ,29(2), 163–179. https://doi.org/10.1016/0047-259X(89)90022-5\n",
      "Härdle, W. K., Okhrin, Y., & Wang, W. (2015). Uniform Confidence Bands for Pricing\n",
      "Kernels [Publisher: Society for Financial Econometrics]. Journal of Financial\n",
      "Econometrics ,13(2), 376–413.\n",
      "Härdle, W. K., & Song, S. (2010). Confidence bands in quantile regression. Econometric\n",
      "Theory,26, 1180–1200. https://doi.org/10.1017/S0266466609990491\n",
      "Hoeffding, W. (1948). A Class of Statistics with Asymptotically Normal Distribution.\n",
      "The Annals of Mathematical Statistics ,19(3), 293–325. https://doi.org/10.1214/\n",
      "aoms/1177730196\n",
      "Horowitz,J.L.(2001). Chapter52-thebootstrap.InJ.J.Heckman&E.Leamer(Eds.),\n",
      "Handbook of econometrics (pp. 3159–3228). Elsevier. https://doi.org/https:\n",
      "//doi.org/10.1016/S1573-4412(01)05005-X\n",
      "Horowitz, J. L., & Manski, C. F. (2000). Nonparametric Analysis of Randomized\n",
      "Experiments with Missing Covariate and Outcome Data [Publisher: [Ameri-\n",
      "can Statistical Association, Taylor & Francis, Ltd.]]. Journal of the American\n",
      "Statistical Association ,95(449), 77–84. https://doi.org/10.2307/2669526\n",
      "Kruppa, J., Liu, Y., Biau, G., Kohler, M., König, I. R., Malley, J. D., & Ziegler, A.\n",
      "(2014). Probability estimation with machine learning methods for dichotomous\n",
      "and multicategory outcome: Theory. Biometrical Journal ,56(4), 534–563. https:\n",
      "//doi.org/https://doi.org/10.1002/bimj.201300068\n",
      "Lin, Y., & Jeon, Y. (2006). Random Forests and Adaptive Nearest Neighbors [Publisher:\n",
      "[American Statistical Association, Taylor & Francis, Ltd.]]. Journal of the\n",
      "American Statistical Association ,101(474), 578–590.\n",
      "Mentch, L., & Hooker, G. (2016). Quantifying Uncertainty in Random Forests via Con-\n",
      "fidence Intervals and Hypothesis Tests. Journal of Machine Learning Research ,\n",
      "17(26), 1–41.\n",
      "Scornet, E., Biau, G., & Vert, J. -P. (2015). Consistency of random forests [Publisher:\n",
      "Institute of Mathematical Statistics]. The Annals of Statistics ,43(4), 1716–1741.\n",
      "https://doi.org/10.1214/15-AOS1321\n",
      "Song, S., Ritov, Y., & Härdle, W. K. (2012). Bootstrap confidence bands and partial\n",
      "linear quantile regression. Journal of Multivariate Analysis ,107, 244–262. https:\n",
      "//doi.org/https://doi.org/10.1016/j.jmva.2012.01.020Bibliography 33\n",
      "Spokoiny, V., & Zhilova, M. (2015). Bootstrap confidence sets under model misspeci-\n",
      "fication [Publisher: Institute of Mathematical Statistics]. Annals of Statistics ,\n",
      "43(6), 2653–2675. https://doi.org/10.1214/15-AOS1355\n",
      "Wager, S., & Athey, S. (2018). Estimation and Inference of Heterogeneous Treat-\n",
      "ment Effects using Random Forests [Publisher: Taylor & Francis _eprint:\n",
      "https://doi.org/10.1080/01621459.2017.1319839]. Journal of the American Sta-\n",
      "tistical Association ,113(523), 1228–1242. https://doi.org/10.1080/01621459.\n",
      "2017.1319839\n",
      "Wager, S., & Walther, G. (2016). Adaptive Concentration of Regression Trees, with\n",
      "Application to Random Forests [arXiv: 1503.06388]. arXiv:1503.06388 [math,\n",
      "stat].Chapter 3\n",
      "DataAnalyticsDrivenControlling: bridg-\n",
      "ing statistical modeling and managerial\n",
      "intuition\n",
      "Publication\n",
      "This paper has been submitted to Management Science.\n",
      "3.1 Introduction\n",
      "There is no doubt that historical data and managerial experience remain crucial factors\n",
      "in corporate decision making processes. However, past information is largely subject\n",
      "to fluctuations due to ever-changing circumstances. Predicting merger & acquisitions\n",
      "(M&As), a task that lies at the heart of strategic management, also remains challenging\n",
      "due to the fluctuations caused by their wave like market behavior (Harford, 2005).\n",
      "The resulting non-stationarity makes traditional time series models inapplicable. We\n",
      "introduce a method to find the stationary span within the recent past that can be\n",
      "safely used for making decisions about the near future and show how it can be used on\n",
      "the example of M&A activity in several German industries.\n",
      "The method in this paper essentially proposes a new way of thinking about the\n",
      "occurrence of M&A events. It differs from previous approaches as it (I) only uses\n",
      "the assumption that there exist stationary intervals within the time series, (II) works\n",
      "even with very small sample sizes, (III) does not require a specification of a sample\n",
      "horizon, or the number and nature of different states, (IV) does not require manual\n",
      "inputs or data screening as it is fully automated, and thus does not introduce a bias or\n",
      "misspecification through human interaction, (V) the proposed approach is not only a\n",
      "stand-alone method, but also serves as an extension to models like ARIMA: we can\n",
      "identify intervals within the time series where the model assumptions are met. Finally,\n",
      "we apply the procedure to the often overlooked non US markets.\n",
      "Past research has often focused on M&As US markets exclusively. For example, Very\n",
      "et al. (2012) comprehensively discusses applications of the most common approaches\n",
      "343.1. INTRODUCTION 35\n",
      "ARIMA and Markov Switching Models on M&As in US Markets. Unfortunately, these\n",
      "approaches can not easily be generalized to non US markets. Consider Figure 3.1, which\n",
      "depicts the number of M&As in the German energy market. It shows the wave like\n",
      "behavior of M&As and the presence of non-stationarity in such time series. To overcome\n",
      "these problems, consider other business problems that are commonly described by\n",
      "count data models. Typical examples are call center arrivals or supply chains. Instead\n",
      "of using a time series approach, they often simulate from the event distribution that is\n",
      "assumed to be Poisson. Unlike these examples, the wave like behavior in M&A time\n",
      "series however distorts the distribution. Figure 3.2 illustrates the total distribution,\n",
      "with a yellow line to describe the 95th percentile of the distribution. While the majority\n",
      "of observations are between 0 and 7, and could follow a Poisson distribution, merger\n",
      "waves generate some heavy outliers that follow a different law.\n",
      "Figure 3.1: Time series of count of M&As per month / energy sector of Germany (blue), with\n",
      "moving average curve of 1 year (green) and 3 years (orange).\n",
      " LPA_Empiricalstudy\n",
      "Bianchi and Chiarella (2018) underlines the importance of accounting for the time-\n",
      "varying dynamics of M&As, but their method requires careful specification of the\n",
      "underlying parameters, which usually change over time. This problem can be avoided\n",
      "by using a subset with stable windows to separate different periods of activity. We take\n",
      "advantage of the fact that within a time series there are always intervals where the\n",
      "parameter doesn’t change. Hence, we can detect locally homogeneous time windows\n",
      "within the time series where a stable distribution can be assumed. However, such\n",
      "selection is often done by hand, as it is challenging to describe the different states using\n",
      "statistical methods. Such approaches are neither scalable, nor adaptive.36 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "Figure 3.2: Distribution of count of M&As per month for the energy sector (GER), and tail\n",
      "of distribution (95th percentile) indicated by yellow line.\n",
      " LPA_Empiricalstudy\n",
      "Look again at Figure 3.1. It indicates that selecting a stable window by hand is\n",
      "not always optimal. Taking small intervals like one year for parameterizing the time\n",
      "series shows high variance (instability), whereas taking longer intervals like 3 years can\n",
      "introduce a high bias due to the time varying nature of the parameter. Our method\n",
      "allows to balance the trade-off between variance and bias by providing a practical\n",
      "technique that chooses the appropriate interval within the time series. Using the\n",
      "parameter information from the latest homogeneous window, managers can forecast\n",
      "the evolution of mergers & acquisitions accurately and in a fully automated fashion.\n",
      "Our results show that the procedure generates reliable forecasts in the studied markets\n",
      "(telecommunication, energy, financials), and reveal that the dynamics of these industries\n",
      "have distinct characteristics that need careful consideration during model selection.\n",
      "We employ an adaptive estimation method called Local Parametric Approach (LPA)\n",
      "following V. Spokoiny (2009) to account for the heterogeneous nature of the different\n",
      "industries, and to deem manual parameterization unnecessary. It helps us find locally\n",
      "homogeneous time intervals with stable parameters and guarantees a trade-off between\n",
      "parameter variance and modeling bias. The technique is based on a series of likelihood\n",
      "ratio tests to determine assumed but unknown change points in the underlying series.\n",
      "As a result one finds local intervals of homogeneity and efficient estimates at each point\n",
      "in time.\n",
      "Since we are often dealing with small sample sizes, and the test statistic used in our\n",
      "methodhasanunknowndistribution, weneedamethodtoapproximatethisdistribution.3.2. RELATED WORK 37\n",
      "Recent advances in bootstrapping methodology allow us to generate confidence sets\n",
      "and critical values that non-asymptotically approximate the true distribution. Here,\n",
      "we couple LPA with multiplier bootstrap (MBS) (V. Spokoiny & Zhilova, 2015) for\n",
      "approximating a critical value for the testing procedure.\n",
      "Comparing the forecast accuracy to commonly used methods shows that our model\n",
      "can generate accurate forecasts without the need for parameterization, or any manual\n",
      "input. Additionally, we highlight that even though ARIMA models have high accuracy,\n",
      "the best fit ARIMA model frequently changes within different various intervals of the\n",
      "time series. In terms of MSE (mean squared error) our approach is more accurate\n",
      "than using simpler metrics such as a 12 or 36 month moving averages in the financial\n",
      "and telecommunication industries. Only the energy was better approximated using\n",
      "moving averages. However, even in such cases our approach could be used as a guideline\n",
      "for selecting an appropriate interval making forecasts with ARIMA models. This is\n",
      "more accurate than using moving averages while maintaining a balance in the bias-\n",
      "variance trade-off. Re-thinking the way that M&A events occur helps us in making\n",
      "better predictions by using novel statistical methods and thus helping managers and\n",
      "controllers to make better decisions using data analytics driven insights.\n",
      "The remainder of this paper is structured as follows: section 3.2 discusses related work.\n",
      "section 3.3 describes the algorithm that is based on a combination of LPA, MBS and\n",
      "put into action in an iterative procedure. section 3.4 contains an experimental study.\n",
      "We describe the evaluation method, verify the robustness of the presented algorithm in\n",
      "simulation scenarios, apply it empirically on a dataset of mergers & acquisitions and\n",
      "show how it can be used to generate forecasts. section 3.5 presents key results, such as\n",
      "robustness to diverse data inputs and adaptability to other applications. section 3.7\n",
      "discusses limitations, such as in the evaluation approach or computational aspects and\n",
      "suggests next steps like density forecasting, introducing a judgemental component and\n",
      "extending the test-statistic.\n",
      "3.2 Related Work\n",
      "Our approach extends previous literature as it serves as a generic toolbox that could\n",
      "easily be adapted to other applications and can give accurate forecasts that can, but\n",
      "do not have to be, adjusted by incorporating knowledge from industry experts and is\n",
      "adaptable to arbitrary frequencies. Although we show how to forecast the occurance of\n",
      "M&A events, our methodology could also extend research in other areas that typically\n",
      "use Poisson processes such as demand forecasting for supply chain planning (Yelland\n",
      "et al., 2010), call center arrival times (Taylor, 2007, 2011) and Oreshkin et al. (2016),\n",
      "sales forecasting (Kolsarici & Vakratsas, 2015), or mergers & acquisitions forecasting\n",
      "(Akkus et al., 2015; Bianchi & Chiarella, 2018; Very et al., 2012). However, the available38 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "datasets are usually subject to non-stationarity and structural breaks, and they usually\n",
      "make manual efforts to fit a meaningful model necessary.\n",
      "Empirical evidence strongly suggests that mergers often have \"wave\" like clusters in\n",
      "time, see Martynova and Renneboog (2005), Harford (2005) and Maksimovic et al.\n",
      "(2013). Ahern and Harford (2014) find that such an activity is subject to network effects\n",
      "and that these \"waves\" largely occur within industries, but can also be transmitted\n",
      "to connected industries. Furthermore, shocks of any kind, even if they lead to merger\n",
      "waves, are difficult to predict. \"Wave\" patterns seem to be heterogeneous and differ\n",
      "both in time and in industries. Following their argumentation, we conclude that data\n",
      "on M&A should be evaluated per industry and geographic location due to differences\n",
      "in regulation, innovation power, technology, and stock markets.\n",
      "Predictive models for M&A intensity could be identified through aggregating acquired\n",
      "knowledge and tailored to specific industries and markets. Alternatively, time-series\n",
      "models, e.g. ARMA can be used. While a co-variate based model provides explainability\n",
      "to the user, it requires manual efforts to gather data and incorporate expert knowledge\n",
      "to define relevant variables and calibrate their impact on a predictive model. Data\n",
      "gathering can be time-consuming and expensive, and knowledge about modeling\n",
      "heterogeneous industries in a specific application requires domain knowledge, which is\n",
      "often scarce and narrowed to said application. Time series models are an alternative,\n",
      "as they can be adapted to any other data set with comparable structure. However,\n",
      "such models need to be robust to non-stationarity, structural breaks and wave patterns\n",
      "that limit their predictive power.\n",
      "There is no doubt that only time varying time series models approximate the dynamics\n",
      "of the underlying series better than any homogeneous parameter approach, e.g. a\n",
      "fixed ARMA( p, q) model. LPA is very appropriate in such cases. The quantitative\n",
      "implementation was first proposed in V. G. Spokoiny (1998), advances are made in\n",
      "Mercurio and Spokoiny (2004) and V. Spokoiny (2009). It helps us to find locally\n",
      "homogeneous time intervals with stable parameters and guarantees a trade-off between\n",
      "parameter variance and modeling bias. The technique is based on a series of likelihood\n",
      "ratio tests to determine some distributional change in the underlying series (which in\n",
      "our case is the maximum likelihood estimator of the Poisson process). As a result one\n",
      "finds local intervals of homogeneity and efficient estimates at each point in time.\n",
      "Since we are often dealing with small sample sizes, and the test statistic distribution is\n",
      "unknown, we need a method to approximate this distribution. Recent advances in boot-\n",
      "strapping methodology allow us to generate empirically approximate the distribution\n",
      "and hence the critical values that non-asymptotically approximate the true distribution.3.2. RELATED WORK 39\n",
      "Here, we couple LPA with MBS (V. Spokoiny & Zhilova, 2015) for approximating\n",
      "a critical value for the testing procedure. MBS builds up on wild bootstrap, that\n",
      "originates from Wu (1986) and Beran (1986). Klochkov et al. (2019) also presents\n",
      "theoretical justifications for why MBS is appropriate to be coupled with LPA, even\n",
      "though for a different setting. An important application is reported in Härdle and\n",
      "Mammen (1993), and Mammen (1993). Further advances are made in Chatterjee and\n",
      "Bose (2005) and Arlot et al. (2010). Notable publications that precede V. Spokoiny and\n",
      "Zhilova (2015) are Bücher and Dette (2013) and Chernozhukov et al. (2013). Klochkov\n",
      "et al. (2019) presents an application in the context of a conditional autoregressive Value\n",
      "at Risk model. We generalize this LPA idea to any count data that is locally Poisson\n",
      "distributed, although our simulation study indicates that this assumption could be\n",
      "relaxed to the general membership to any of the exponential families. That allows us to\n",
      "bridge business requirements with the robustness of novel statistical methods through\n",
      "flexible automated estimations. This is valuable as available data for problems in\n",
      "strategic management like forecasting the intensity of M&A events is often challenging.\n",
      "Assumptions on the underlying distribution, such as stationarity or the absence of\n",
      "structural breaks are usually not fulfilled.\n",
      "We detect locally homogeneous windows by computing a nonparametric likelihood ratio\n",
      "statistics. This approach can be linked to the branch of change point detection methods.\n",
      "Chen and Gupta (2011), Eckley et al. (2011), and Aminikhanghahi and Cook (2017)\n",
      "summarize and evaluate diverse methods of change point detection. Notable approaches\n",
      "are Hinkley and Hinkley (1970), (Hsu, 1979), (Haccou et al., 1987), and (Chen &\n",
      "Gupta, 1999) that propose change point detection methods for gamma, exponentially,\n",
      "and normally distributed data respectively. Kutoyants and Spokoiny (1999) propose an\n",
      "adaptive procedure as well as theoretical properties for Poisson distributed data. Chen\n",
      "and Gupta (2011) provides the null distribution of a likelihood ratio test for Poisson\n",
      "distributed random variables, but they do not evaluate the efficiency of the procedure\n",
      "on real data.\n",
      "Both change point detection and homogeneous window approaches can serve as deter-\n",
      "minator for an optimal forecasting window. Recent approaches for optimal window\n",
      "selection are Giraitis et al. (2013), Pesaran et al. (2013), and Inoue et al. (2017). They\n",
      "address parameter instability and frequent structural breaks and conclude that adaptive\n",
      "window selection should be preferred over choosing fixed window sizes, such as a 1 year\n",
      "or 3 year moving average. Since we aim at developing a generally applicable method\n",
      "that is robust to different data characteristics, we need an adaptive forecasting window.\n",
      "Hence, we pursue a nonparametric approach that is independent of knowledge about or\n",
      "assumptions on the data set, except that the values are generated by a Poisson process\n",
      "with smooth but time varying intensity over some unknown time window.40 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "Note that even though change point detection methods can be modified to deal with\n",
      "the problem of finding homogeneous windows within a time series, LPA is not a change-\n",
      "point detection method, at least not in the conventional manner. The aim of LPA\n",
      "is to look back from a given point in time, and find another time point where the\n",
      "distribution changes. This change can be characterized as the change in mean for some\n",
      "distributions, but not necessarily so. In contrast, traditional change point detection\n",
      "methods usually detect anomalous sequences/states in a time series by looking at the\n",
      "whole time series. Many times, these methods aim to find multiple points within the\n",
      "time series to represent temporary shocks or structural breaks that may or may not\n",
      "have caused a change in distribution. Due to the difference between our approach and\n",
      "change point detection methods, we will not discuss or compare our approach with\n",
      "change point detection methods.\n",
      "3.3 Methodology\n",
      "3.3.1 Basic Idea\n",
      "Planning processes in corporate environments are based on internal financial data of\n",
      "different kinds. Traditionally, these problems have been solved using diverse time series\n",
      "models. However, it is difficult to use them since real time series often have structural\n",
      "breaks and they do not satisfy stationarity assumptions. Following the same reasoning,\n",
      "fitting a single parametric model to a non-stationary time series is not appropriate. To\n",
      "contribute to solving this problem, we focus on detecting locally homogeneous intervals\n",
      "with stable parameters within a \"stability region\" of a time series. In these so called\n",
      "\"intervals of homogeneity\", a local parametric model can be safely used. To be more\n",
      "specific, we focus on a count data model where the time varying intensity follows a\n",
      "Poisson process. Take again Figure 3.1 as an example. We aim to detect the last\n",
      "time point (possibly around 95-97) that added the non stationary component (a slight\n",
      "uptrend is observable) and cut off the time series before the point in time where the\n",
      "parameter changes. We call these time points break points in the rest of this paper.\n",
      "Automated analyses can be beneficial as they make modelling easier. Our procedure\n",
      "automatically detects the locally homogeneous region and use only this time window\n",
      "for analysis and forecasting.\n",
      "In this section, we lay down the procedure of finding locally homogeneous windows,\n",
      "and show how it can be used to obtain forecasts.\n",
      "3.3.2 Stochastics\n",
      "LetYt∈N, t= 0, ..., Tbe a count data time series such as the count of M&A series, see\n",
      "in Figure 3.1. Think of Yt∼Poisson (θ), where θrepresents the rate or average number\n",
      "of occurrences in a fixed interval. Since we allow for time variation in our model, for\n",
      "any interval I= [a, b]with a < banda, b∈ {0, ..., T}, we write (Yt)t∈I∼Poisson (θ).3.3. METHODOLOGY 41\n",
      "The log likelihood function on Iis:\n",
      "LI(θ) =∑︂\n",
      "t∈Ilog(θYte−θ/Yt!) = log θ∑︂\n",
      "t∈IYt−∑︂\n",
      "t∈Iθ−∑︂\n",
      "t∈Ilog(Yt!),(3.1)\n",
      "and the MLE θ˜Ibased on observations in i∈Iis:\n",
      "θ˜Idef=argmax\n",
      "θ∈ΘLI(θ), (3.2)\n",
      "which for a Poisson model is the sample mean.\n",
      "3.3.3 Local Parametric Approach\n",
      "LPA, first introduced by V. G. Spokoiny (1998) is based on the phenomenon that a\n",
      "series of locally parametric models can describe the features of a time series better\n",
      "than a global parametric model. The basic idea is that given a time series and a model\n",
      "for its dynamics, one finds locally stationary intervals of the time series in an iterative\n",
      "fashion. This is done by finding the set of the most recent observations, such that the\n",
      "model parameters are approximately stable in that interval. This set of time points is\n",
      "calledinterval of homogeneity . Employing the same procedure at each point in time,\n",
      "one locally estimates the parameter (Härdle et al., 2015). The merit of LPA is that it\n",
      "does not require an explicit expression of the law of the dynamics of the parameter,\n",
      "but only assumes that the parameter is constant on some unknown time interval in the\n",
      "past (V. Spokoiny, 2009).\n",
      "In order to check the homogeneity of an interval I= [a, b], LPA looks for some break\n",
      "point τ∈(a, b)such that Aτ= [a, τ)has a parameter and Bτ= [τ, b]has a parameter as\n",
      "well. Obviously if the parameters are identical, we are looking at a homogeneous interval\n",
      "I. Deviations from the identical parameter situation indicate then non-homogeneity.\n",
      "One then checks this homogeneity for different points τin the center of I(Klochkov\n",
      "et al., 2019).\n",
      "The testing hypotheses are therefore:\n",
      "H0(I) : (Yt)t∈I∼Poisson (θ∗\n",
      "I), θ∗\n",
      "I∈Θ,\n",
      "vs\n",
      "H1(I) : (Yt)t∈Aτ∼Poisson (θ∗\n",
      "Aτ), θ∗\n",
      "Aτ∈Θ,\n",
      "(Yt)t∈Bτ∼Poisson (θ∗\n",
      "Bτ), θ∗\n",
      "Bτ∈Θ,\n",
      "with some θ∗\n",
      "Aτ̸=θ∗\n",
      "Bτ,(3.3)\n",
      "and the LR test statistic for a break point τis:\n",
      "TI,τ=LAτ(θ˜Aτ) +LBτ(θ˜Bτ)−LI(θ˜I), (3.4)42 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "which, since one has many candidates τ∈J, arrives at:\n",
      "TI= max\n",
      "τ∈JTI,τ, (3.5)\n",
      "this unfortunately has a very intractable distribution, hence the critical values zI(α)\n",
      "needed to test H0in equation (3.3)\n",
      "TI≥zI(α) (3.6)\n",
      "are hard to calculate. Indeed, the limiting distribution of TIis different from general\n",
      "likelihood ratio tests due to the nonlinear maxoperator in equation (3.5). Hence,\n",
      "convergence of the generalized LR statistics to a χ2distribution according to Wilk’s\n",
      "phenomenon can not be put into action. While the asymptotic distribution of the\n",
      "sup-LR test in equation (3.5) can still be derived (Andrews & Ploberger, 1994), a\n",
      "large enough sample size is required for its asymptotic critical values to be applicable.\n",
      "Certainly, that is not the case in most practical situations where only small samples of\n",
      "data are available.\n",
      "V. Spokoiny and Zhilova (2015) provide a non-asymptotic result for mis-specified\n",
      "models with small sampling sizes. They propose a simulation based approach MBS\n",
      "which can be used to construct critical values. We extend the MBS technique and\n",
      "discuss it in detail in the next section.\n",
      "3.3.4 Multiplier Bootstrap\n",
      "Since the distribution for TIin equation (3.5) is not available, we employ bootstrapping.\n",
      "MBS is a novel and state-of-the-art technique to approximate the unknown distribution.\n",
      "It does not put any assumptions on the data distribution and constructs the critical val-\n",
      "ues completely in a data driven fashion. The departure from distributional assumptions\n",
      "makes this technique unique and easily applicable with LPA to assist in hypothesis\n",
      "testing. Refer to V. Spokoiny and Zhilova (2015) for the theoretical justification of\n",
      "using the MBS procedure for the construction of likelihood-based confidence sets.\n",
      "The idea of MBS is to first introduce random weights to the previously defined likelihood\n",
      "function:\n",
      "L◦\n",
      "I(θ) =∑︂\n",
      "t∈Iwtlt(θ),\n",
      "where the weights wtare iid, independent of the sample, with E(wt) = 1andVar(wt) =\n",
      "1. The weights generated under these assumptions are optimal for mimicing the\n",
      "unknown distribution (see assumption 3.1 in Klochkov et al. (2019))). The bootstrap\n",
      "version of equation (3.1) is given by:3.3. METHODOLOGY 43\n",
      "L◦\n",
      "I(θ) = log θ∑︂\n",
      "t∈IYtwt−∑︂\n",
      "t∈Iwtθ−∑︂\n",
      "t∈Ilog(Yt!)wt.\n",
      "The bootstrap MLE is then defined as:\n",
      "θ˜◦\n",
      "I= arg max L◦\n",
      "I(θ),\n",
      "which is:\n",
      "θ˜◦\n",
      "I=∑︁\n",
      "t∈IYtwt∑︁\n",
      "t∈Iwt.\n",
      "It follows that the corresponding bootstrap version of equation (3.8) is:\n",
      "T◦\n",
      "I,τ=L◦\n",
      "A,τ(θ˜◦\n",
      "A,τ) +L◦\n",
      "B,τ(θ˜◦\n",
      "B,τ)−sup\n",
      "θ{︂\n",
      "L◦\n",
      "A,τ(θ) +L◦\n",
      "B,τ(θ+θ˜B,τ−θ˜A,τ)}︂\n",
      ".(3.7)\n",
      "Here, the shift term θ˜B,τ−θ˜A,τis devoted to compensate for the biases of the bootstrap\n",
      "estimators θ˜◦\n",
      "A,τandθ˜◦\n",
      "B,τ. Klochkov et al. (2019) show that the distribution of this test\n",
      "conditional on the data mimics the \"true\" distribution of TIwith high probability (see\n",
      "Theorem 1 in the referenced script). Using equation (3.7) we can obtain the critical\n",
      "value through simulations. Indeed, the critical value z◦\n",
      "I(α)is defined as:\n",
      "z◦\n",
      "I(α) =z◦\n",
      "I(α;Y) = inf{︁\n",
      "z≥0 :P(T◦\n",
      "I> z2/2)≤α}︁\n",
      ".\n",
      "3.3.5 Algorithm\n",
      "The algorithm for an adaptive window length selection at each point in time is now\n",
      "straightforward. It is based on sequential testing of the hypotheses on a nested set\n",
      "of intervals {Ik}k=0,1,...,K, where I0⊂I1⊂. . .⊂IK. Let nk=|Ik|be the number of\n",
      "observations in each interval. The first interval I0is assumed to be homogeneous with\n",
      "length n0. Then, for each interval Ik, the null hypothesis of parameter homogeneity is\n",
      "tested against the alternative of a break point at an unknown location τwithin Ik, as\n",
      "in equation (3.3).\n",
      "Since the setup deals with nested intervals, but the existence and location of a break\n",
      "point are unknown, only additional points in each new interval are considered as\n",
      "possible break points. The candidate set for break points in each interval is defined as\n",
      "Jk=Ik\\Ik−1. Using each point τ∈Jk, the left and right intervals are constructed as\n",
      "Ak,τ= [i0−nk+1, τ]andBk,τ= (τ, i0]respectively (see Figure 3.3). The test statistic\n",
      "is calculated similarly to equation (3.5) as\n",
      "TIk,τ=LAk,τ(θ˜Ak,τ) +LBk,τ(θ˜Bk,τ)−LIk+1(θ˜Ik+1), (3.8)44 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "where Ak,τandBk,τare as previously specified and we test at every point τ∈Jkfor a\n",
      "break point. The kth interval is rejected if\n",
      "max\n",
      "j∈JkTIk,τ≤z◦\n",
      "Ik(α), (3.9)\n",
      "and z◦\n",
      "Ikis generated via MBS as explained in the previous section. If the interval I\n",
      "is not rejected, i.e. there exists no break point and it is homogeneous, we continue\n",
      "the testing procedure by choosing a bigger interval. Otherwise, the length of the last\n",
      "non-rejected interval ˆ︁Iis the interval of homogeneity and ˆ︁θi0=ˆ︁θˆ︁Iis the respective\n",
      "adaptive estimate of ˆ︁I.\n",
      "Homogeneity testing for Ikutilizes also part of observations of Ik+1. Hence, the pre-\n",
      "definition of intervals is crucial. Following that, the choice of interval lengths affects\n",
      "the test results, and therefore requires careful selection. Based on the initial length n0,\n",
      "the interval lengths are defined by\n",
      "nk=⌈︃\n",
      "n0ck⌉︃\n",
      ", (3.10)\n",
      "where cis a geometric multiplier, chosen slightly above 1 to ensure a monotonic increase\n",
      "of interval lengths, but not by a big margin. Furthermore, we select Kto be the smallest\n",
      "integer such that the whole time series is covered under a geometrically increasing\n",
      "length.\n",
      "Figure 3.3: Graphical illustration of the iterative algorithm to search for the homogeneous\n",
      "window within a time series\n",
      "In summary, the LPA algorithm for adaptive choice of an interval of homogeneity and\n",
      "the corresponding MLE is given by the following iterative procedure:3.4. EXPERIMENTAL RESULTS 45\n",
      "1.Initialization : Select I0, I1, I2,and define J1=I1\\I0,(∀τ∈J1), A1,τ= [i0−\n",
      "n2, τ],B1,τ= (τ, i0].\n",
      "2.Iteration : For each iteration, select Ik−1, Ik, Ik+1,,Jk=Ik\\Ik−1,(∀τ∈Jk)\n",
      "Ak,τ= [i0−nk+1, τ], Bk,τ= (τ, i0].\n",
      "3.Testing homogeneity : Calculate test statistics in equation (3.8) and select\n",
      "critical value with MBS. Test hypothesis in equation (3.3) using equation (3.9).\n",
      "4.Loop: IfIkis accepted, take the next interval Ik+1. Otherwise set ˆ︁Ito the latest\n",
      "non rejected Ik.\n",
      "5.Adaptive estimator : Take interval ˆ︁Ias interval of homogeneity and ˆ︁θi0=ˆ︁θˆ︁Ias\n",
      "adaptive estimate of ˆ︁I. Repeat the procedure for each point in time (different i0).\n",
      "3.4 Experimental Results\n",
      "The following lines seek to answer the question whether or not we can generate\n",
      "better forecasts by using the described adaptive methodology, and whether or not\n",
      "the methodology is robust with respect to previously unseen and thus unpredictable\n",
      "patterns. We compare one-step-ahead and multi-period point parameter forecasts of\n",
      "the proposed locally adaptive procedure to a baseline of one year and three years\n",
      "moving averages in a pseudo-out-of-sample approach. We acknowledge that this is\n",
      "only a baseline evaluation approach. A more sophisticated evaluation approach would\n",
      "be to generate multi-period density forecasts that could be evaluated using a tailored\n",
      "loss-function as in Diebold (2015) and Diebold et al. (1998), and Gonzalez-Rivera and\n",
      "Sun (2014). However, as this is beyond the scope of this paper (or altogether another\n",
      "paper), we leave it open for future work.\n",
      "3.4.1 Simulation study\n",
      "This section evaluates the performance of the proposed technique using simulated\n",
      "data sets as shown in Figure 3.4. We create scenarios that mimic common patterns\n",
      "in financial data sets. The simulations focus both on short-term shocks and regime\n",
      "shifts. Starting with the simplest piece-wise constant model, we gradually increase\n",
      "the complexity of the simulations by generating Poisson distributed data and finally\n",
      "test the robustness of the methodology by changing the underlying model to follow an\n",
      "exponential distribution. For each scenario, we consider a time series (Yt)300\n",
      "t=1with the\n",
      "following specifications:\n",
      "(a)Regime shifts with piece-wise constant model :(Yt)100\n",
      "t=1= 1,(Yt)200\n",
      "t=101= 10and\n",
      "(Yt)300\n",
      "t=201= 20,\n",
      "(b)Regime shifts with Poisson model :(Y1t)100\n",
      "t=1with θ1= 1,(Y2t)200\n",
      "t=101with θ2= 1046 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "and(Y3t)300\n",
      "t=201with θ3= 20,\n",
      "(c)Short term shock with piece-wise constant model :(Yt)199\n",
      "t=1= 1,(Yt)200\n",
      "t=200= 10and\n",
      "(Yt)300\n",
      "t=201= 1,\n",
      "(d)Structural break with piece-wise constant model :(Yt)180\n",
      "t=1= 10,(Yt)200\n",
      "t=181= 7and\n",
      "(Yt)300\n",
      "t=201= 10,\n",
      "(e)Structural break with Poisson model :(Y1t)180\n",
      "t=1with θ1= 5,(Y2t)200\n",
      "t=181with θ2= 1\n",
      "and(Y3t)300\n",
      "t=201with θ3= 5,\n",
      "(f)Regime shifts with exponential model :(Y1t)100\n",
      "t=1with θ1= 0.1,(Y2t)200\n",
      "t=101with\n",
      "θ2= 1and(Y3t)300\n",
      "t=201with θ3= 10.\n",
      "The simulated data of scenarios (a)-(f) is shown in the time series plots on the left hand\n",
      "side in Figure 3.4. Since the algorithm requires pre-selection of the intervals, we fix c in\n",
      "equation (3.10) at 1.35. Here, c >1is chosen slightly greater than one, so that in the\n",
      "worst case one only neglects a small proportion of unknown homogeneous interval. A dif-\n",
      "ferentselectionofcwillnotaffecttheresults, aslongasitisnotchosentobemuchhigher\n",
      "than 1. Assuming a minimal homogeneous window ( n0) of 5 months, we compute Kas\n",
      "described in section 3.3.5. For example, the candidate homogeneous windows for the\n",
      "latest period in the time series are [6,9,12,16,22,30,40,55,74,100,135,183,247,300].\n",
      "Note that since we allow the number of intervals to vary with the time point for which\n",
      "the homogeneous windows has to be determined, the number of intervals being tested\n",
      "gradually decrease as the number of historical data points in the time series decrease.\n",
      "The algorithm is applied to find the homogeneous window and corresponding MLE\n",
      "estimate for each point in time in each simulation and the results are presented in\n",
      "Figure 3.4. Also, for each scenario, we run 100 simulations to smoothen the estimated\n",
      "window sizes and construct confidence intervals that are depicted by dotted lines in all\n",
      "plots in Figure 3.4.\n",
      "Plot (a) in Figure 3.4 shows that the procedure detects intervals of homogeneity\n",
      "correctly in all cases of this fairly simple scenario. It is robust to small and big values\n",
      "and gives a good approximation of the true parameters. The step-wise increase of\n",
      "homogeneous windows and the fluctuation of MLEs is a consequence of the limited\n",
      "number of possible time windows Kthat the algorithm tests for. If Kwere to be\n",
      "increased, for example arithmetically, which means that the algorithms tests for all\n",
      "possible interval sizes, increasing the interval by one at each iteration, we would expect\n",
      "the algorithm to generate a straight downward slopping line instead. The arithmetic\n",
      "increase in intervals requires a lot of tests to be performed, whereas the geometric\n",
      "increase with lesser number of tests already results in high accuracy. For computational3.4. EXPERIMENTAL RESULTS 47\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "(d)\n",
      "(e)\n",
      "(f)\n",
      "Figure 3.4: Simulated series (left), homogeneous windows (middle) and MLE (right).\n",
      "LPA_Simulations48 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "ease, we illustrate this on scenario (a) in Figure 3.5 and avoid such an experiment for\n",
      "other scenarios. Similarly, we will use geometrically increasing intervals in our use-case\n",
      "study in the next section.\n",
      "(a)\n",
      "Figure 3.5: Simulated series (left), homogeneous windows (middle) and MLE (right) using\n",
      "arithmetically increasing intervals in LPA.\n",
      " LPA_Simulations\n",
      "Next, a more realistic scenario with values generated from a Poisson process in (b)\n",
      "shows that the procedure is robust to noise even when the sample size is small. On\n",
      "the other hand, when nis small, the problem of multiple testing causes many false\n",
      "negatives. This becomes evident in the first third of (b). This can be easily dealt with\n",
      "by changing the number of tested intervals in the algorithm. Regardless of this issue,\n",
      "the MLE remains close to the true parameter value.\n",
      "Furthermore, some temporary shocks and small structural breaks are mimicked in\n",
      "simulations (c)-(e). (c) shows that a large shock is detected accurately, with an indicator\n",
      "to select a smaller window size around the change in mean. The simulation in (d)\n",
      "shows that temporary changes in mean are not always recognised by the algorithm,\n",
      "but the MLE after such short-term shocks is still affected. The procedure also detects\n",
      "structural breaks within a Poisson framework accurately as depicted in (e), but the\n",
      "estimated time windows are inaccurate shortly after the break. With increasing n, the\n",
      "accuracy is restored and the approximated MLE remains accurate.\n",
      "Finally, to check the robustness of the algorithm, values are generated from an exponen-\n",
      "tial distribution. The simulation in (f) shows that the algorithm detects breakpoints\n",
      "correctly even with exponentially distributed data. Accordingly, the assumption of\n",
      "Poisson distributed values can be easily relaxed towards models from any exponential\n",
      "family. This robustness allows the algorithm to be used even with misspecified models.\n",
      "For each simulation scenario, we also compare the results with fixed window estimates\n",
      "of 12 months (high variance) and 36 months (high bias) and show the results in Figure\n",
      "3.6. All subplots show that LPA finds a balance between variance and bias by selecting\n",
      "a smaller or bigger window size when necessary. Plot (a) shows that while the estimates\n",
      "of LPA fluctuate (as described above), the shift in regime is detected earlier by LPA\n",
      "than by fixed window estimates. Plots (b) and (e) show that for the simulated intervals3.4. EXPERIMENTAL RESULTS 49\n",
      "with constant mean, fixed window estimates indicate a highly fluctuating mean, while\n",
      "LPA recognizes intervals of time homogeneity correctly. Moreover, the impact of the\n",
      "short term shock disappears faster in the LPA estimates in (c) and (d). However, LPA\n",
      "underestimates the magnitude of shocks as visible in (d).\n",
      "In conclusion, the algorithm accurately detects small shocks, regime shifts and tempo-\n",
      "rary mean changes in time series without strict assumptions on the underlying model.\n",
      "The results could be improved further by correct selection of interval lengths and\n",
      "numbers of intervals being tested, as they have a significant impact on the precision\n",
      "and accuracy of the results.\n",
      "(a)\n",
      " (b)\n",
      "(c)\n",
      " (d)\n",
      "(e)\n",
      " (f)\n",
      "Figure 3.6: Time series of simulated data and one step ahead prediction with estimates from\n",
      "LPA, 1 year fixed window and 3 year fixed window.\n",
      "LPA_Simulations50 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "3.5 Use case study\n",
      "In this section, we apply LPA to a working example of time series that are relevant\n",
      "to businesses in the financial industry. We use a data set of mergers & acquisitions\n",
      "per month that we acquired from the database Refinitiv Eikon Deals (restricted access\n",
      "through subscription). We consider different industries according to the Thomson\n",
      "Reuters Business Classification scheme in Germany. The data set consists of a total of\n",
      "9,969 observations in ten industries in the US and Germany. We put the procedure\n",
      "into action on the following three industries in Germany:\n",
      "1. Financials\n",
      "2. Telecommunication\n",
      "3. Energy\n",
      "Due to inconsistent recordings of transactions, we considered only 424 observations\n",
      "from 01-1984 to 04-2020 in Germany for each industry. Following previous literature,\n",
      "we consider different industries separately. Without insider knowledge, the frequency\n",
      "of M&A events could be assumed to be random, which is based on the intuition that\n",
      "we usually learn about mergers only after they are announced. We also assume that at\n",
      "each point, there exist a time window where a somewhat stable structure can be found\n",
      "in the short run, but can be interrupted by exogenous factors that change industry\n",
      "dynamics. Given these characteristics, we model the number of M&A with a Poisson\n",
      "process and apply LPA to forecast the next period given the MLE of the last observed\n",
      "homogeneous time window. We do not preprocess the data and let the procedure\n",
      "account for structural breaks and non-stationarity.\n",
      "Similar to the simulation study in previous section, we fix n0at 5 months, and c at\n",
      "1.35. To re-iterate, this seemingly arbitrary choice ensures that we neglect only few\n",
      "unknown homogeneous intervals (if any), while keeping the number of performed tests\n",
      "minimal. Next, we run 100 simulations to smoothen the estimated window sizes. We\n",
      "keep n0and c for the interval selection through equation (3.10) constant as an aim of\n",
      "the proposed algorithm is to evaluate unseen data even if no knowledge about it is\n",
      "available. Some example cases are illustrated to verify the robustness of the algorithm\n",
      "with respect to different types of time series in Figure 3.7. The plot on the right hand\n",
      "side shows the homogeneous windows for each point in time. The corresponding LPA\n",
      "estimate, 12 month estimate, and 36 month estimate as one period ahead forecast are\n",
      "shown in the left plot.\n",
      "The first plot in Figure 3.7 shows the German financial industry, where an upward\n",
      "trend in the number of mergers can be observed over time. The plot shows that LPA3.5. USE CASE STUDY 51\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "Figure 3.7: Time series of original data and one step ahead prediction with estimates from\n",
      "LPA, 1 year fixed window and 3 year fixed window (left) Homogeneous windows (right) for\n",
      "(1) Financials, (2) Telecommunication and (3) Energy.\n",
      " LPA_Empiricalstudy\n",
      "estimates closely mimic this trend, and is much more responsive to shocks as in the\n",
      "mid-90s. Moreover, contrary to the green 1-year moving average curve, which shows\n",
      "high variance in the MLE estimate, LPA recognizes the regions within time series\n",
      "where the average number of M&A is approximately constant, such as from 2010 to\n",
      "2020. The LPA estimates on the left suggest that the selected window size differs\n",
      "over time (sometimes up to 200, sometimes only a few observations) and using a fixed\n",
      "time window for generating forecasts is not recommended according to the technique.\n",
      "Comparing the window plot of the same industry with the simulation plots (a) and\n",
      "(b) from the previous section, we identify six regimes in the German financial industry52 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "(1984-1988, 1988-1990, 1990-1994, 1994-1999, 1999-2006 and 2006-2020). These regimes\n",
      "could be associated with external events, such as: a merger wave in 1984, the effects of\n",
      "globalization in the late 1980s, the German bank merger wave in the 1990s, market\n",
      "liberalization policies in the mid-90s, and the technological innovations in the late 20th\n",
      "century.\n",
      "The second part of Figure 3.7 shows the German telecommunication industry, where\n",
      "the number of M&As per month seems stable and stationary, except for a short merger\n",
      "wave in the mid-90s due to the liberalization of the market and another short wave\n",
      "around 2001 (possibly related to the dotcom-bubble). LPA suggests a stable time series\n",
      "as the algorithm recommends to select large windows, and sometimes the whole time\n",
      "series. Only during the interval where a shock can be seen on the left, LPA’s choice\n",
      "of homogeneous window on the right restricts the time window to a few years (for\n",
      "example between 1994 and 2001). We see that LPA can handle time-varying parameters\n",
      "while facing a trade-off between parameter variability and modelling bias. A similar\n",
      "conclusion can be drawn from the energy markets plots in (3) of Figure 3.7.\n",
      "We further extend our analysis by comparing the predictions from our LPA approach\n",
      "with a baseline ARIMA model. We use the auto.arima function in R that uses the\n",
      "algorithm given in Hyndman and Khandakar (2008) for finding the best fit for our data.\n",
      "The best model for all three datasets is summarized in Table 3.1. As expected, all three\n",
      "series show non-stationarity and require differencing. We verify this by examining the\n",
      "auto-correlation function plots of the series as shown in Figure 3.8. The auto-correlation\n",
      "lags are positive for many lags, this indicates that the series needs differencing. The\n",
      "second and third panel of the same plot show that the time series becomes stationarity\n",
      "after taking first differences. Furthermore, the models suggest no autoregressive term,\n",
      "and only one or two moving average terms. While these models have led to a small\n",
      "MSE for the forecast period of last three months, they can not be relied on when there\n",
      "is an abrupt change in the time series, e.g. as in 1996. We repeat the procedure the\n",
      "analysis for the period from 01-1984 to 09-1996 and use 10-1996 to 12-1996 as forecast\n",
      "period. The results reveal that the best fit ARIMA model for this time period changes\n",
      "for all three datasets (ARIMA(2,1,2), ARIMA(1,1,2), and ARIMA(0,1,2) respectively),\n",
      "suggesting different autoregressive and moving average lags. This implies that a single\n",
      "parametric model is not a good fit for the entire time series.\n",
      "Next, we forecast the number of M&As for 02-2020 to 04-2020 using the LPA estimate\n",
      "and the fixed 1-year and 3-year window estimates of 01-2020. The estimates and mean\n",
      "squared errors (MSE) of the estimation are summarized in Table 3.1. Apart from the\n",
      "selection of time-varying window lengths, the results suggest that LPA can also provide\n",
      "guidance on the a-priori selection of fixed windows. Looking at the distribution plot of3.5. USE CASE STUDY 53\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "Figure 3.8: Autocorrelation plot for the original data (left), autocorrelation plot for the first\n",
      "differenced data (middle) and partial autocorrelation plot (right) for (1) Financials, (2)\n",
      "Telecommunication and (3) Energy.\n",
      " LPA_Empiricalstudy\n",
      "window lengths (as a proportion of data points in the time series before the time of\n",
      "evaluation) in Figure 3.9, and selecting the window with highest frequency (w)as the\n",
      "fixed time window for each time series, we also make a forecast and report the MSE in\n",
      "the same table.\n",
      "(1)\n",
      " (2)\n",
      " (3)\n",
      "Figure 3.9: Distribution of estimated interval length as a proportion of data points for (1)\n",
      "Financials, (2) Telecommunication and (3) Energy.\n",
      " LPA_Empiricalstudy\n",
      "The Table 3.1 shows that LPA produces the smallest MSE in the financials and\n",
      "telecommunication industry. However, in the energy sector the 1 year fixed window\n",
      "outperforms LPA, perhaps due to its high fluctuations. Similarly, the homogeneous54 CHAPTER 3. DATA ANALYTICS DRIVEN CONTROLLING\n",
      "Financials Telecom. Energy\n",
      "LPA estimate 52.99 3.43 4.23\n",
      "12 month MA estimate 55.58 2.42 3.08\n",
      "36 month MA estimate 55.50 2.94 4.17\n",
      "Most recurring window(w) 160 184 309\n",
      "w month MA estimate 55.25 2.90 4.62\n",
      "LPA MSE 1008.24 3.11 8.61\n",
      "12 month MSE 1159.29 7.34 3.29\n",
      "36 month MSE 1154.25 4.89 8.25\n",
      "w month MSE 1139.23 5.06 11.03\n",
      "ARIMA best fit (0,1,2) (0,1,1) (0,1,1)\n",
      "ARIMA MSE 301.15 0.79 0.23\n",
      "Table 3.1: Forecast results for 02-2020 to 04-2020 based on the adaptively selected MLE, fixed\n",
      "windows, ARIMA and most recurring window proportionally (w)in the distribution plots in\n",
      "Figure 3.9\n",
      "time window recommended by LPA for the financial industry was roughly 160 months.\n",
      "Choosing this time window resulted in a lower MSE than using 12 and 36 months fixed\n",
      "window estimates. For the energy sector, however, LPA recommends the selection of a\n",
      "very long window, for which the estimate deviates significantly from the true value,\n",
      "but still captures the stationary aspect of the time series. As a whole, the results\n",
      "show that cluster patterns and level shifts are accurately detected, and that a plausible\n",
      "fit is achieved under the assumption that M&A follow a Poisson distribution with\n",
      "time-varying parameter.\n",
      "The analysis shows that the proposed technique efficiently handles the complex proper-\n",
      "ties of M&A time series and helps us generate better forecasts. Moreover, the empirical\n",
      "analysis reveals that the patterns in the various German industries differ strongly.\n",
      "Therefore, the usage of an automated and data driven procedure lets us obtain accurate\n",
      "forecasts with minimal effort and can be adapted to other industries or even other\n",
      "business problems. It can be used as a baseline for forecasting or simulation approaches\n",
      "and can be integrated into large scale planning systems. The MLE series could be\n",
      "forecasted using e.g. autoregressive models that generate different scenarios. Business\n",
      "experts could then make a judgement about the likeliness of these scenarios. Moreover,\n",
      "the availability of a time-varying parameter allows analysts to use more sophisticated\n",
      "approaches, e.g. modeling the distributional properties of various time-series that\n",
      "are assumed to follow a Poisson distribution, such as the examples mentioned in the\n",
      "introduction (call centers, sales, supply chains). Businesses are often not interested in\n",
      "exact values, but in having an overview over the range of expected figures, and forecasts\n",
      "of low quality can lead to costly miscalculations. The proposed procedure helps increase\n",
      "forecast quality and availability and thus generate business value if employed.3.6. CONCLUSION 55\n",
      "3.6 Conclusion\n",
      "A new algorithm for automatically finding homogeneous time intervals in a non station-\n",
      "ary count time series data is proposed. Trends, cyclical components, and even black\n",
      "swan events can be tackled with this technique, without need of manual supervision\n",
      "or model assumptions. The algorithm is based on a fruitful combination of a local\n",
      "parametric model (here a Poisson process) and MBS. We conduct a simulation study\n",
      "that indicates that the procedure is indeed robust, even if the input data is not Poisson\n",
      "distributed. These results are then used to evaluate a data set of M&A industry-based in\n",
      "Germany. The results show that this nonparametric model provides accurate forecasts\n",
      "and also helps in finding an appropriate window size for other models. In conclusion,\n",
      "we provide an easy-to use solution for analyzing large data collections automatically\n",
      "that addresses the most common problems in time series modeling and can be adapted\n",
      "to diverse applications, including call center arrivals, sales forecasting or supply chain\n",
      "decisions.\n",
      "3.7 Future Work\n",
      "This work is subject to several limitations that are caused by additional complexity\n",
      "that exceeds the scope of this work. We evaluated only three German industries, chosen\n",
      "randomly. However, data for all industries in the US and Germany is available and\n",
      "could be used. The simulations showed that the proposed method had difficulties with\n",
      "detecting small changes in distribution. We also saw that the method is not in all cases\n",
      "better than choosing a simple approach using moving averages. An evaluation based on\n",
      "all 20 datasets could give further insights on the robustness of the method. Furthermore,\n",
      "the evaluation using a pseudo-out-of-sample point forecast is fairly limited and we justify\n",
      "the superiority of our approach based on the simple measure of a mean-squared-error.\n",
      "Diebold (2015) outlines that this approach provides no insurance against over-fitting\n",
      "and is computationally costly. Another questionable point is whether the occurrence\n",
      "of M&A per month strictly follows a time-varying Poisson process, as assumed in\n",
      "this paper. Fortunately, the simulation study shows that this assumption need not\n",
      "necessarily be fulfilled though.\n",
      "Answering these questions using a sophisticated evaluation approach through generating\n",
      "(multi-period) density forecasts would give more insights and could be an interesting\n",
      "area for future research. Future research could also evaluate the fit to a Poisson\n",
      "distribution with time-varying MLE, but with respect to different values of n0and\n",
      "c. Alternatively, other methods for determining the optimal number of tests to be\n",
      "performed to find balance between computational cost and accuracy can be developed.\n",
      "Finally, a possible extension could include a more general version of the current test\n",
      "statistic that looks into both directions.56 Bibliography\n",
      "Bibliography\n",
      "Ahern, K. R., & Harford, J. (2014). The Importance of Industry Links in Merger\n",
      "Waves [_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jofi.12122].\n",
      "The Journal of Finance ,69(2), 527–576. https://doi.org/10.1111/jofi.12122\n",
      "Akkus, O., Cookson, J. A., & Hortaçsu, A. (2015). The Determinants of Bank Mergers:\n",
      "A Revealed Preference Analysis [Publisher: INFORMS]. Management Science ,\n",
      "62(8), 2241–2258. https://doi.org/10.1287/mnsc.2015.2245\n",
      "Aminikhanghahi, S., & Cook, D. J. (2017). A Survey of Methods for Time Series\n",
      "Change Point Detection. Knowledge and information systems ,51(2), 339–367.\n",
      "https://doi.org/10.1007/s10115-016-0987-z\n",
      "Andrews, D. W. K., & Ploberger, W. (1994). Optimal Tests when a Nuisance Parameter\n",
      "is Present Only Under the Alternative [Publisher: [Wiley, Econometric Society]].\n",
      "Econometrica ,62(6), 1383–1414. https://doi.org/10.2307/2951753\n",
      "Arlot, S., Blanchard, G., & Roquain, E. (2010). Some nonasymptotic results on\n",
      "resampling in high dimension, I: Confidence regions [Publisher: Institute of\n",
      "Mathematical Statistics]. Annals of Statistics ,38(1), 51–82. https://doi.org/10.\n",
      "1214/08-AOS667\n",
      "Beran, R. (1986). Discussion: Jackknife, Bootstrap and Other Resampling Methods in\n",
      "Regression Analysis [Publisher: Institute of Mathematical Statistics]. Annals of\n",
      "Statistics ,14(4), 1295–1298. https://doi.org/10.1214/aos/1176350143\n",
      "Bianchi, D., & Chiarella, C. (2018). An Anatomy of Industry Merger Waves. Journal of\n",
      "Financial Econometrics ,17(2), 153–179. https://doi.org/10.1093/jjfinec/nby025\n",
      "Bücher, A., & Dette, H. (2013). Multiplier bootstrap of tail copulas with applica-\n",
      "tions [Publisher: Bernoulli Society for Mathematical Statistics and Probability].\n",
      "Bernoulli ,19(5A), 1655–1687. https://doi.org/10.3150/12-BEJ425\n",
      "Chatterjee, S., & Bose, A. (2005). Generalized bootstrap for estimating equations\n",
      "[Publisher: Institute of Mathematical Statistics]. Annals of Statistics ,33(1),\n",
      "414–436. https://doi.org/10.1214/009053604000000904\n",
      "Chen, J., & Gupta, A. K. (1999). Change point analysis of a Gaussian model. Statistical\n",
      "Papers,40(3), 323–333. https://doi.org/10.1007/BF02929878\n",
      "Chen, J., & Gupta, A. K. (2011). Parametric Statistical Change Point Analysis: With\n",
      "Applications to Genetics, Medicine, and Finance [Google-Books-ID: mwzCuR-\n",
      "MUVLIC]. Springer Science & Business Media.\n",
      "Chernozhukov, V., Chetverikov, D., & Kato, K. (2013). Gaussian approximations and\n",
      "multiplier bootstrap for maxima of sums of high-dimensional random vectors\n",
      "[Publisher: Institute of Mathematical Statistics]. Annals of Statistics ,41(6),\n",
      "2786–2819. https://doi.org/10.1214/13-AOS1161Bibliography 57\n",
      "Diebold, F. X. (2015). Comparing Predictive Accuracy, Twenty Years Later: A Personal\n",
      "Perspective on the Use and Abuse of Diebold–Mariano Tests [Publisher: Taylor\n",
      "& Francis]. Journal of Business & Economic Statistics ,33(1), 1–1. https:\n",
      "//doi.org/10.1080/07350015.2014.983236\n",
      "Diebold, F. X., Gunther, T. A., & Tay, A. S. (1998). Evaluating Density Forecasts with\n",
      "Applications to Financial Risk Management [Publisher: [Economics Department\n",
      "of the University of Pennsylvania, Wiley, Institute of Social and Economic\n",
      "Research, Osaka University]]. International Economic Review ,39(4), 863–883.\n",
      "https://doi.org/10.2307/2527342\n",
      "Eckley, I. A., Fearnhead, P., & Killick, R. (2011). Analysis of changepoint models\n",
      "[Library Catalog: www.cambridge.org Pages: 205-224 Publisher: Cambridge\n",
      "University Press]. https://doi.org/10.1017/CBO9780511984679.011\n",
      "Giraitis, L., Kapetanios, G., & Price, S. (2013). Adaptive forecasting in the presence of\n",
      "recent and ongoing structural change. Journal of Econometrics ,177(2), 153–170.\n",
      "https://doi.org/10.1016/j.jeconom.2013.04.003\n",
      "Gonzalez-Rivera, G., & Sun, Y. (2014). Density Forecast Evaluation in Unstable\n",
      "Environments (tech. rep. No. 201428) [Publication Title: Working Papers].\n",
      "University of California at Riverside, Department of Economics.\n",
      "Haccou, P., Meelis, E., & van de Geer, S. (1987). The likelihood ratio test for the\n",
      "change point problem for exponentially distributed random variables. Stochastic\n",
      "Processes and their Applications ,27, 121–139. https://doi.org/10.1016/0304-\n",
      "4149(87)90009-3\n",
      "Härdle, W. K., & Mammen, E. (1993). Comparing Nonparametric Versus Parametric\n",
      "Regression Fits [Publisher: Institute of Mathematical Statistics]. Annals of\n",
      "Statistics ,21(4), 1926–1947. https://doi.org/10.1214/aos/1176349403\n",
      "Härdle, W. K., Hautsch, N., & Mihoci, A. (2015). Local Adaptive Mul-\n",
      "tiplicative Error Models for High-Frequency Forecasts [_eprint:\n",
      "https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.2376]. Journal of\n",
      "Applied Econometrics ,30(4), 529–550. https://doi.org/10.1002/jae.2376\n",
      "Harford, J. (2005). What drives merger waves? Journal of Financial Economics ,77(3),\n",
      "529–560. https://doi.org/10.1016/j.jfineco.2004.05.004\n",
      "Hinkley, D. V., & Hinkley, E. A. (1970). Inference About the Change-Point in a\n",
      "Sequence of Binomial Variables [Publisher: [Oxford University Press, Biometrika\n",
      "Trust]].Biometrika ,57(3), 477–488. https://doi.org/10.2307/2334766\n",
      "Hsu,D.A.(1979).DetectingShiftsofParameterinGammaSequenceswithApplications\n",
      "toStockPriceandAirTrafficFlowAnalysis[Publisher:Taylor&Francis_eprint:\n",
      "https://www.tandfonline.com/doi/pdf/10.1080/01621459.1979.10481604]. Jour-\n",
      "nal of the American Statistical Association ,74(365), 31–40. https://doi.org/10.\n",
      "1080/01621459.1979.1048160458 Bibliography\n",
      "Hyndman, R. J., & Khandakar, Y. (2008). Automatic time series forecasting: The\n",
      "forecast package for r. Journal of Statistical Software, Articles ,27(3), 1–22.\n",
      "https://doi.org/10.18637/jss.v027.i03\n",
      "Inoue, A., Jin, L., & Rossi, B. (2017). Rolling window selection for out-of-sample\n",
      "forecasting with time-varying parameters. Journal of Econometrics ,196(1),\n",
      "55–67. https://doi.org/10.1016/j.jeconom.2016.03.006\n",
      "Klochkov, Y., Härdle, W. K., & Xu, X. (2019). Localizing Multivariate CAViaR.\n",
      "IRTG1792 Discussion paper , 48.\n",
      "Kolsarici, C., & Vakratsas, D. (2015). Correcting for Misspecification in Parameter\n",
      "Dynamics to Improve Forecast Accuracy with Adaptively Estimated Models\n",
      "[Publisher: INFORMS]. Management Science ,61(10), 2495–2513. https://doi.\n",
      "org/10.1287/mnsc.2014.2027\n",
      "Kutoyants, Y. A., & Spokoiny, V. (1999). Optimal choice of observation window for\n",
      "Poisson observations. Statistics & Probability Letters ,44(3), 291–298. https:\n",
      "//doi.org/10.1016/S0167-7152(99)00020-6\n",
      "Maksimovic, V., Phillips, G., & Yang, L. (2013). Private and Public Merger Waves [_-\n",
      "eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jofi.12055]. The Journal\n",
      "of Finance ,68(5), 2177–2217. https://doi.org/10.1111/jofi.12055\n",
      "Mammen, E. (1993). Bootstrap and Wild Bootstrap for High Dimensional Linear\n",
      "Models [Publisher: Institute of Mathematical Statistics]. Annals of Statistics ,\n",
      "21(1), 255–285. https://doi.org/10.1214/aos/1176349025\n",
      "Martynova, M., & Renneboog, L. (2005). A Century of Corporate Takeovers: What\n",
      "Have We Learned and Where Do We Stand? (previous title: The History of\n",
      "M&A Activity Around the World: A Survey of Literature) (SSRN Scholarly\n",
      "Paper No. ID 820984). Social Science Research Network. Rochester, NY.\n",
      "Mercurio, D., & Spokoiny, V. (2004). Statistical inference for time-inhomogeneous\n",
      "volatility models [Publisher: Institute of Mathematical Statistics]. Annals of\n",
      "Statistics ,32(2), 577–602. https://doi.org/10.1214/009053604000000102\n",
      "Oreshkin, B. N., Réegnard, N., & L’Ecuyer, P. (2016). Rate-Based Daily Arrival Process\n",
      "Models with Application to Call Centers [Publisher: INFORMS]. Operations\n",
      "Research ,64(2), 510–527. https://doi.org/10.1287/opre.2016.1484\n",
      "Pesaran, M. H., Pick, A., & Pranovich, M. (2013). Optimal forecasts in the presence of\n",
      "structural breaks. Journal of Econometrics ,177(2), 134–152. https://doi.org/\n",
      "10.1016/j.jeconom.2013.04.002\n",
      "Spokoiny, V. G. (1998). Estimation of a function with discontinuities via local polyno-\n",
      "mial fit with an adaptive window choice [Publisher: Institute of Mathematical\n",
      "Statistics]. The Annals of Statistics ,26(4), 1356–1378. https://doi.org/10.1214/\n",
      "aos/1024691246Bibliography 59\n",
      "Spokoiny, V. (2009). Multiscale local change point detection with applications to\n",
      "value-at-risk [Publisher: Institute of Mathematical Statistics]. The Annals of\n",
      "Statistics ,37(3), 1405–1436. https://doi.org/10.1214/08-AOS612\n",
      "Spokoiny, V., & Zhilova, M. (2015). Bootstrap confidence sets under model misspeci-\n",
      "fication [Publisher: Institute of Mathematical Statistics]. Annals of Statistics ,\n",
      "43(6), 2653–2675. https://doi.org/10.1214/15-AOS1355\n",
      "Taylor, J. W. (2007). A Comparison of Univariate Time Series Methods for Forecasting\n",
      "Intraday Arrivals at a Call Center [Publisher: INFORMS]. Management Science ,\n",
      "54(2), 253–265. https://doi.org/10.1287/mnsc.1070.0786\n",
      "Taylor, J. W. (2011). Density Forecasting of Intraday Call Center Arrivals Using Models\n",
      "Based on Exponential Smoothing [Publisher: INFORMS]. Management Science ,\n",
      "58(3), 534–549. https://doi.org/10.1287/mnsc.1110.1434\n",
      "Very, P., Metais, E., Lo, S., & Hourquet, P. -G. (2012). Can We Predict M&A Activity?\n",
      "In S. Finkelstein & C. L. Cooper (Eds.), Advances in Mergers and Acquisitions\n",
      "(pp. 1–32). Emerald Group Publishing Limited. https://doi.org/10.1108/S1479-\n",
      "361X(2012)0000011004\n",
      "Wu, C. F. J. (1986). Jackknife, Bootstrap and Other Resampling Methods in Regression\n",
      "Analysis [Publisher: Institute of Mathematical Statistics]. Annals of Statistics ,\n",
      "14(4), 1261–1295. https://doi.org/10.1214/aos/1176350142\n",
      "Yelland, P. M., Kim, S., & Stratulate, R. (2010). A Bayesian Model for Sales Forecasting\n",
      "at Sun Microsystems [Publisher: INFORMS]. Interfaces ,40(2), 118–129.Chapter 4\n",
      "Surrogate Models for Optimization of\n",
      "Dynamical Systems\n",
      "Publication\n",
      "Khowaja K, Shcherbatyy M, Härdle WK (2021) Surrogate Models for Optimization\n",
      "of Dynamical Systems, \"Foundations of Modern Statistics\", Springer Proceedings in\n",
      "Mathematics & Statistics\n",
      "4.1 Introduction\n",
      "Over the years, mathematical modeling and optimization techniques have effectively\n",
      "described complex real-life dynamical structures using system of differential equations.\n",
      "More often, the dynamical behavior of such models, especially in optimization and\n",
      "inverse problems (the problems where some of the ’effects’ (responses) are known but\n",
      "not some of the ’causes’ (parameters) leading to them are unknown), cause necessity of\n",
      "repetitive solution of these model equations with a slight change in system parameters.\n",
      "This parameter exploration process can be computationally intense, specially in complex\n",
      "non-linear systems. While numerical models replaced experimental methods due to their\n",
      "robustness, accuracy, and rapidness, their increasing complexity, high cost, and long\n",
      "simulation time have limited their application in domains where multiple evaluations\n",
      "of the model differential equations are demanded.\n",
      "To prevent this trade-off between computational cost and accuracy, one needs to focus\n",
      "on reduced order models (ROMs) which provide compact, accurate and computationally\n",
      "efficient representations of ODEs and PDEs to solve these multi-query problems. These\n",
      "approximation models, also commonly recognized as a surrogate models or meta-\n",
      "models Shcherbatyy and Shcherbata (2018), allow the determination of solution of\n",
      "model equations for any arbitrary combination of input parameters at a cost that is\n",
      "independent of the dimension of the original problem. They reduce the computational\n",
      "time for solution of the complex optimization problems by using training instances\n",
      "derived from the evaluations of the true objective functions. Accordingly, they meet\n",
      "the most essential criteria of every analysis problem: the criteria of highest fidelity\n",
      "at lowest possible computational cost, where high fidelity is defined by the efficacy of\n",
      "604.1. INTRODUCTION 61\n",
      "theoretical methods to replicate the physical phenomenons with least possible error\n",
      "Iulianoa and Quagliarellaa (2013).\n",
      "In this work, we use Proper Orthogonal Decomposition (POD), a model reduction\n",
      "techniquethatoriginatedinstatisticalanalysisandisknownforitsoptimality, capturing\n",
      "the most dominant components of data in an efficient way Hinze and Volkwein (2005).\n",
      "POD serves the purpose of dimension reduction by extracting hidden structures from\n",
      "high dimensional data and projecting it on lower dimensional space consisting of basis\n",
      "elements that contain characteristics of the expected solution Kerschen et al. (2005).\n",
      "We use POD to derive low order models of dynamical system by reducing a large\n",
      "number of interdependent variables to a much smaller number of uncorrelated variables,\n",
      "while preserving as much as possible of the variation in the original variables, in an\n",
      "iterative fashion. We hypothesize that the system responses of dynamical models can\n",
      "be obtained with a very high accuracy, but lower computational cost using this model\n",
      "reduction technique.\n",
      "The novelty of this research is three-fold: 1) POD is combined with interpolation\n",
      "methods in an iterative procedure, which is an improved methodology for construction\n",
      "of highly accurate surrogate models; 2) the methodology has been extended to optimal\n",
      "control problems which has rarely been explored in the literature; 3) the combination\n",
      "of POD and radial basis functions (RBF) for surrogate models is quite under utilized\n",
      "for the the economic models, some of which are discussed in this paper.\n",
      "The computational procedure used in this research is decomposed between offline and\n",
      "online phases. The offline phase (training of the model) entails utilization of sampling\n",
      "techniques to generate data, computation of snapshot matrix of model solutions using\n",
      "variable order methods for solving ODEs (associated with the dynamical systems),\n",
      "obtainment of proper orthogonal modes via Singular Value Decomposition (SVD)\n",
      "and estimation of POD expansion coefficients that approximate the POD basis (via\n",
      "interpolation techniques radial basis functions).\n",
      "Next, the model quality is evaluated by carrying out error analysis on various experi-\n",
      "mental designs. These experimental designs are created by varying sampling strategies,\n",
      "interpolation techniques and the size of training set. Using the optimal experimental\n",
      "design, the online phase of algorithm starts. The online phase (testing of the model)\n",
      "involves redefinition of model equations in terms of surrogate models and computation\n",
      "of system responses corresponding to any arbitrary set of input parameters in given\n",
      "domain Shcherbatyy and Shcherbata (2018).\n",
      "Finally, using the optimal experimental design, we solve optimal control problems using\n",
      "both models to evaluate accuracy of the surrogate model. If the error tolerance is not62 CHAPTER 4. SURROGATE MODELS\n",
      "met, an iterative algorithm is implemented to enhance the performance of the surrogate\n",
      "model. All codes used for the analysis in this paper are available on www.quantlet.de\n",
      "The remainder of this paper is organized as follows. In the next section, we summarize\n",
      "the research on the surrogate models, and identify the limitations of existing literature.\n",
      "In section 4.3, we explain in detail theoretical concepts related to POD, SVD and\n",
      "RBF, and how these are used to construct surrogate models. In section 4.4, we\n",
      "discuss the newly proposed iterative algorithm. The perspective of our methodology is\n",
      "demonstrated with practical examples of dynamical systems in section 4.5. Finally, we\n",
      "conclude the main results and provide a summary of current research, limitations, as\n",
      "well as the future prospects of this research in the last section.\n",
      "4.2 Literature Review\n",
      "Over a century ago, Pearson proposed the idea of representing the statistical data in\n",
      "high dimensional space using a low dimensional straight line or plane, hence discovering\n",
      "a finite dimensional equivalence of POD as a tool for graphical analysis Pearson\n",
      "(1901). In the years following Pearson’s paper, the technique has been independently\n",
      "rediscovered by several other scientists including Kosambi, Hotelling and Van Loan\n",
      "under different names in the literature such as principle component analysis (PCA),\n",
      "Hotelling Transformation and Loeve-Karhunen Expansion, depending on the domain in\n",
      "which it is used. Despite their early discovery, the computational resources required to\n",
      "compute POD modes were limited, and the technique remained virtually unused until\n",
      "the 1950s. The technological advancements subsequently took off with the massive\n",
      "increase in computing power, leading to the popularity of POD Kerschen et al. (2005).\n",
      "Since then, the development and applications of POD have been widely investigated in\n",
      "various disciplines such as structural mechanics Kerschen et al. (2005), Aerodynamics\n",
      "Iulianoa and Quagliarellaa (2013), Signal and Image Processing Benaarbia and Chryso-\n",
      "choos (2017), etc. Due to its strong theoretical foundations, the technique has been\n",
      "used in many applications, such as for damage detection Lanata and Grosso (2006),\n",
      "human face recognition Sirovich and Kirby (1987), detection of signals in multi-channel\n",
      "time-series Wax and Kailath (1985), exploration of peak clustering Berardi et al. (2015)\n",
      "and many more.\n",
      "In general, a non-equivalent variant of POD, known as factor analysis, has been\n",
      "renowned and has been used for various applications Adongo et al. (2015), A. Bai et al.\n",
      "(2015), J. Bai and Wang (2016), and Maravalle and Rawdanowicz (2018), etc. Unlike\n",
      "POD, factor analysis assumes that the data have a strict factor structure and it looks\n",
      "for the factors that amount for common variance in the data. On contrary, PCA the\n",
      "finite counterpart of POD, allows the accountability of maximal amount of variance for4.2. LITERATURE REVIEW 63\n",
      "observed variables. The PCA analysis consists of identifying the set of variables, also\n",
      "known as principle components, from the system that retain as much variation from\n",
      "the original set of variables as possible. Similarly, principal expectile analysis (PEC),\n",
      "which generalizes PCA for expectiles was recently developed as a dimension reduction\n",
      "tool for extreme value theory Tran et al. (2019). These POD equivalent tools have also\n",
      "been adopted in analysis on several instances such as Adongo et al. (2015), Chen et al.\n",
      "(2018), Li et al. (2018), Lin et al. (2021), and Tran et al. (2019). Yet, most of these\n",
      "sources exploit only the real life data for dimension reduction.\n",
      "Even though the real life data can be very useful in analysis, complete data on relevant\n",
      "dynamical systems is rarely available. This creates an urgent need for the introduction\n",
      "of tools that utilize simulated data. The simulated data can be easily generated by\n",
      "repetitive evaluations of the original set of differential equations using so-called ’method\n",
      "of snapshots’. Bujlak Bujlak (2012) explains how a simulation based matrix is obtained\n",
      "by evaluating the original set of equations with various parameter combinations. The\n",
      "resulting snapshot matrix allows easy implementation of data analytical and smoothing\n",
      "tools for reducing the dimensionality of the dynamical systems.\n",
      "Very recently, researchers have tried to couple various smoothing methods with POD\n",
      "to improve the performance of surrogate models. In Iulianoa and Quagliarellaa (2013),\n",
      "the authors construct a POD+cubic spline surrogate model for an aerodynamic design\n",
      "problem. Similarly, the POD+neural network framework for solving finite element\n",
      "models is proposed in Im et al. (2021). Some of these sources also recognize problem\n",
      "with these surrogate models, such as Chang et al. (2021) in which the authors remedy\n",
      "the common problem of high training time in smoothed POD models using Hadamard\n",
      "product.\n",
      "Another well known issue with the surrogate models is that some times they result\n",
      "in low accuracy due to occurrence of solution on the boundaries. One way to deal\n",
      "with this issue is to examine the efficacy of POD+RBF surrogate models using various\n",
      "pre-processing methods for the snapshot matrix Gooijer et al. (2021). One can then\n",
      "examine the errors due to truncation through POD and due to interpolation of the\n",
      "data. Another solution is presented in Zimmermann (2013) where surrogate modelling\n",
      "techniques are enhanced by incorporating derivatives of snapshots for the training.\n",
      "Analternativemethodfordealingwithissueistochangethewaysnapshotsareobtained.\n",
      "In this paper, we propose to deal with this problem by using various sampling methods\n",
      "and an iterative training procedure that truncates the domain of sampling at each step,\n",
      "which provides an improved method for construction of the surrogate models. We will\n",
      "discuss this technique in detail in section 4.4, but first, we present the mathematical64 CHAPTER 4. SURROGATE MODELS\n",
      "framework for the POD+RBF surrogate modelling technique.\n",
      "4.3 Mathematical Framework\n",
      "Model reduction techniques have been known for their ability to reduce the computa-\n",
      "tional complexity of mathematical models involving numerical simulations. The main\n",
      "reason for increasing applications of ROMs in various disciplines is due to its strong\n",
      "theoretical foundations. Also, computational complexities of high dimensional physical\n",
      "system is ever-so-rising, which has created demand for the model reduction techniques.\n",
      "ROMs address these issues effectively by providing low dimensional approximations of\n",
      "the high dimensional systems.\n",
      "Although a variety of dimensionality-reduction techniques exist, for example operational\n",
      "based reduction methods Schilders et al. (2008), reduced basis methods Boyaval et al.\n",
      "(2010), the ROMs are often based upon POD. Analogous to PCA, the POD theory\n",
      "find components of the systems, known as Proper Orthogonal Modes (POMs), that are\n",
      "ordered in a way that each subsequent mode holds less energy than previous one. As\n",
      "stated earlier, POD is ubiquitous in the dimensionality reduction of physical systems.\n",
      "It presents the optimal technique for capturing the system modes in least square sense.\n",
      "That is, for constructing ROM for any system, incorporating kPOMs will give the\n",
      "bestkcomponent approximation of that system. This assures that any approximation\n",
      "obtained using POD will be the best possible approximation: there is no other method\n",
      "that can reduce the dimensionality of the given system in lower number of components\n",
      "or modes.\n",
      "In this section, we discuss the mathematical concepts associated with POD and\n",
      "its correspondence with SVD and RBF for construction of surrogate models. The\n",
      "computational procedure presented in the sections 4.4 and 4.5 is strictly based on the\n",
      "theory formulated in this section.\n",
      "4.3.1 Optimal Control Problem for Dynamical Systems\n",
      "Many problems of optimal control are focused on the minimization and maximization\n",
      "problems. In order to find an optimal set of parameters, optimization models are\n",
      "usually defined in which the problems are summarized by the objective function.\n",
      "These optimization parameters are called control parameters and they affect the choice\n",
      "of allocation. In optimal control problems, these parameters are time paths which\n",
      "are chosen within certain constraints so as to minimize or maximize the objective\n",
      "functional. The applications presented in section 4.5 are optimization problems, the\n",
      "general structure of which has been discussed in the next paragraph.\n",
      "Let us consider optimization problem which consists of finding a vector of optimization\n",
      "parameters u∗∈USand proper state function y∗⊂YSthat minimizes the optimization4.3. MATHEMATICAL FRAMEWORK 65\n",
      "criterion (objective function)\n",
      "ψ0=ψ˜0(u∗, y∗) = min\n",
      "(u,y)∈US×YSψ˜0(u, y) (4.1)\n",
      "subject to ODEs (state equation)\n",
      "c(y, u) = 0∼{︄\n",
      "y′\n",
      "i−f(t, u, y ) = 0 , t∈[t0, T],\n",
      "y(t0)−y0= 0,(4.2)\n",
      "box constrains on the control variable\n",
      "U={u∈US:u−≤u≤u+, u−∈US, u+∈US} (4.3)\n",
      "and possibly additional equality and non-equality constraints on state and control\n",
      "ψj˜(u, y) = 0 , j= 1, . . . , m 1,\n",
      "ψj˜(u, y)≤0, j=m1+ 1, . . . , m.(4.4)\n",
      "where USandYSare real Banach spaces, u=u(t) = [ u1(t), . . . , u nu(t)]⊤∈US, y=\n",
      "y(t) = [y1(t), . . . , y ny(t)]⊤∈YS, ψj˜:US×YS→R, j= 0,1, . . . , m\n",
      "We assume that for each u∈U, there exists a unique solution y(u)of state equation\n",
      "c(y, u) = 0. For rest of the paper, we will use the compact notation of the optimization\n",
      "problem (4.1- 4.4) in its reduced form: find a function u∗such that\n",
      "u∗∈U∂u, ψ0(u∗) = min\n",
      "u∈U∂uψ0(u)\n",
      "U∂u={u:u∈U;ψj(u) = 0 , j= 1, . . . , m 1;ψj(u)≤0, j=m1+ 1, . . . , m }\n",
      "c(y(u), u) = 0\n",
      "ψj(u) =ψ˜j(u, y(u)), j= 0,1, . . . , m(4.5)\n",
      "The optimal control problems in this research are solved using direct method. In the\n",
      "direct method, each problem is transformed to nonlinear programming problem, i.e., it\n",
      "is first discretized and then the resulting nonlinear programming problem is optimized.\n",
      "The optimality conditions of undiscretized optimal control problems need to be re-\n",
      "established for each new problem. They also often require partial a-priori knowledge\n",
      "of the mathematical structure of the solution which in general is not available for66 CHAPTER 4. SURROGATE MODELS\n",
      "many practical problems. Therefore, direct methods are preferred because optimality\n",
      "conditions are generic for the discretized optimal control problems.\n",
      "The first step of the direct method is to approximate each component of the control\n",
      "vector by a function of finite parameters ui(t) =ui(t, b(i)), b(i)= [b(i)\n",
      "1, ..., b(i)\n",
      "ni]⊤, i=\n",
      "1, . . . , n u. As a result, we write control function u(t)as a function of vector of\n",
      "optimization parameters b:u(t) =u(t, b). In this paper we use a piecewise-linear or\n",
      "piecewise-constant approximation for each function ui(t), i= 1, . . . , n u.\n",
      "The optimization problem can be written as nonlinear programming problem as\n",
      "following: find a vector b∗such that\n",
      "b∗∈U∂, ψ0(b∗) = min\n",
      "b∈U∂ψ0(b)\n",
      "U∂={b:b∈Ub, ψj(b) = 0 , j= 1, . . . , m 1;ψj(b)≤0, j=m1+ 1, . . . , m }\n",
      "Ub={b:b∈Rn, b−≤b≤b+, b−∈Rn, b+∈Rn}\n",
      "c(y(b), b) = 0\n",
      "ψj(b) =ψ˜j(u(b), y(b)), j= 0,1, . . . , m(4.6)\n",
      "4.3.2 Surrogate Models for Optimization Problems\n",
      "The optimization problem formulated in equation (4.6) used for estimation of parameter\n",
      "values is often computationally expensive. It requires repetitive solutions of the state\n",
      "equation c(y(b), b) = 0and the objective function ψ˜0, subject to the constraints\n",
      "ψ˜j, j= 1, . . . , mfor different values of optimization parameters b. In order to solve\n",
      "multi-queryproblemswithlimitedcomputationalresources, oftenapproximationmodels\n",
      "(also known as surrogates models, meta-models or ROMs) are used. Surrogate models\n",
      "replace the high-fidelity models and tend to have lower numerical complexity, and\n",
      "hence less computational cost.\n",
      "The first step for construction of the surrogate models is to select an appropriate\n",
      "sampling strategy. Once nssampling points are generated, the state equation (4.6)\n",
      "(ODEs) is solved for each sample point b(i). The resulting nsvectors of solutions\n",
      "(snapshots) Yi=[︂\n",
      "y(︁\n",
      "t1, b(i))︁⊤, . . . , y(︁\n",
      "tnt, b(i))︁⊤]︂⊤\n",
      "∈Rm, m=ny×ntat different time\n",
      "instances, t0< t1< t2< . . . < t nt=Tare called snapshots vectors Yi. The snapshot\n",
      "vectors collectively create the snapshot matrix Y= [Y1, Y2, . . . , Y n]∈Rm×ns.\n",
      "Initial sampling and method of snapshots\n",
      "The method of snapshots for POD was first introduced by Sirovich Sirovich (1987)\n",
      "in 1987. Generally, it comprises of evaluating the model equations for the number of\n",
      "sampling points at various time instances. Each model response is called snapshot and\n",
      "is recorded in a matrix which is collectively called snapshot matrix.4.3. MATHEMATICAL FRAMEWORK 67\n",
      "The initial dimension of the problem is equal to the number of snapshots nsrecorded\n",
      "at each time instance ti, i= 1, ..., n t. These points are selected from the parameter\n",
      "space using some sampling technique. In general, the sampled points should represent\n",
      "the dynamic behaviour of the system. Many researchers simply use the random or\n",
      "uniform sampling, however there is no standard method for generating the sampling\n",
      "points. Nevertheless, the choice of sampling method has direct effects on the accuracy\n",
      "of the model and therefore, it is regarded as an autonomous problem. This research\n",
      "briefly explores the initial sampling problem by comparing various classical a-priori\n",
      "methods of sampling.\n",
      "We propose to use Latin Hypercube Sampling (LHS) and its variant Symmetric Latin\n",
      "Hypercube Sampling (SLHS) for sampling. LHS is a memory-based, near-random\n",
      "sampling technique that aims at spreading the sample points evenly across the surface.\n",
      "In statistics, a square grid containing sample positions is a latin square if and only if\n",
      "there is only one sampling point in each row and each column. A latin hypercube is\n",
      "the generalization of this concept to an arbitrary number of dimensions, whereby each\n",
      "sample is the only one in each axis-aligned hyperplane containing it. Unlike random\n",
      "sampling (RS), which is frequently referred as Monte-Carlo method in finance, LHS\n",
      "uses a stratified sampling techniques that remembers the position of previous sampling\n",
      "point and shuffles the inputs before determining the next sampling points. It has been\n",
      "considered to be more efficient in a large range of conditions and proven to have faster\n",
      "speed and lower sampling error than RS Chrisman (2014).\n",
      "SLHS is an extension of LHS that achieves the purpose of optimal design in a relatively\n",
      "moreefficientway. SLHSalsohashigherminimumdistancebetweenrandomlygenerated\n",
      "points than LHS. In a nutshell, both LHS and SLHS are hypothesized to perform better\n",
      "than RS. Nevertheless, sampling is performed using all three techniques in this work to\n",
      "determine which techniques provides optimal sampling of the underlying space and\n",
      "maximizes the system accuracy. A simple sampling distribution of each of the three\n",
      "techniques is illustrated in Figure 4.1.\n",
      "Figure 4.1: Comparison of various sampling techniques.\n",
      " SurrogateModel\n",
      "We discuss the utility of these sampling techniques, and how they are used for surrogate\n",
      "modelling in the next sections. The deeper questions of sampling that relate to the68 CHAPTER 4. SURROGATE MODELS\n",
      "choice of surrogate model, nature of the objective function and analysis are left for the\n",
      "reader to explore from recommended sources such as Iulianoa and Quagliarellaa (2013).\n",
      "Model order reduction\n",
      "The overarching goal of POD method is to provide a fit of the desired data by extracting\n",
      "interpolation functions from the information available in the data set. Geometrically, it\n",
      "derivesproperorthogonalmodesbyprojectingtheoriginalmodelontothereducedspace\n",
      "spanned by the POD modes Iulianoa and Quagliarellaa (2013). A simple mathematical\n",
      "formulation of POD technique is laid out in this subsection which closely follow the\n",
      "references Bujlak (2012), Chatterjee (2000), and Shcherbatyy and Shcherbata (2018).\n",
      "Suppose that we wish to approximate the response of the system given by output\n",
      "parameters y∈Rm, where m=ny×nt, using the set of input parameters b⊂Rnu\n",
      "over a certain domain Ω. The ROMs approximate the state function y(t) in domain Ω\n",
      "using linear combination of some basis function ϕi(x)such that\n",
      "y(t)≈M∑︂\n",
      "i=1ai.ϕi(t) (4.7)\n",
      "where, aiare unknown amplitudes of the expansions and tis the temporal coordinate.\n",
      "The first step in this process would be to find the basis. Once the basis function is\n",
      "chosen, the amplitudes can be easily determined by a minimization process. It is ideal\n",
      "to take orthonormal set as the basis with the property\n",
      "∫︂\n",
      "Ωϕk1(t). ϕk2(t)dx={︄\n",
      "1k1=k2\n",
      "0k1̸=k2(4.8)\n",
      "This way, the determination of the amplitudes akonly depends on function ϕi\n",
      "k(t)and\n",
      "not on any other ϕ. Along with being orthonormal, the basis should approximate\n",
      "the function in best possible way in terms of the least square error. These ordered\n",
      "orthogonal functions are called the POMS for the function y(t)and the equation (4.7)\n",
      "is called the POD of y(t).\n",
      "In order to determine the number of POMs that should be used in approximation of\n",
      "lower dimensional space, we use the idea that POD inherently orders the basis elements\n",
      "by their relative importance. This idea is used very often in statistics with singular\n",
      "value decomposition of the matrices. Since the theory of SVD is so widespread, we only\n",
      "highlight the most general and relevant details of SVD that are helpful in derivation of\n",
      "POMs and POD basis.\n",
      "There prevails a misconception amongst researchers about distinction between SVD\n",
      "and POD. As opposed to the common understanding, POD and SVD are not strictly4.3. MATHEMATICAL FRAMEWORK 69\n",
      "the same: the former is a model reduction technique where as the latter is merely a\n",
      "method of calculating the orthogonal basis.\n",
      "In general, SVD is a technique that is used to decompose any real rectangular matrix\n",
      "Yinto three matrices, U,ΣandV, whereUandVare orthogonal matrices, Σis a\n",
      "diagonal matrix that contains the singular values σiofY, sorted in a decreasing order\n",
      "such that σ1≥σ2≥...≥σd≥0, anddis the number of non-zero singular values of Y.\n",
      "The singular values can then be used as a guide to determine the POD basis. If a\n",
      "k-dimensional approximation of original surface is required, where the rank k<d. The\n",
      "firstkcolumns of the matrix Userve as the basis ϕi, i= 1, ..., k. These set of columns,\n",
      "gathered in matrix Φ, form an orthonormal set of basis for our new low-dimensional\n",
      "surface.\n",
      "The relative magnitude of each singular value with respect to all the others give a\n",
      "measure of importance of the corresponding eigen function in representing elements\n",
      "of the input collection. Based on the same idea, a common approach for selection\n",
      "of number of POMs ( k) is to set a desired error margin ϵPODfor the problem under\n",
      "consideration and choose kas a minimum integer such that the cumulative energy E(k)\n",
      "captured by first ksingular values (now POMs) is less than 1- ϵPOD, i.e.\n",
      "E(k) =k∑︂\n",
      "i=1σ2\n",
      "i\n",
      "d∑︂\n",
      "i=1σ2\n",
      "i≤1−ϵ2\n",
      "POD (4.9)\n",
      "After collection of basis using SVD, it is easy to calculate the matrix of amplitudes Ak.\n",
      "LetΣk= [σ1, σ2, ..., σ k]be the set of klargest singular values of our initial matrix Y,\n",
      "then, the matrix of amplitudes is given by Yk= Σ kAk, Ak= Σ⊤\n",
      "kYk.\n",
      "With the basis vectors and amplitude matrix, using POD discrete theory, low dimen-\n",
      "sional approximation of our problem has been constructed. However, the formulation\n",
      "is not very useful since our new model can only give the responses of the system for\n",
      "a discrete number of parameter combinations (those that were previously used to\n",
      "generate the snapshot matrix). Since, in many practical applications (for optimization\n",
      "and inverse analysis), even though the values of input parameters may sometime fall in\n",
      "a particular range, the parameter values are not known a-priori and can assume any\n",
      "arbitrary value between those ranges. Therefore, we take a step further to approximate\n",
      "the newly constructed model. We combine POD with RBF interpolation to create\n",
      "low-order parameterization of high-order systems for accurate prediction of system70 CHAPTER 4. SURROGATE MODELS\n",
      "responses.\n",
      "RBF is a unique interpolation technique that determines one continuous function\n",
      "defined over the whole domain. It is a widely used for smoothing and multidimensional\n",
      "approximation. Let Ykbe the reduced dimensional matrix. For better approximation\n",
      "of the surrogate model, we want to find a continuous function f(b) =y, where bis the\n",
      "vectors of some parameters and yis the system response. It can be achieved easily by\n",
      "applying RBF to reduced dimensional space where system responses are expressed as\n",
      "amplitudes in the matrix Ak. Hence,\n",
      "f(b) =y= Σ kAk= Σ kfa(b) =ϕfa(b) (4.10)\n",
      "When RBF is applied for the approximation of fa,fais written as linear combination\n",
      "of some basis functions gisuch that\n",
      "fa(b) =⎡\n",
      "⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣ai\n",
      "1\n",
      "ai\n",
      "2\n",
      ".\n",
      ".\n",
      ".\n",
      "ai\n",
      "K⎤\n",
      "⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦=⎡\n",
      "⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣d11\n",
      "d21\n",
      ".\n",
      ".\n",
      ".\n",
      "dK1⎤\n",
      "⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.g1(b) +⎡\n",
      "⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣d12\n",
      "d22\n",
      ".\n",
      ".\n",
      ".\n",
      "dK2⎤\n",
      "⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.g2(b) +...+⎡\n",
      "⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣d1N\n",
      "d2N\n",
      ".\n",
      ".\n",
      ".\n",
      "dKN⎤\n",
      "⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.gN(b) =D.g(b)(4.11)\n",
      "In this work, we use linear and cubic spline RBF for analysis, given by:\n",
      "linear spline :gj(b) =||b−bj||;cubic spline :gj(b) =||b−bj||3; (4.12)\n",
      "Oncethebasisfunctions giareknown, theaimistosolvefortheinterpolationcoefficients\n",
      "that are collectively stored in matrix B. Since we already have the value of amplitudes\n",
      "Afrom last step, matrix Bcan be easily obtained by using the equation B=G−1A.\n",
      "Finally, using equation (4.10), our initial space ycan be approximated by:\n",
      "y≈Φ.D.g(b) =yˆ (4.13)\n",
      "Since matrix ΦandDare calculated once for all, one only needs to compute the vector\n",
      "g(b)for any arbitrary combination of parameters to obtain system responses.\n",
      "We have constructed surrogate model using POD and RBF to calculate the value\n",
      "of functionals ψˆj(b) =ψ˜j(b, yˆ), j= 0,1, . . . , m. The formulation of optimal control4.4. ENHANCED SURROGATE MODELS 71\n",
      "problem for surrogate models is to find a vector bˆ∗such that:\n",
      "bˆ∗∈U∂, ψˆ0(︂\n",
      "bˆ∗)︂\n",
      "= min\n",
      "b∈U∂ψˆ0(b)\n",
      "U∂={︂\n",
      "b:b∈Ub, ψˆj(b) = 0 , j= 1, . . . , m 1;ψˆj(b)≤0, j=m1+ 1, . . . , m}︂\n",
      "Ub={b:b∈Rn, b−≤b≤b+, b−∈Rn, b+∈Rn}\n",
      "yˆ =S(b)\n",
      "ψˆj(b) =ψ˜j(u(b), yˆ), j= 0,1, . . . , m(4.14)\n",
      "Replacing the state equation (4.2) with surrogate model given in equation (4.13) can\n",
      "decrease the computational time by a significant amount. It is free of the complexity of\n",
      "initial problem and involves matrix multiplication that can be accomplished in a much\n",
      "smaller time than solving ordinary differential equations with high fidelity methods.\n",
      "We test this hypothesis by comparing the accuracy of system responses and time of\n",
      "calculation for both equation (4.2) and equation (4.13) for real life examples in section\n",
      "4.5.\n",
      "We evaluate the accuracy of responses by generating ngtest points for the set of\n",
      "parameters P, using the same sampling technique that had been used for generation\n",
      "of training test. For these new points, we calculate the system responses Yg=\n",
      "[y1, y2, ..., y ng]∈Rm×ngusing initial numerical method (that solves entire system), and\n",
      "newly constructed surrogate model Yˆg= [yˆ1, yˆ2, ..., yˆng]∈Rm×ng. We use relative\n",
      "maximum absolute error (RMAE) to determine the accuracy of the optimization results\n",
      "given by:\n",
      "RMAE = max\n",
      "1≤i≤mmax\n",
      "1≤j≤ng|yji−yˆji|\n",
      "yji(4.15)\n",
      "4.4 Enhanced Surrogate Models\n",
      "While POD-RBF surrogate models presented in equations (4.3) are usually accurate,\n",
      "sometimes the desired accuracy of the model is not achieved. This usually occurs\n",
      "because either the initial sampling does not truly represent the true behaviour of\n",
      "the dynamical system, or system’s optimal values occur at the corner points and the\n",
      "predictive models in general tend to perform poorly on extreme ends. One common\n",
      "approach to overcome this issue is to use adaptive sampling, a method that has\n",
      "been used by many researchers such as Iulianoa and Quagliarellaa (2013) to find\n",
      "optimal design space points. In Garud et al. (2016), the authors compare the adaptive\n",
      "sampling technique with uniform and random sampling and show the effectiveness of\n",
      "this approach in generating enough data points in the most plausible regions. However,\n",
      "this technique involves solving a series of point placement non-linear programming\n",
      "problems for optimization and the repetitive nature of this procedure can still have a72 CHAPTER 4. SURROGATE MODELS\n",
      "high computational cost.\n",
      "In this paper, we deal with the sampling issue in two ways— we first propose to\n",
      "use non-random, memory based sampling techniques that assist in diversifying the\n",
      "training sample, as discussed in the previous section. Secondly, we develop an iterative\n",
      "algorithm which recursively shifts the domain of training to direct the surrogate model\n",
      "towards finding the true optimal solutions. The combination of these approaches result\n",
      "in highly accurate solutions as demonstrated in the next section.\n",
      "The choice of sampling techniques obviously affects the accuracy of the surrogate model.\n",
      "Therefore, we would like to compare the various sampling methodologies discussed in\n",
      "section 4.3. We combine each sampling technique with varying number of training\n",
      "points and various interpolation techniques, and treat it as a separate experimental\n",
      "designs in our research. We compare these experimental designs to determine which\n",
      "setup results in the highest accuracy while satisfying the time constraints for generation\n",
      "of the snapshots.\n",
      "The algorithm for constructing surrogate models can be divided into three parts:\n",
      "experimental design, offline phase and online phase. The offline phase (training of\n",
      "the model) entails utilization of sampling techniques to generate data, computation of\n",
      "snapshot matrix of model solutions, obtainment of proper orthogonal modes via singular\n",
      "value decomposition and estimation of POD expansion coefficients that approximate\n",
      "the POD basis via RBFs. Then comes a pseudo-testing phase (testing to find the best\n",
      "experimental design) where the surrogate models from the offline phase are used to\n",
      "solve the dynamical system and the overall error of approximation is used to select the\n",
      "best experimental design.\n",
      "Note that until this point, only the system of ODEs is solved, and the accuracy of the\n",
      "original and surrogate system responses is compared to decide the best experimental\n",
      "design. Once the best sampling strategy and corresponding number of training points,\n",
      "and interpolation technique are decided, the algorithm enters in its online phase (testing\n",
      "phase) in which the surrogate model responses are used to solve the optimal control\n",
      "problem and the error between true and surrogate optimal values is calculated. If the\n",
      "error exceeds the given threshold, the iterative algorithm is activated.\n",
      "The iterations caters to the aforementioned low-accuracy issue in two ways. Firstly, it\n",
      "trains the initial model with the sampling points from a slightly wider domain than\n",
      "the domain in which the optimization is performed. This way, the corner points are\n",
      "incorporated into the sampling space and surrogate model tends to provide better\n",
      "approximation for the optimal points. Secondly, in order to minimize the error of\n",
      "approximation, the algorithm allows to decrease the width of domain of control pa-4.4. ENHANCED SURROGATE MODELS 73\n",
      "Figure 4.2: Example of iterative algorithm of two optimization parameters b1andb2with\n",
      "iterations i= 1, . . . , 5and recursively decreasing lengths li, i= 1, . . . , 5\n",
      "rameters at each iteration. By decreasing the size of sampling space, the sampling\n",
      "points move closer to each other. Even if the corner points are not accounted for in the\n",
      "sampling design, the smallest distance between the corner and the neighboring points is\n",
      "lower in smaller domain, hence resulting in better approximation and higher accuracy.\n",
      "The iterative algorithm becomes active every time the error of approximation is higher\n",
      "than the tolerance level.\n",
      "4.4.1 Iterative Algorithm\n",
      "The iterative process can be summarized in four steps:\n",
      "1.Initialization: In this step, the parameters of algorithm are initialized. This\n",
      "includes width (the length of domains of control parameters), desired tolerance\n",
      "level and b(0)=initial guess for b(the optimization parameters)\n",
      "2.Setting up the bounds: In this step, upper and lower bounds of domain are\n",
      "defined for each control parameter. It is done by taking b(0), interpolating it and\n",
      "substituting it as the value of control variables in our problem. Next, the new\n",
      "bounds are created centered at b(0). The width of domain for each subsequent\n",
      "iteration is lower than the previous iteration. The value of b(0)is replaced with\n",
      "optimal value of bobtained using surrogate model ( bˆ∗) in the previous iteration.\n",
      "Finally, it is checked if the new bounds are within the bounds that were defined\n",
      "at the beginning of the problem. If not, the algorithm restricts them from\n",
      "exceeding the initial bounds. This step of the iterative process is depicted for\n",
      "two optimization parameters in Figure 4.2.\n",
      "3.Optimization: This is the main step of the algorithm which includes training and\n",
      "testing phases. In summary, we create sampling set and snapshots, construct the\n",
      "surrogate model, solve optimization problem and calculate the error.74 CHAPTER 4. SURROGATE MODELS\n",
      "Figure 4.3: POD-RBF algorithm flowchart\n",
      "4.Updating parameters: This step prepares the parameters for the next iteration\n",
      "in the case when the tolerance level falls below the error of approximation. In\n",
      "general, the algorithm replaces b(0)with the optimized value of bˆ∗from the\n",
      "surrogate response of current iteration, shortens the length by using a predefined\n",
      "multiplier. If the tolerance criteria is met, the iterative process stops. Else the\n",
      "algorithm resumes from step 2.\n",
      "The iterative algorithm discussed throughout this section is summarized in flowchart\n",
      "presented in the Figure 4.3.\n",
      "4.5Application of POD-RBF Method on Dynamical\n",
      "Systems\n",
      "In this section, the POD-RBF procedure is used to construct the surrogate models for\n",
      "real-life dynamical systems and associated optimal control problems are solved. Three\n",
      "dynamical systems with various complexity are presented, with model 1 being the simple\n",
      "non-linear ODE problem, and model 2 and 3 featuring a non-linear system of equations\n",
      "with complex optimization criteria. For each model, a description of the problem\n",
      "is presented and the values of initial parameters used in numerical experiments are\n",
      "defined. Next, the numerical experiments are performed to first decide the combination\n",
      "of sampling technique, interpolation method and sampling points optimal for that\n",
      "model and then the optimization problem is solved to evaluate the accuracy of surrogate\n",
      "responses and the difference in computational time of optimization with original and\n",
      "POD-RBF methods.\n",
      "As a convention for this section, the variables with the hat operator ( .ˆ) represent the\n",
      "results obtained using surrogate model and without hat stand for the results from\n",
      "original model. The description of common variable names are summarized in Table\n",
      "4.1.4.5. APPLICATION OF POD-RBF METHOD ON DYNAMICAL SYSTEMS 75\n",
      "Notation Description\n",
      "b(0)Initial value of optimization parameter\n",
      "bˆ∗Optimal value of optimization parameter, surrogate model\n",
      "b∗Optimal value of optimization parameter, original model\n",
      "ψ0(b(0))Value of optimization criteria for b(0), original model\n",
      "ψ0(bˆ∗) Value of optimization criteria for bˆ∗, original model\n",
      "ˆ︂ψ0(bˆ∗) Value of optimization criteria for bˆ∗, surrogate model\n",
      "ψ0(b∗) Value of optimization criteria for b∗, original model\n",
      "ψi(b(0)) Value of ithoptimization constraint for b(0), original model\n",
      "ψi(bˆ∗) Value of ithoptimization constraint for bˆ∗, original model\n",
      "ˆ︁ψi(bˆ∗) Value of ithoptimization constraint for bˆ∗, surrogate model\n",
      "ψi(b∗) Value of ithoptimization constraint for b∗, original model\n",
      "Table 4.1: Details of notations used in preceding analysis\n",
      "4.5.1 Model 1: Science Policy\n",
      "Description of the Model\n",
      "This subsection features a very interesting application of optimal control theory in\n",
      "economics. The problem is one of the oldest optimal control problem in economics\n",
      "known as science policy and was originally introduced in 1966 by M.D. Intriligator and\n",
      "B.L.R. Smith in their paper \"Some Aspects of the Allocation of Scientific Effort between\n",
      "Teaching and Research\" Intriligator and Smith (1966). Science policy addresses the\n",
      "important issue of allocation of new scientists between teaching and research staff, in\n",
      "order to maintain the strength of educational processes or alternatively, avoiding any\n",
      "other dangers caused by inappropriate allocation between scientific careers Intriligator\n",
      "(1975). In order to find the optimal allocation, the optimal control problem was\n",
      "formulated as following:\n",
      "max\n",
      "(u,y)∈U×Yψ0˜=∫︂⊤\n",
      "t0[0.5y1(t) + 0.5y2(t)]dt, (4.16)\n",
      "subject to\n",
      "c(y, u) = 0∼⎧\n",
      "⎪⎪⎨\n",
      "⎪⎪⎩y′\n",
      "1(t)−u(t)gy1(t) +δy1(t) = 0 , t∈[t0, T]\n",
      "y′\n",
      "2(t)−(1−u(t))gy1(t) +δy2(t) = 0\n",
      "y1(t0)−y10= 0, y2(t0)−y20= 0[︄\n",
      "ψ1˜\n",
      "ψ2˜]︄\n",
      "=[︄\n",
      "0\n",
      "0]︄\n",
      "∼{︄\n",
      "y1(T)−y1T= 0\n",
      "y2(T)−y2T= 0\n",
      "u−≤u(t)≤u+76 CHAPTER 4. SURROGATE MODELS\n",
      "In this formulation, the state variable y1andy2represent the teaching scientists\n",
      "and research scientists respectively at any given time t. The detailed description\n",
      "of all the parameters and their values are summarized in Table 4.2. The control\n",
      "variable urepresents the number of new scientists becoming teachers, correspondingly\n",
      "(1−u)represents the number of new researchers. Hence, the differential equations\n",
      "determine the rate of change of number of teachers and researchers by subtracting the\n",
      "new proportion from the allocated proportion. The upper and lower limit of control\n",
      "function indicate the limits of the science policy in affecting the initial career choices,\n",
      "by government contracts, grants, incentive schemes, etc.\n",
      "Parameters Definitions Values\n",
      "u(t0) Proportion of new scientists becoming teachers at initial time 0.5\n",
      "g Number of scientists annually produced by one scientist 0.14\n",
      "δ Rate of exit of scientists due to death, retirement or transfer 0.02\n",
      "y10 Number of initial scientists working as teachers 100\n",
      "y20 Number of initial scientists working as researchers 80\n",
      "T Final time for the analysis in this policy 15\n",
      "y1T Number of final scientists working as teachers 200\n",
      "y2T Number of final scientists working as researchers 240\n",
      "u−Lower limit of control function 0.1\n",
      "u+Upper limit of control function 0.6\n",
      "Table 4.2: Description of parameters for Model 1\n",
      "The problem is the one of choosing a trajectory for the allocation of u(t)such that\n",
      "the welfare is maximized, given by the objective function in equation (4.16). The\n",
      "terminal part g1(., .)of welfare is not accounted for in the objective function, but the\n",
      "state constraints are added to compensate for it in the form of y1(T)−y1T= 0and\n",
      "y2(T)−y2T= 0. The optimization process is focused at maximizing the intermediate\n",
      "value g2(., ., .)of welfare. The welfare function is thought to be additive of individual\n",
      "utilities along the lines of utilitarian approach. The utilities are set as a linear function,\n",
      "with an assumption that the teachers and researchers are perfect substitutes, and the\n",
      "allocation of any scientist to one career will lead him to abandon the other career\n",
      "completely. This assumption, even though unrealistic, is granted for simplicity and can\n",
      "be complicated at the later stages.\n",
      "Simulation\n",
      "This system of equations is solved for ns= 40,60,80training points, generated with\n",
      "LHS, SLHS and RS to create the snapshot matrix. The desired tolerance level is\n",
      "ϵPOD= 0.01. The singular value plot for one specific experimental design, SLHS and\n",
      "ns= 40is presented Figure 4.4 and shows that the first 4 singular values explain\n",
      "almost 100% variance. The plots of singular values for other experimental designs\n",
      "depicted similar pattern. Given the criterion in equation (4.9), we choose the rank of4.5. APPLICATION OF POD-RBF METHOD ON DYNAMICAL SYSTEMS 77\n",
      "k= 4. It can be clearly noticed that the magnitude of all the singular values is very\n",
      "small compared to first singular value; the relative commutative energy E(i)of first\n",
      "singular value is more than 99%. This shows that that the responses of the system are\n",
      "fully correlated. Hence, rank 4 approximation is enough and adding more vectors in\n",
      "approximation (by increasing the rank) will not improve the precision a lot.\n",
      "Figure 4.4: Cumulative energy plot to determine singular values for Model 1.\n",
      " Surrogate-\n",
      "Model_SciencePolicy\n",
      "Next, the surrogate model is constructed for each of the variant with this rank and\n",
      "the RMAE are reported in Table 4.3. The table shows that the lowest RMAE was\n",
      "obtained for LHS, followed by SLHS and the RS. As the theory suggests, RMAE is\n",
      "observed to decrease with increasing number of sampling points with an exception of\n",
      "cubic spline in random sampling. The anomalous behavior of RS can be associated\n",
      "with its randomness, which sometimes generates the sampling points which belong to\n",
      "only one region of the surface, leading to higher variance in the model and higher error\n",
      "of approximation, even with increasing number of training points. Another trend that\n",
      "can be consistently observed is that the linear spline RBF tend to perform better than\n",
      "the cubic spline in this model. Overall, the best experimental design for this model is\n",
      "to use a combination of LHS with linear spline RBF and ns= 80. The surrogate model\n",
      "approximation for the initial control value u= 0.5and the original system response\n",
      "are plotted in Figure 4.5 and show that the approximated responses are very close to\n",
      "the actual responses.\n",
      "Sampling Interpolation ns= 40 ns= 60 ns= 80\n",
      "LHSLinear 0.02034 0.00293 0.00150\n",
      "Cubic 0.05316 0.00647 0.00641\n",
      "SLHSLinear 0.03825 0.00679 0.00437\n",
      "Cubic 0.05175 0.00897 0.00861\n",
      "RSLinear 0.01525 0.02410 0.02792\n",
      "Cubic 0.16457 0.26597 12.91601\n",
      "Table 4.3: RMAE for various experimental designs of Model 178 CHAPTER 4. SURROGATE MODELS\n",
      "Figure 4.5: Actual surface vs approximated surface for Model 1.\n",
      " SurrogateModel_-\n",
      "SciencePolicy\n",
      "Optimization\n",
      "For the final step of analysis, the surrogate model was constructed with 40 training\n",
      "points, LHS, and linear spline RBF. Here, we use ns= 40because given the simplicity of\n",
      "the problem, the accuracy required for optimization can be achieved by small number of\n",
      "training points. The optimization problem is solved with two optimization parameters\n",
      "for control function using both original and surrogate model. The results of optimization\n",
      "are given in Table 4.4. The problem started with equal number of scientists allocated\n",
      "in both careers, with the initial value of state constraint ψ1(b(0)) = [11 .8001; 43 .0163]\n",
      "representing that the number of teachers and researchers allocated at initial time were\n",
      "11 and 43 units short of y1Tandy2Trespectively. The solution to the problem allocates\n",
      "around 52% of new scientists to teaching at the beginning of the time. This proportion\n",
      "decreases as the time passes with around 47% scientists allocated as teaching staff at\n",
      "the end of time (see Figure 4.6(b)). The optimal surface in 4.6(a)) shows that the\n",
      "number of teaching staff is allocated to be higher than the number of researchers until\n",
      "the end time. The surrogate model gave consistent results, with error of approximation\n",
      "(the relative error of ψ0(bˆ∗)andˆ︂ψ0(bˆ∗)) as low as 0.005 in the first iteration.\n",
      "Even though the optimization using surrogate model is slightly quicker than the original\n",
      "model, the time taken for construction of surrogate model is higher. Hence, despite\n",
      "of highly accurate system responses through surrogate model, substituting original\n",
      "model with POD-RBF model might not be useful, as the time taken for optimization\n",
      "by surrogate model (training + optimization) takes much longer than the original\n",
      "model. This example give us insight into why surrogate modelling was avoided into\n",
      "applications earlier: the simple nature of optimization models for some applications do\n",
      "not require high computational resources, while the construction of surrogate models is\n",
      "much more computationally expensive and may not be desirable.4.5. APPLICATION OF POD-RBF METHOD ON DYNAMICAL SYSTEMS 79\n",
      "Field Value Field Value\n",
      "b(0)[0.5000 0.5000] Bounds [0.1000,0.6000]\n",
      "b∗[0.6000,0.3461] bˆ∗[0.5187,0.4730]\n",
      "ψ0(b(0))210.6500 ψ0(bˆ∗)209.7600\n",
      "ψ0(b∗)212.8400 ˆ︂ψ0(bˆ∗)210.9900\n",
      "ψ1(b(0)) [11 .8001,43.0163]⊤ψ1(bˆ∗) [0 .0003,0.0014]⊤\n",
      "ψ1(b∗) [0 .000,0.000]⊤ ˆ︂ψ1(bˆ∗) [0 .0000,0.0023]⊤\n",
      "Time orig2.8109 sec Time surr2.3694 sec\n",
      "Time cnstr37.8406 sec ϵ 0.0058\n",
      "Table 4.4: Optimization results for Model 1\n",
      "Figure 4.6: Optimal surface and control functions for Model 1\n",
      " SurrogateModel_Science-\n",
      "Policy\n",
      "4.5.2 Model 2: Population Dynamics\n",
      "Description of the Model\n",
      "In this subsection, a more complex application of optimal control theory is presented\n",
      "with a general model of non-linear system of ODEs defined by:\n",
      "c(y, u) = 0∼⎧\n",
      "⎪⎪⎪⎪⎪⎪⎨\n",
      "⎪⎪⎪⎪⎪⎪⎩{︄\n",
      "y′\n",
      "1−p1y1−p2y2\n",
      "2−u1y1F(y1, t)y2= 0,\n",
      "y′\n",
      "2−p3y2−p4y2\n",
      "2−u1u2y1F(y1, t)y2= 0,t∈Ωt= (t0, T]\n",
      "y1(t0)−y10= 0\n",
      "y1(t0)−y20= 0\n",
      "F(y1, t) = 1−e−p5y1\n",
      "(4.17)\n",
      "These type of dynamical problems are usually observed in population dynamics in\n",
      "biology, ecology and environmental economics. These problems are variation of prey-\n",
      "predator model presented by Lotka-Volterra. This subsection aims at generalizing the\n",
      "approach of POD-RBF on these non-linear models without providing specific details of\n",
      "the model parameters of the optimization problem.80 CHAPTER 4. SURROGATE MODELS\n",
      "The optimization problem considered here consists of finding a value of control function\n",
      "u∗=[u∗\n",
      "1, u∗\n",
      "2]that minimizes the distance between y1and its desirable value y1dValue on\n",
      "control function is restricted by dual pointwise constraints and value y2do not exceed\n",
      "maximum value y2d.The optimization problem can be formulated in the following\n",
      "manner: find u∗that minimize optimization criterion\n",
      "ψ0(u∗) = min\n",
      "u∫︂T\n",
      "t0(y1(t, u)−y1d)2dt (4.18)\n",
      "subject to state equation (4.17), box constraints on the control\n",
      "U={︁\n",
      "u:u−(t)≤u(t)≤u+(t)}︁\n",
      "(4.19)\n",
      "and pointwise constraint on state\n",
      "y2(t)≤y+\n",
      "2 (4.20)\n",
      "The pointwise state constraint (4.20) is transformed into an equivalent equality con-\n",
      "straint of the integral type\n",
      "ψ1(u) =ψ˜1(u, y(u)) =∫︂T\n",
      "t0(|y2(t, u)−y2d|+y2(t, u)−y2d)2dt(4.21)\n",
      "Taking into account equations (4.18-4.21) the optimization problem can be written in\n",
      "a reduced form as follows:\n",
      "ψ0(u∗) = min\n",
      "u∈U∂∫︂T\n",
      "t0(y1(t, u)−y1d)2dt\n",
      "U∂u={u:u∈U;ψ1(u) =ψ˜j(u, y(u)) = 0}︂\n",
      "c(y(u), u) = 0(4.22)\n",
      "Simulation\n",
      "For numerical experiments we select the following values for the input parameters:\n",
      "[p1, p2, p3, p4, p5]= [0.734,0.175,−0.500,−0.246,0.635],[t0, T]= [0,10],nu= 2, u−=[︁\n",
      "u−\n",
      "1, u−\n",
      "2]︁\n",
      "= [−0.5500,−1.0370] , u+=[︁\n",
      "u+\n",
      "1, u+\n",
      "2]︁\n",
      "= [−0.300,−0.7870],y1d= 5, y+\n",
      "2= 6.\n",
      "The control functions u1(t), u2(t)on the interval [t0, T]are approximated by linear\n",
      "functions. Thus, the vector of optimization parameters bconsist of four components:\n",
      "b=[︂\n",
      "b(1)\n",
      "1, b(1)\n",
      "2, b(2)\n",
      "1, b(2)\n",
      "2]︂T\n",
      "= [b1, b2, b3, b4]T.\n",
      "For numerical simulations, LHS, SLHS and RS are used to define the sampling matrix4.5. APPLICATION OF POD-RBF METHOD ON DYNAMICAL SYSTEMS 81\n",
      "with ns= 40,60and80. Also, RBF interpolation-linear spline and cubic spline is used\n",
      "for comparison of results. The solution y= [y1, y2]where ny= 2is then computed for\n",
      "time instances, tiwith t0< ti< tnt,nt= 100equally spaced instances of t, and ns\n",
      "sampling points, and then system responses were collected to generate the snapshot\n",
      "matrix. The error of approximation is fixed ϵPOD= 0.01.\n",
      "Next, the POD-RBF approach is applied to this model to first determine the dimen-\n",
      "sion of POD basis through SVD using cumulative energy method (it is done for all\n",
      "experimental designs) and it is concluded that 3 singular values should be considered.\n",
      "Having chosen k= 3, the numerical simulations are performed for model 2 given\n",
      "in equation (4.17). For testing of the model, ng= 10points were used to calculate\n",
      "the RMAE for each combination. Table 4.5 exhibits that among all the surrogate\n",
      "models that were trained using different number of sample points, different sampling\n",
      "techniques and RBF interpolations, the cubic spline RBF showed the lowest error\n",
      "for both LHS and SLHS in general, with a few exceptions. Also, as expected, the\n",
      "error of approximation shows a decreasing pattern as the number of sample points\n",
      "increase from 60 to 80, except in RS when the RMAE follows no particular trend. The\n",
      "least RMAE is obtained for the model trained on 80 data points from SLHS for cubic\n",
      "spline RBF. For one of such sample point b= [−0.425,−0.425,−0.912,−0.912], the\n",
      "POD-RBF responses were obtained for ns= 40and the original and approximated y1\n",
      "andy2were plotted as shown in Figure 4.7. For this point, all POD-RBF gave relative\n",
      "maximum absolute error less than 1% as desired.\n",
      "Sampling Interpolation ns= 40 ns= 60 ns= 80\n",
      "LHSLinear 0.45112 0.32948 0.18871\n",
      "Cubic 0.28229 0.24010 0.15794\n",
      "SLHSLinear 0.26162 0.19198 0.19204\n",
      "Cubic 0.23986 0.18685 0.15376\n",
      "RSLinear 0.59500 0.55080 0.86405\n",
      "Cubic 0.92109 0.15595 0.19902\n",
      "Table 4.5: RMAE for various experimental designs of Model 2\n",
      "Optimization\n",
      "In previous subsubsection, the best results were obtained for ns= 80with SLHS and\n",
      "cubic spline RBF. That experimental design is used to solve the optimization problem\n",
      "(4.22) and the results are summarized in Table 4.6. For simplicity, the number of\n",
      "optimization parameters for each control variable are taken to be 2. We could, however,\n",
      "allows specification of different number of optimization parameters for each control\n",
      "variable. The optimization results of this model apparently highlight the efficiency of\n",
      "surrogate modeling. As the Table 4.6 reports, the tolerance level is met in the first82 CHAPTER 4. SURROGATE MODELS\n",
      "Figure 4.7: Actual vs approximated surface for Model 2\n",
      " SurrogateModel_PopulationDy-\n",
      "namics\n",
      "iteration, with error between approximated and actual responses being less than 0.01\n",
      "in first iteration. Hence, the desired accuracy is achieved and no further iterations were\n",
      "required.\n",
      "The optimization criteria obtained using surrogate model ˆ︂ψ0(bˆ∗) = 43 .5647is very close\n",
      "toψ0(b∗) = 43 .3287. Moreover, since results of optimization problem were obtained\n",
      "within one iteration, the construction time of surrogate model can be considered once for\n",
      "all. Therefore, the total computational time for optimization through surrogate model\n",
      "of 6.6 seconds + 15.35 seconds is less than 23.40 seconds taken by original problem.\n",
      "Relatively, the surrogate method is four times faster than the original method in solving\n",
      "optimization problem. In a nutshell, for this highly non-linear model, surrogate model\n",
      "gave highly accurate and computationally efficient result of the optimization problem.\n",
      "Field Value Field Value\n",
      "b(0)[-0.4250,-0.4250, Bounds [-0.5500, -0.300];\n",
      "-0.9120,-0.9120] [-1.0370,-0.7870]\n",
      "b∗[-0.5006,-0.3250, bˆ∗[-0.4922,-0.3334,\n",
      "-1.0120,-1.0120] -1.0120,-1.0120]\n",
      "ψ0(b(0))55.2817 ψ0(bˆ∗)43.9127\n",
      "ψ0(b∗)43.3287 ˆ︂ψ0(bˆ∗)43.5647\n",
      "ψ1(b(0))22.9396 ψ1(bˆ∗)0.0162\n",
      "ψ1(b∗)0.0000 ˆ︂ψ1(bˆ∗)0.0000\n",
      "Time orig23.3983 sec Time surr6.6241 sec\n",
      "Time cnstr15.3470 sec ϵ 0.0081\n",
      "Table 4.6: Optimization results for Model 24.5. APPLICATION OF POD-RBF METHOD ON DYNAMICAL SYSTEMS 83\n",
      "4.5.3Model 3: Quality Control in Production and Process\n",
      "Management\n",
      "Description of the Model\n",
      "The third model in this series is that of optimal control strategy in production and\n",
      "process management. This non-linear dynamical system is taken from work of M.D.\n",
      "Haider Ali Biswas Biswas and Ali (2016). The model addresses the issue of declining\n",
      "quality of goods in production processes over time by the help of state constraints in\n",
      "optimization problem. Even though the model is introduced in the context of industrial\n",
      "engineering in the original paper, the model in equally valid in industrial economics\n",
      "since the quality of products is one of the main factors in determining the aggregate\n",
      "demand and supply of each firm and it comes to economists to keep check of the market\n",
      "demand by controlling the quality of products. The mathematical model of the problem\n",
      "taken directly from Biswas and Ali (2016) is as following:\n",
      "Model 3 :=⎧\n",
      "⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨\n",
      "⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩max\n",
      "(u1,u2)∈UJ=l(y(T)) +∫︂T\n",
      "0L(t, y(t), u(t))\n",
      "subject to\n",
      "y′\n",
      "1(t) =y2(t)u1(t)−d(t),\n",
      "y′\n",
      "2(t) =−(α+u2(t))y2(t) +u2(t),\n",
      "g(t, x(t))≤0,∀t∈[0, T],\n",
      "(u1(t), u2(t))∈Ua.e.t∈[0, T],\n",
      "y1(t)≥0,a.e.t∈[0, T],\n",
      "y(0) = y0,\n",
      "where\n",
      "g(t, y(t)) =−y2(t) + 0.5,\n",
      "l(y(T)) =by2(T)e−ρT,\n",
      "L(t, y(t), u(t)) = ( wd−hy1(t)−ru2\n",
      "1(t)−cu2(t))e−ρt\n",
      "U={(u1, u2),0≤u1(t)≤U1,0≤u2(t)≤U2,a.e.t∈[0, T]}(4.23)\n",
      "In this model, the state variables y1(t)andy2(t)represent the inventory level, and\n",
      "proportion of ’good’(appropriate quality) from the end items at any time trespectively.\n",
      "At initial time, y10= 3andy20= 1. The control function u1(t)represented the\n",
      "scheduled production rate with upper limit U1= 3and control function u2(t)represents\n",
      "the preventive maintenance rate to reduce the proportion of defective units produced\n",
      "with an upper limit of U2= 4. The demand rate ( d) and the obsolescence rate of\n",
      "process performance in absence of maintenance ( α) are fixed at d= 4andα= 2. The84 CHAPTER 4. SURROGATE MODELS\n",
      "Figure4.8: ActualsurfacevsapproximatedsurfaceforModel3\n",
      " SurrogateModel_Production\n",
      "negative sign associated with the second differential equation in the dynamical system\n",
      "corresponds to the declining proportion of ’good’ items in absence of maintenance. The\n",
      "maintenance is introduced in the optimization problem by declaration of lower bound\n",
      "on proportion of good items in form of state constraint. The final objective of the\n",
      "problem is to minimize the salvage cost (the estimated resale value of a good at the\n",
      "end of its useful life).\n",
      "Simulation\n",
      "The positive constants in equation (4.23) are: [ρ, w, h, c, b, r ] = [0 .1,8,1,2.5,10,2]. We\n",
      "carry out similar analysis for this model. The rank determined using the energy method\n",
      "isk= 4for all variants. The RMAE results as recorded in Table 4.7 show that once\n",
      "again cubic spline RBF dominated linear spline in higher number of training points.\n",
      "Also, the least error of approximation was obtained when the combination of SLHS,\n",
      "cubic spline RBF, and ns= 80. The approximation of system responses for an arbitrary\n",
      "point and its comparison with original system responses is displayed in Figure 4.8.\n",
      "Sampling\n",
      "StrategyInterpolation\n",
      "Typens= 40 ns= 60 ns= 80\n",
      "LHSLinear 0.08475 0.00886 0.00813\n",
      "Cubic 0.03809 0.00567 0.00697\n",
      "SLHSLinear 0.01432 0.02622 0.00212\n",
      "Cubic 0.02214 0.00586 0.00157\n",
      "RSLinear 0.03245 0.06733 0.06917\n",
      "Cubic 0.06310 0.00377 0.06124\n",
      "Table 4.7: RMAE for various experimental designs of Model 34.5. APPLICATION OF POD-RBF METHOD ON DYNAMICAL SYSTEMS 85\n",
      "Optimization\n",
      "The experimental design concluded in previous subsection was used to solve the\n",
      "optimization problem of Model 3 with 4 optimization parameters for each control\n",
      "function. Piecewise-linear interpolation was used to interpolate the optimization\n",
      "parameters. Here, unlike Model 2, the error of approximation was above the set\n",
      "threshold of ϵPOD= 0.01when the optimization results were obtained for the first time.\n",
      "This entails the use of iterative process discussed in section 4.4. After applying the\n",
      "aforementioned algorithm, the error of approximation was achieved in 3 iterations and\n",
      "the summary of results for each iteration is presented in Table 4.8 and Figure 4.6. The\n",
      "optimization results here match the results reported in the original paper, i.e. in the\n",
      "presence of state constrains, the declining trend of number of good items represented\n",
      "by state variable y2was halted by imposing a minimum proportion.\n",
      "Parameter Iteration 1 Iteration 2 Iteration 3\n",
      "b(0) [2.7,2.7,2.7,2.7,\n",
      "0.0,0.0,0.0,0.0][0.7022,0.0000,\n",
      "1.8041,1.4614,\n",
      "1.8999,1.3773,\n",
      "1.9082,4.0000][0.8376,0.7384,\n",
      "2.1002,0.5137,\n",
      "2.2801,1.3892,\n",
      "1.6146,4.0000]\n",
      "Bounds[0,3]\n",
      "[0,4][0,3]\n",
      "[1,4][0.0000,2.0137]\n",
      "[2.0000,4.0000]\n",
      "b∗ [0,0,0,0,\n",
      "4,4,4,4]- -\n",
      "bˆ∗[0.7022,0.0000,\n",
      "1.8041,1.4614,\n",
      "1.8999,1.3773,\n",
      "1.9082,4.0000][0.8376,0.7384,\n",
      "2.1002,0.5137,\n",
      "2.2801,1.3892,\n",
      "1.6146,4.0000][0.3097,0.3571,\n",
      "0.1290,0.3428,\n",
      "3.1945, 3.0046,\n",
      "2.706, 4.0000]\n",
      "ψ0(b(0)) 16.0926 - -\n",
      "ψ0(b∗) 21.4360 - -\n",
      "ˆ︂ψ0(bˆ∗) 22.2183 26.1910 25.1481\n",
      "ψ0(bˆ∗) 20.9054 25.0440 25.0711\n",
      "Time orig 20.4522 sec - -\n",
      "Time cnstr 15.1739 sec 16.3270 sec 20.1867 sec\n",
      "Time surr 2.2351 sec 2.8383 sec 7.9384 sec\n",
      "ψ1(b(0)) 0.1568 - -\n",
      "ψ1(bˆ∗) 0 0 0\n",
      "ˆ︂ψ1(bˆ∗) 0 0 0\n",
      "ϵ 0.0628 0.0458 0.0031\n",
      "Table 4.8: Optimization results for Model 3\n",
      "However, the main goal of this analysis is not to evaluate the accuracy of actual\n",
      "responses, but rather analyze how accurately and efficiently surrogate model could\n",
      "predict the system responses. The results from this model have given an ideal example\n",
      "of the iterative procedure described before. As illustrated in Figure 4.10 for first86 CHAPTER 4. SURROGATE MODELS\n",
      "Figure 4.9: Optimal surface and optimal control plots for Model 3\n",
      " SurrogateModel_-\n",
      "Production\n",
      "Figure 4.10: Illustration of iterative algorithm for Model 3\n",
      "optimization parameter of each control function, the domain of the control function\n",
      "decreases with each iteration and a new surrogate model is constructed to determine\n",
      "bˆ∗, which moves closer to b∗as the algorithm moves forward. This domain is centered\n",
      "at the interpolated value of optimization parameters for each control function (note:\n",
      "this is not evident in Figure under consideration as only one optimization parameter\n",
      "is plotted for simplicity whereas 4 optimization parameters are used). The distance\n",
      "between bˆ∗of final iteration and b∗is visibly higher in this case. This can be interpreted\n",
      "using the results reported in Table 4.8.\n",
      "For this model, the surrogate model has better results of optimization than the original\n",
      "model: the maximum value of the optimization criteria for the original model ψ0(b∗)\n",
      "was 21.4360, whereas, at the end, the optimal value obtained by surrogate model is\n",
      "25.0711. This implies that surrogate model performed better than the original model\n",
      "in this case. Surrogate model also outperformed the original model in terms of time\n",
      "for solution of optimization problem: the problems that took the over 20 seconds to4.6. CONCLUSION 87\n",
      "be solved by original model could be solved in less than 3 seconds with the surrogate\n",
      "model. On the other hand, The construction time for the surrogate model exceeds the\n",
      "time taken by the optimization through the original model. This could be a concern if\n",
      "the optimization problem is being solved only once.\n",
      "As previously discussed, for many applications, specially those involving inverse prob-\n",
      "lems, the optimization problems are required to be solved repetitively. Since the\n",
      "surrogate model is constructed once for all, the computational time gained by using\n",
      "surrogate models for the optimization can easily overtake the time of construction.\n",
      "Furthermore, with more complicated dynamical systems, the computational cost de-\n",
      "manded by original models increase rapidly, while the computational time needed to\n",
      "solve the same using surrogate models remain low. Hence, these reduced order models\n",
      "dynamically adapt to the system behavior and provide highly accurate solutions to\n",
      "the optimal control problems, while decreasing the computational complexity and are\n",
      "therefore recommended to be adapted in many other applications.\n",
      "4.6 Conclusion\n",
      "This research employs Proper Orthogonal Decomposition, a surrogate modeling tech-\n",
      "nique integrated in optimization framework for dimension reduction of associated\n",
      "dynamical systems. POD extracts hidden structures from high dimensional data and\n",
      "projects them on lower dimensional space using the statistical method of singular\n",
      "value decomposition. In the first instance, POD is coupled with various Radial Basis\n",
      "Functions — a smoothing technique— and the computational procedure is hypothesized\n",
      "to provide compact, accurate and computationally efficient solution of optimal control\n",
      "problems. The main contribution of this research is to enhance these surrogate models\n",
      "by introducing various sampling methods to the algorithm, and using an iterative\n",
      "algorithm, to achieve more accurate results.\n",
      "The algorithm and computational procedure is implemented on three real-life optimal\n",
      "control problems that are taken directly from literature sources. It is demonstrated\n",
      "that the dimensionality of high order models in the form of ODEs of dynamical systems\n",
      "could be reduced substantially to as low as 3 with relative maximum absolute error less\n",
      "than 0.01 between original and approximated system responses. Hence approximated\n",
      "surrogate model gave a good alternative method of solution of ODEs with low CPU\n",
      "intensity. The simulation part of PDF-RBF procedure is carried out by varying the\n",
      "number of sample points, sampling strategy, and RBF interpolation types in the\n",
      "training phase. The results showed that the approximation is more precise if the model\n",
      "is trained on higher number of sample points. Also, the interpolated surrogate model\n",
      "constructed using cubic-spline RBF led to better results in the complex model than its\n",
      "liner counterpart. Furthermore, LHS and SLHS both led to better approximations than88 CHAPTER 4. SURROGATE MODELS\n",
      "RS, which highlights the significance of our proposal to use memory-based sampling\n",
      "techniques.\n",
      "In solution of optimization problems, the system responses obtained by surrogate model\n",
      "invariably gave accurate results with improved computational time. As a whole, all\n",
      "three models agreed with the hypothesis of this work that surrogate models can increase\n",
      "the computational efficiency in solution of dynamical systems while maintaining the\n",
      "accuracy of system responses. However, the construction time of the surrogate models\n",
      "is subject to the available computational resources and the numerical simulation might\n",
      "be much faster in a high-performance computer, compensating for the time used in\n",
      "iterative process of POD-RBF algorithm.\n",
      "The presented surrogate model algorithm significantly enhance the existing surrogate\n",
      "modelling technique. The algorithm also establishes a new paradigm for coupling\n",
      "optimization and modern statistics using data analytics methods. The proposed\n",
      "framework opens up a whole new avenue of research for utilizing surrogate models,\n",
      "specially in the machine learning research that estimate hyper-parameter through\n",
      "optimization problems, and require methods to ease the computational burden.\n",
      "4.6.1 Limitations and Future Work\n",
      "ROMs are usually thought of as computationally inexpensive mathematical representa-\n",
      "tions that offer the potential for near real-time analysis. The hypothesis of this research\n",
      "is based on the same notion. However, while analyzing the performance POD-RBF\n",
      "procedure on non-linear dynamical systems in the last section of this work, it is brought\n",
      "into consideration that the even though the optimization process itself is faster with\n",
      "surrogate responses, their construction is sometimes computationally expensive as it\n",
      "involved accumulating a large number of system responses to input parameters. It\n",
      "is also noteworthy that sometimes ROMs lack robustness with respect to parameter\n",
      "changes. These limitations are considered, however the detailed discussion of these\n",
      "issues and their solutions are left for the future work.\n",
      "In future, the performance of surrogate models can be evaluated on more complicated\n",
      "models consisting of highly non-linear ordinary and partial differential equations. Also,\n",
      "other sampling techniques which allow inclusion of corner and optimization points\n",
      "in the training set, methods of obtaining POMs, and interpolation methods can be\n",
      "explored as an extension of this work. Furthermore, the computational time of each of\n",
      "the model can be calculated with more efficient machines in homogeneous computer\n",
      "environment to get near-exact insight into the performance of surrogate models.Bibliography 89\n",
      "Bibliography\n",
      "Adongo, A. A., Lewis, A., & Chikelu, J. C. (2015). Principal component and factor\n",
      "analysis of macroeconomic indicators. IOSR Journal Of Humanities And Social\n",
      "Science,23(7), 01–07. https://doi.org/10.9790/0837-2307100107\n",
      "Bai, A., Heera, S., & Deshpande, P. (2015). An application of factor analysis in the\n",
      "evaluation of country economic rank. Procedia Computer Science ,54(3), 311–\n",
      "317. https://doi.org/10.1016/j.procs.2015.06.036\n",
      "Bai, J., & Wang, P. (2016). Econometric analysis of large factor models. Annual Review\n",
      "of Economics ,8(1), 53–80. https://doi.org/10.1146/annurev-economics-080315-\n",
      "015356\n",
      "Benaarbia, A., & Chrysochoos, A. (2017). Proper orthogonal decomposition prepro-\n",
      "cessing of infrared images to rapidly assess stress-induced heat source fields.\n",
      "Quantitative InfraRed Thermography Journal ,14(1), 132–152. https://doi.org/\n",
      "10.1080/17686733.2017.1281553\n",
      "Berardi, V., Gonzalez, R., Klepeis, N. E., Palacios, A., Bellettiere, J., Hughes, S.,\n",
      "Obayashi, S., & Hovell, F. (2015). Proper orthogonal decomposition methods\n",
      "for the analysis of real-time data: Exploring peak clustering in a secondhand\n",
      "smoke exposure intervention. Journal of Computational Science ,11, 102–111.\n",
      "https://doi.org/10.1016/j.jocs.2015.10.006\n",
      "Biswas, M. H. A., & Ali, A. (2016). Production and process management: An optimal\n",
      "control approach. Yugoslav Journal of Operations Research ,26, 8–8. https:\n",
      "//doi.org/10.2298/YJOR141015008K\n",
      "Boyaval, S. N., Bris, C. L., Lelièvre, T., Maday, Y., Nguyen, N., & Patera, A. T. (2010).\n",
      "Reduced basis techniques for stochastic problems. Archives of Computational\n",
      "Methods in Engineering ,17,435–454.https://doi.org/10.1007/s11831-010-9056-z\n",
      "Bujlak, V. (2012). Inverse analysis with model reduction (proper orthogonal decompo-\n",
      "sition in structural mechanics) . Springer. https://doi.org/10.1007/978-3-642-\n",
      "22703-5\n",
      "Chang, Y., Wang, X., Zhang, L., Li, Y., Mak, S., Wu, C. J., & Yang, V. (2021).\n",
      "Reduced-ordermodelingforcomplexflowemulationbycommonkernel-smoothed\n",
      "proper orthogonal decomposition. AIAA Journal ,59(9), 3291–3303. https:\n",
      "//doi.org/10.2514/1.J060574\n",
      "Chatterjee, A. (2000). An introduction to the proper orthogonal decomposition. Current\n",
      "Science,78(7).\n",
      "Chen, Y., Härdle, W., He, Q., & Majer, P. (2018). Risk related brain regions detection\n",
      "and individual risk classification with 3d image fpca. Statistics & Risk Modeling ,\n",
      "35(3-4), 89–110. https://doi.org/10.1515/strm-2017-0011\n",
      "Chrisman, L. (2014). Latin hypercube vs. monte carlo sampling.90 Bibliography\n",
      "Garud, S. S., Karimi, I. A., & Kraft, M. (2016). Smart adaptive sampling for surrogate\n",
      "modelling. In Z. Kravanja & M. Bogataj (Eds.), 26th european symposium on\n",
      "computer aided process engineering (pp. 631–636). Elsevier. https://doi.org/10.\n",
      "1016/B978-0-444-63428-3.50110-7\n",
      "Gooijer, B., Havinga, J., Geijselaers, H., & Van den Boogaard, T. (2021). Evaluation of\n",
      "pod based surrogate models of fields resulting from nonlinear fem simulations.\n",
      "Advanced Modeling and Simulation in Engineering Sciences ,8. https://doi.org/\n",
      "10.1186/s40323-021-00210-8\n",
      "Hinze, M., & Volkwein, S. (2005). Proper orthogonal decomposition surrogate models\n",
      "for nonlinear dynamical systems: Error estimates and suboptimal control. https:\n",
      "//doi.org/10.1007/3-540-27909-1_10\n",
      "Im, S., Lee, J., & Cho, M. (2021). Surrogate modeling of elasto-plastic problems via\n",
      "long short-term memory neural networks and proper orthogonal decomposition.\n",
      "Computer Methods in Applied Mechanics and Engineering ,385, 114030. https:\n",
      "//doi.org/10.1016/j.cma.2021.114030\n",
      "Intriligator, M. (1975). Applications of optimal control theory in economics. Synthese ,\n",
      "31(2), 271–288. https://doi.org/10.1007/BF00485980\n",
      "Intriligator, M., & Smith, B. (1966). Some aspects of the allocation of scientific effort\n",
      "between teaching and research. The American Economic Review ,56(1/2), 494–\n",
      "507. https://doi.org/10.2307/1821313\n",
      "Iulianoa, E., & Quagliarellaa, D. (2013). Proper orthogonal decomposition, surrogate\n",
      "modelling and evolutionary optimization in aerodynamic design. Computers and\n",
      "Fluids,84, 327–350. https://doi.org/10.1016/j.compfluid.2013.06.007\n",
      "Kerschen, G., Golinval, J., Vakakis, A., & Bergman, L. (2005). The method of proper\n",
      "orthogonal decomposition for dynamical characterization and order reduction\n",
      "of mechanical systems: An overview. Nonlinear Dynamics ,41, 147–169. https:\n",
      "//doi.org/10.1007/s11071-005-2803-2\n",
      "Lanata, F., & Grosso, A. D. (2006). Damage detection and localization for continuous\n",
      "static monitoring of structures using a proper orthogonal decomposition of\n",
      "signals.Smart Materials and Structures ,15(6), 1811–1829. https://doi.org/10.\n",
      "1088/09641726156036\n",
      "Li, K., Cursio, J. D., & Sun, Y. (2018). Principal component analysis of price fluctuation\n",
      "in the smart grid electricity market. Sustainability ,10(11). https://doi.org/10.\n",
      "3390/su10114019\n",
      "Lin, M., Khowaja, K., Chen, C., & Härdle, W. (2021). Blockchain mechanism and\n",
      "distributional characteristics of cryptos. Advances in Quantitative Analysis of\n",
      "Finance and Accounting , (18), 167–196. https://doi.org/10.6293/AQAFA.\n",
      "202112_(18).0006Bibliography 91\n",
      "Maravalle, A., & Rawdanowicz, L. (2018). Changes in economic and financial synchro-\n",
      "nisation, a global factor analysis. (1517). https://doi.org/10.1787/ba7c5c04-en\n",
      "Pearson, K. (1901). On lines and planes of closest fit to points in space. The London,\n",
      "Edinburgh, and Dublin Philosophical Magazine and Journal of Science ,2(11),\n",
      "559–572. https://doi.org/10.1080/14786440109462720\n",
      "Schilders, W., Vorst, H. V., & Rommes, J. (2008). Model order reduction: Theory,\n",
      "research aspects and applications (Vol. 13). https://doi.org/10.1007/978-3-540-\n",
      "78841-6\n",
      "Shcherbatyy, M., & Shcherbata, I. (2018). Proper orthogonal decomposition for ordinary\n",
      "differential equations and partial differential equations. Proceedings XXXII\n",
      "International Conference PDMU, Czech Republic, Prague , 162–170.\n",
      "Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. i. coherent\n",
      "structures. Quarterly of Applied Mathematics ,45(3), 561–571. https://doi.org/\n",
      "10.1090/qam/910463\n",
      "Sirovich, L., & Kirby, M. (1987). Low-dimensional procedure for the characterization\n",
      "of human faces. J. Opt. Soc. Am. A ,4(3), 519–524. https://doi.org/10.1364/\n",
      "JOSAA.4.000519\n",
      "Tran, N. M., Burdejová, P., Ospienko, M., & Härdle, W. K. (2019). Principal component\n",
      "analysis in an asymmetric norm. Journal of Multivariate Analysis ,171, 1–21.\n",
      "https://doi.org/10.1016/j.jmva.2018.10.004\n",
      "Wax, M., & Kailath, T. (1985). Detection of signals by information theoretic criteria.\n",
      "IEEE Transactions on Acoustics, Speech, and Signal Processing ,33(2), 387–392.\n",
      "https://doi.org/10.1109/TASSP.1985.1164557\n",
      "Zimmermann, R. (2013). Gradient-enhanced surrogate modeling based on proper\n",
      "orthogonal decomposition. Journal of Computational and Applied Mathematics ,\n",
      "237(1), 403–418. https://doi.org/10.1016/j.cam.2012.06.010Chapter 5\n",
      "Blockchain Mechanism and Distribu-\n",
      "tional Characteristics of Cryptos\n",
      "Publication\n",
      "Lin MB, Khowaja K, Chen CYH, Härdle WK (2022) Blockchain mechanism and\n",
      "distributional characteristics of cryptos, Advances in Quantitative Analysis of Finance\n",
      "& Accounting (AQAFA), Vol. 18, DOI: 10.6293/AQAFA.202112_(18).0006\n",
      "5.1 Introduction\n",
      "Cryptocurrency (crypto) is a digital asset designed to be as a medium of exchange\n",
      "wherein individual coin ownership is recorded in a digital ledger or computerised\n",
      "database. Its creation of monetary units and verification of fund transactions are\n",
      "secured using encryption techniques and distributed across several nodes (devices) on\n",
      "a peer-to-peer network. Such technology-enhanced and privacy-preserving features\n",
      "make it potentially different to other existing financial instruments and has attracted\n",
      "attention of many investors and researchers (Härdle et al., 2020). Many studies have\n",
      "investigated the similarity between a pool of cryptocurrencies in order to classify the\n",
      "important features of digital currencies. For example, Blau et al. (2020) has concluded\n",
      "that the top sixteen most active cryptocurrencies co-move with bitcoin. Researchers\n",
      "have also focused on describing the price behaviour of cryptos using economic factors\n",
      "(Ciaian et al., 2016; Sovbetov, 2018). However, owing to the unique technology of\n",
      "cryptocurrencies, there still exists a gap between the creators of blockchain mechanism\n",
      "and users operating the financial market of the cryptocurrencies and through this\n",
      "research, we aim to take a step towards mitigating that gap.\n",
      "We specialise our research on the following research questions. First, we characterise\n",
      "crypto behaviour using distributional characteristics of time series data. Also, instead\n",
      "of using the prices alone, we use actual block time and block size to incorporate\n",
      "the operational features of cryptos. Second, we hypothesise that the blockchain\n",
      "structure that the coin attaches plays a pivotal role in explaining the behaviour. More\n",
      "explicitly, we investigate the extent to which blockchain structure leads to explain\n",
      "the distributional characteristics. Using a characteristic based clustering coupled with\n",
      "925.1. INTRODUCTION 93\n",
      "spectral clustering technique, we group the selected cryptos into a number of clusters\n",
      "and stratify the mechanisms that make the coins within the particular cluster showing\n",
      "the same behaviour in price, actual block time, and actual block size, respectively.\n",
      "When studying cryptocurrencies, many researchers only focus on crypto price and daily\n",
      "returns (Hou et al., 2020; Trimborn & Härdle, 2018). While price is important when\n",
      "cryptos are used as a medium of payment, it is definitely not the only measure for\n",
      "evaluation of cryptocurrencies. For example, many low price coins are highly traded\n",
      "and many coins that are not used as medium of payment have low prices, e.g., XPR\n",
      "and Dogecoin. Cryptos were introduced to serve various purposes and the purpose of\n",
      "the coin does matter. This makes it necessary to use other time series while studying\n",
      "crypto markets. In this research, we propose to use actual block size and actual block\n",
      "time alongside price.\n",
      "Actual block size is the average actual size \"usage\" of a single block in data storage for\n",
      "one day. Since a block comprises of transaction data, it can represent the status of how\n",
      "a blockchain mechanism allocates transactions to a block. We consider it a measure\n",
      "of scalability of the system. A well-functioning blockchain should be able to level the\n",
      "transaction arrivals. Transaction distribution within a day for any crypto needs such\n",
      "balancing because it affects miners rewards and hence the demand of the coin. An\n",
      "ideal block size would keep confirmation times from ballooning while keeping fees and\n",
      "security reasonable. Therefore, actual block size of cryptos can provide insight into the\n",
      "behaviour of cryptos.\n",
      "Actual block time, on the other hand, measures the consistency and performance of\n",
      "the system. It is defined as the mean time required in minutes for each day to create\n",
      "the next block. In other words, it is the average amount of time for the day a user\n",
      "has to wait, after broadcasting their transaction, to see this transaction appear on the\n",
      "blockchain. Think of crypto markets as a fast food franchise and miners as customers\n",
      "who have to wait a certain time to make the purchase. If the waiting time is shorter on\n",
      "certain days while on other instances, the customers have to wait much longer, there is\n",
      "a discrepancy in the system. Analogously, the time series of block time, which is the\n",
      "distribution of waiting time, can be seen as a service level of the whole system and it is\n",
      "necessary to maintain as the users’ expectation or target block time set by the system\n",
      "depend on it.\n",
      "The idea of investigating the underlying blockchain mechanism, a cornerstone of crypto\n",
      "technology, and its connection to the crypto behaviour is still in its infancy. One of the\n",
      "first endeavours in explaining this relationship was made by L. Guo et al. (2018) who\n",
      "highlight that the the fundamental characteristics of cryptocurrencies (e.g., algorithm94 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "and proof type) have a vital role in differentiating the performance of cryptocurrencies.\n",
      "They develop a spectral clustering methodology to group cryptos in a dynamic fashion,\n",
      "but their research is limited in the exploitation of blockchain characteristics. With a\n",
      "similar spirit, Iwamura et al. (2019) start by claiming that high fluctuation is a reflection\n",
      "of the lack of flexibility in the Bitcoin supply schedule. They further strengthen their\n",
      "arguments by considering the predetermined algorithm of cryptos (specifically, the\n",
      "proof of work) to explain the volatility in cryptocurrency market. Zimmerman (2020)\n",
      "argue in their work that the higher congestion in blockchain technology leads to higher\n",
      "volatility in crypto prices. They claim that the limited settlement space in blockchain\n",
      "architecture makes users compete with one another, affecting the demand. In his model,\n",
      "the value of cryptos is governed by its demand, making the price sensitive to blockchain\n",
      "capacity.\n",
      "These research results, albeit true, are limited to a particular set of cryptocurrency\n",
      "mechanism and do not thoroughly explain the dynamics of cryptocurrencies. Also, most\n",
      "of the papers only use price as a proxy of behaviour. We advance the previous findings\n",
      "by incorporating a rich set of underlying mechanisms and connecting them to multiple\n",
      "time series. We take a deep dive into eighteen cryptos with a variety of mechanisms-\n",
      "concluded in Garriga et al. (2020))- from a technical perspective to summarise their\n",
      "mechanism and algorithm designs using variables, such as consensus algorithm, type of\n",
      "hashing algorithm, difficulty adjustment frequency and so on.\n",
      "We investigate a relationship between underlying blockchain mechanism of cryptocur-\n",
      "rencies and the distributional characteristics. Using the a characteristic-based clustering\n",
      "technique, we cluster the selected coins into a number of clusters and scrutinise the\n",
      "compositions of fundamental characteristics in each group. We observe that the clusters\n",
      "obtained from these time series indeed share common underlying mechanism. Through\n",
      "empirical evidence, we show that the cryptos forked from same origin and same con-\n",
      "sensus mechanism tend to become part of same clustering group. Furthermore, the\n",
      "clusters obtained by the time series of block time have same hashing algorithms and\n",
      "difficulty adjustment algorithms. Also, a similar nature (static or dynamic) of block\n",
      "size was observed within clusters obtained by the time series of actual block size. We\n",
      "conclude with empirical evidence that the crypto behaviour is actually linked with\n",
      "their blockchain protocol architectures.\n",
      "The implications of this study are abundant. The creators of cryptocurrencies can\n",
      "manage the impact of blockchain underlying mechanisms on the corresponding distri-\n",
      "butional characteristics, in a consideration of adoption rate of invented coins. From\n",
      "the users’ perspective, they can make an optimal decision in which coins should be\n",
      "adopted while concerning the price fluctuation.5.2. DATA SOURCE AND DESCRIPTION 95\n",
      "This paper proceeds as follows. section 2 discusses data source and the underlying\n",
      "mechanisms of the cryptos. section 3 presents the methodology used for classifying\n",
      "characteristics of time series and clustering algorithm. section 4 provides an illustration\n",
      "of analysis results. section 5 concludes and provides several avenues for future research.\n",
      "5.2 Data Source and Description\n",
      "According to CoinMarketCap (https://coinmarketcap.com), currently there are over\n",
      "7,000 cryptocurrencies and their total market capitalisation has surpassed USD$400\n",
      "billion as of November 09, 2020. Most of studies have focused on the mainstream coins\n",
      "(e.g., Bitcoin, Ethereum), and little has been investigated on the coins which have been\n",
      "introducedandfeaturedwithadiverseblockchainmechanismsandinventedtechnologies.\n",
      "The work of X. Guo and Donev (2020) is one of exceptions. In this study, 18 cryptos\n",
      "with different set of blockchain mechanisms have been examined –Bitcoin, Bitcoin\n",
      "Cash, Bitcoin Gold, Bitcoin SV, Blackcoin, Dash, Dogecoin, Ethereum, Ethereum\n",
      "Classic, Feathercoin, Litecoin, Monero, Novacoin, Peercoin, Reddcoin, Vertcoin, XRP\n",
      "(Ripple), and Zcash. We explore an interplay between distributional characteristics of\n",
      "crpytos and blockchain mechanism. We discuss the key characteristics of blockchain\n",
      "mechanisms and the time series data in this section.\n",
      "5.2.1 Underlying Mechanism\n",
      "Most of cryptos nowadays apply blockchain-based systems in which transactions are\n",
      "grouped into blocks and cryptographically interlinked to form a back-linked list of\n",
      "blocks containing transactions. The transactions are validated using the nodes within\n",
      "the crypto peer-to-peer network through a majority consensus directed by algorithms\n",
      "insteadofacentralauthority’sapproval. Insuchanoperationprocess, manyalgorithmic\n",
      "mechanisms are required to govern the performance and outcome of a crypto system.\n",
      "Some key blockchain-based characteristics are discussed below:\n",
      "Fork:It occurs as user base or developers conduct a fundamental or significant software\n",
      "change, see as in Figure 5.1. There are two types of forks – soft and hard forks. The\n",
      "former is an update to the protocol architecture and then all the nodes are enforced\n",
      "to follow in order to proceed with the operations of a crypto. The latter one creates\n",
      "a duplicate copy of the origin blockchain and modifies the copy to meet the desired\n",
      "quality (e.g., safety, scalability). In this case, a new crypto can be generated accordingly.\n",
      "For example, Peercoin network facilitates an alternative consensus mechanism –proof-\n",
      "of-stake (PoS) to Bitcoin’s proof-of-work (PoW) system for reducing dependency on\n",
      "energy consumption from mining process (King & Nadal, 2012).\n",
      "Going beyond a digital currency, Ethereum establishes an open-ended decentralised\n",
      "platform for diverse applications such as decentralised applications (dapps) and smart\n",
      "contracts (Buterin, 2014).96 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "Figure 5.1: Blockchain software forks in cryptocurrency\n",
      "Consensus mechanism: In order to establish an agreement on a specific subset of the\n",
      "candidate transactions, consensus mechanism provides a protocol for a large number\n",
      "of trust-less nodes in a decentralised blockchain network. For instance, PoW (Proof-\n",
      "of-Work, as adopted by e.g., Bitcoin, Litecoin) achieves consensus with a competition\n",
      "among miners on solving computational puzzles, which consume numerous computa-\n",
      "tional resources; and PoS (Proof-of-Stake, as adopted by e.g., Peercoin, Blackcoin)\n",
      "randomly assigns a block creator (transaction validator) with probability proportional\n",
      "to their coins staked.\n",
      "Hashing algorithm: It is a mathematical algorithm that encrypts a new transaction\n",
      "(or a new block) into a fixed length character string, known as hash value, and later\n",
      "interlinks this string with a given blockchain to ensure the security and immutability\n",
      "of a crypto. Various hashing algorithms are implemented in cryptos such as SHA-256,\n",
      "Scrypt and Equihash. These provide different degree of complexity to blockchain\n",
      "operations.\n",
      "Difficulty adjustment algorithm: It is an adaptive mechanism which periodically\n",
      "adjusts the difficulty toward hashrate to target an average time interval between blocks,\n",
      "known as target block time or target confirmation time. It regulates the creation rate of\n",
      "a block and maintains a certain amount of outputs of a blockchain. Such a mechanism\n",
      "is commonly seen in a PoW framework. An example from Bitcoin is shown in Figure5.2. DATA SOURCE AND DESCRIPTION 97\n",
      "5.2 where its difficulty adjustment algorithm, known as DAA, modifies the difficulty\n",
      "every 2016 blocks to meet target block time of 10 minutes.\n",
      "Figure 5.2: Bitcoin’s difficulty adjustment toward actual block time\n",
      " Blockchain_mecha-\n",
      "nism_plotting\n",
      "5.2.2 Data\n",
      "The data applied in this paper are collected from Bitinfocharts which is available at\n",
      "https://bitinfocharts.com/. These time series are composed of data points observed\n",
      "daily from the genesis date of each crypto. The lengths of these time series are thus\n",
      "varied coin by coin, but as explained in the section 5.3, we continue to use the whole\n",
      "time series for each coin.\n",
      "Price:Much previous literature has been triggered by the substantial fluctuations in\n",
      "crypto prices. In this study we investigate 18 crypto prices in USD on daily time series.\n",
      "Among these 18 cryptos, Bitcoin has been dominant and Reddcoin has the lowest price\n",
      "on balance as seen in Figure 5.3. We characterise these price time series in table 5.1.\n",
      "Most of these coins (i.e., Bitcoin, Ethereum, Bitcoin Cash) have high fluctuations in\n",
      "price; while some coins (i.e., XRP, Blackcoin) tends to be steady.\n",
      "Actual block time: It is the mean time required in minutes for each day to create\n",
      "the next block. In other words, it is the average amount of time for the day a user\n",
      "has to wait, after broadcasting their transaction, to see this transaction appear on the\n",
      "blockchain. Some literature also refers it as confirmation time. It can be considered\n",
      "as a service level indicator for cryptos which should be maintained by underlying\n",
      "mechanisms. Most of the coins discussed in this paper tend to have lower block\n",
      "time compared with Bitcoin as seen in Figure 5.4. Also, many coins show outliers in\n",
      "observations and this can indicate that the extreme events appear in the blockchain\n",
      "system. The underlying mechanisms can be ineffective to accommodate the current\n",
      "system demand. The distributional characteristics for time series of actual block time98 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "Figure 5.3: Time series of prices of the 18 cryptos\n",
      "Blockchain_mechanism_plotting\n",
      "are presented in table 5.2. The data for XRP are missing but its designed block time\n",
      "is around 5 second per transaction.\n",
      "Figure 5.4: Actual block time in minutes\n",
      " Blockchain_mechanism_plotting\n",
      "Actual block size: It is defined as the average actual size \"usage\" of a single block\n",
      "in data storage for one day. Since a block is is comprised of transaction data, it can5.3. METHODOLOGY 99\n",
      "represent the status of how a cryptocurrency mechanism allocates transactions to a\n",
      "block. In this study, as introduced in section 1, we consider it as an indicator for the\n",
      "stableness of scalability of a crypto. In Figure 5.5 shows that most of the cryptos under\n",
      "study have smaller block size usage than Bitcoin, except Bitcoin SV. The plot also\n",
      "depicts that almost all the coins have outliers. These outliers can lead to the imbalance\n",
      "in transaction fee and reward which can influence the ecosystem of a crypto. The\n",
      "characteristics for block size time series are shown in table 5.3. XRP does not have\n",
      "typical blockchain structure, hence, there is no block size data in the study. The data\n",
      "for Peercoin are missing.\n",
      "Figure 5.5: Actual block size in megabytes\n",
      " Blockchain_mechanism_plotting\n",
      "5.3 Methodology\n",
      "In order to investigate the relationship between underlying blockchain mechanism of\n",
      "cryptocurrenciesandthedistributionalcharacteristicsofcryptosasaproxyofbehaviour,\n",
      "we aim to group them into number of clusters and scrutinise the compositions of features\n",
      "in each group. These blockchain-based features manifest the underlying mechanism\n",
      "of how the cryptos operate transactions on their chains, and subsequently govern the\n",
      "price, actual block size and block time. As described in the previous section, we use\n",
      "the time series data of 18 different cryptos with a range of different mechanisms.100 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "The time series data available for the cryptos is subject to numerous limitations.\n",
      "The most important one of them is that different coins were introduced at different\n",
      "time points, therefore, the data available for each coin has different lengths. For the\n",
      "clustering problems (Aghabozorgi et al., 2015), defining the distance metric between\n",
      "points in time series with various lengths is not conventional. For many analytical\n",
      "problems, this issue is easily tackled by truncating the time series to the shared sample\n",
      "period. We refrain from doing so because, in the analysis of cryptocurrency prices, the\n",
      "evolution of the data in time is highly crucial for an investigation in the short term\n",
      "and long term dynamics and therefore, truncating the time series would lead to loss\n",
      "of important information. Hence, we deal with the time series data of cryptos with\n",
      "different lengths and do not directly impose a distance metric on the input data points.\n",
      "Furthermore, characterising the behaviour of a time series in terms of a single quanti-\n",
      "tative attribute (such as range based volatility) has its own limitations. The chosen\n",
      "attribute usually captures the dynamics of time series in one particular aspect, which\n",
      "may not be sufficient to encompass an entire behaviour or introduces a biased as-\n",
      "sessment. This becomes particularly true in the problems of crypto classification\n",
      "and clustering where these attributes, used as a similarity measure, are very diverse,\n",
      "resulting in weak robustness in the results.\n",
      "To cope with these limitations, we resort to the characteristic based clustering method\n",
      "proposed by Wang et al. (2005). It was recently applied by Pele et al. (2020) for\n",
      "classifying cryptos in order to distinguish them from traditional assets. This methods\n",
      "recommends to incorporate various global measures describing the structural charac-\n",
      "teristics of a time series for a clustering problem. These global measures are obtained\n",
      "by applying statistical operations that best represent the underlying characteristics.\n",
      "Also, by extracting a set of measures from the original time series we simply bypass\n",
      "the issue of defining a distance metric. It’s understood that the global measures are\n",
      "domain-specific. Employing a greedy search algorithm, Wang et al. (2005) selects the\n",
      "pivotal features in the clustering tasks. In our case, we import the experts’ discretion\n",
      "on the choice of features as distributional characteristics which best represent the\n",
      "dynamics of cryptocurrencies.\n",
      "We choose a variety of measures for our analysis. Starting from the first four moments\n",
      "and quantiles that characterises the distribution and symmetry of the data, we include\n",
      "the statistics for concluding the global structure such as global optimum, as well as the\n",
      "measures for long term dependencies, risk and noise. The selected features are mean,\n",
      "standard deviation, skewness, kurtosis, maximum, minimum, first quartile, median,\n",
      "third quartile, 1% and 5% extreme quantiles as a measure of downside risk, linear\n",
      "trend, intercept, autocorrelation for long term dependency, self-similarity using Hurst5.4. EMPIRICAL EVIDENCE 101\n",
      "exponent and chaos using Lyaponav’s exponents.\n",
      "We further extend the methodology by including the power spectrum of time series as\n",
      "an additional measure. The power spectrum is obtained in this work using Fast Fourier\n",
      "Transform (FFT). For computational ease, discrete fourier transform (DFT) has been\n",
      "formalised as a linear operator that maps the data points in a discrete input signal\n",
      "X{x1, x2,···, xn}to the frequency domain f={f1, f2,···fn}.\n",
      "For a given time series Xofntime points, sine and cosine functions are used to\n",
      "get the coefficients ωn=e−2πi/ηand the frequencies are calculated using the matrix\n",
      "multiplication:\n",
      "⎡\n",
      "⎢⎢⎢⎢⎢⎢⎢⎣f1\n",
      "f2\n",
      "f3\n",
      "...\n",
      "fn⎤\n",
      "⎥⎥⎥⎥⎥⎥⎥⎦=⎡\n",
      "⎢⎢⎢⎢⎢⎢⎢⎣1 1 1 ··· 1\n",
      "1ωn ω2\n",
      "n··· ωn−1\n",
      "n\n",
      "1ω2\n",
      "n ω4\n",
      "n···ω2(n−1)\n",
      "n\n",
      "...............\n",
      "1ωn−1\n",
      "n ω2(n−1)\n",
      "n ···ω(n−1)2\n",
      "n⎤\n",
      "⎥⎥⎥⎥⎥⎥⎥⎦⎡\n",
      "⎢⎢⎢⎢⎢⎢⎢⎣x1\n",
      "x2\n",
      "x3\n",
      "...\n",
      "xn⎤\n",
      "⎥⎥⎥⎥⎥⎥⎥⎦(5.1)\n",
      "This matrix multiplication involves O(n2)and makes DFT computationally expensive.\n",
      "FFT is a fast algorithm to compute DFT using only O(nlogn)operations (Brunton &\n",
      "Kutz, 2019). A simple fftcommand in python computes the FFT of the given time\n",
      "signal. The power spectrum of this signal is the normalised squared magnitude of\n",
      "thefand it indicates how much variance of the initial space each frequency explains\n",
      "(Brunton & Kutz, 2019). Including the power spectrum as a feature for characteristic\n",
      "based clustering allows capturing the variability in the time signal that is not explained\n",
      "by any other measure.\n",
      "Accumulating all the aforementioned features in a vector gives in a reduced dimensional\n",
      "representation of time series of each crypto. These vectors are then used to cluster\n",
      "the cryptos into groups using spectral clustering. Spectral clustering exploits the\n",
      "eigenvalues of similarity matrix to cluster and results in more balanced clusters than\n",
      "other techniques that were employed during the process. For details related to spectral\n",
      "clustering, the readers are recommended to follow the tutorial on spectral clustering by\n",
      "von Luxburg (2006). The results of the above methodology are discussed in detail in\n",
      "the next section.\n",
      "5.4 Empirical Evidence\n",
      "In this section, we showcase the result from the characteristic based clustering individ-\n",
      "ually on the crypto price and operational features–which are constructed with price,\n",
      "block size \"scalability\" and block time \"service level\" time series. We explore the102 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "clustering results and classify them with the underlying mechanisms of the investi-\n",
      "gated 18 cryptos. The 18 cryptos are: Bitcoin, Bitcoin Cash, Bitcoin Gold, Bitcoin\n",
      "SV, Blackcoin , Dash, Dogecoin, Ethereum, Ethereum Classic, Feathercoin, Litecoin,\n",
      "Monero, Novacoin, Peercoin, Reddcoin, Vertcoin, XRP, and Zcash.\n",
      "We calculate the characteristics for each of these cryptos for prices, block size and block\n",
      "time separately. The results of all other attributes except the FFT are summarised in\n",
      "tables 5.1, 5.2, 5.3 correspondingly in Appendix. Note that the data for XRP are not\n",
      "available for the block size and block time, and for Peercoin block size is missing as\n",
      "described before in section 3.\n",
      "After calculating the attributes and FFT power spectrum described in section 5.3, the\n",
      "feature space is 216 dimensional (200 dimensional vector of power spectrum and 16\n",
      "characteristics), visualisation of which is not possible. We project the feature space\n",
      "into a three dimensional space using principle component analysis (PCA), and the\n",
      "results of which are exhibited for an intuitive understanding. We discuss each of the\n",
      "clustering in detail below. Moreover, in order to avoid a monopoly outcome and sustain\n",
      "a certain level of interpretability, we impose the maximum number of the clusters to\n",
      "avoid a single coin case in each cluster.\n",
      "5.4.1 Clustering with Crypto Prices\n",
      "Table 5.1 shows that as expected, Bitcoin has the highest average price and highest\n",
      "standard deviation, due to high magnitude of its prices. The VaR99 and VaR95 for\n",
      "Bitcoin are, however, very low, showing a low downside risk of Bitcoin. On the contrary,\n",
      "Bitcoin Cash, Bitcoin SV, Bitcoin Gold and Zcash all show high value at risk. This\n",
      "could be due to low persistence of risk shocks (de Souza, 2019; Katsiampa et al., 2019).\n",
      "The high positive coefficients of self similarity for all the coins show high dependency\n",
      "on the previous time values. The high autocorrelation further confirms the presence of\n",
      "long term dependencies of the time series. The Lyaponov exponent as a measure of\n",
      "chaos is greater than 0 for all the time series which shows unstable dynamics throughout\n",
      "the prices of cryptos.\n",
      "The characteristics of Dogecoin in table 5.1 assume very low values, unlike any other\n",
      "coin, because the prices of Dogecoin are very low, despite it being a popular coin. This\n",
      "can be due to high supply of the coin with no limit on the total number of coins created.\n",
      "The coin also has no technical innovations, which is considered as one of the reasons\n",
      "why the coin has such small price. Hence, the uncontrolled underlying mechanism of\n",
      "the coin has significant impact on the prices, despite the high trading volumes of the\n",
      "coin. Same can be concluded for XRP and Reddcoin, which also have a very high\n",
      "maximum supply that is reflected in their very low prices.5.4. EMPIRICAL EVIDENCE 103\n",
      "Using characteristic based clustering on price time series, we have the result with 5\n",
      "clusters as below:\n",
      "0. Bitcoin, Dash\n",
      "1. Bitcoin SV, Zcash\n",
      "2. Bitcoin Cash, Bitcoin Gold\n",
      "3.Ethereum, Litecoin, XRP, Monero, Peercoin, Vertcoin, Reddcoin, Feathercoin,\n",
      "Blackcoin\n",
      "4. Ethereum Classic, Dogecoin, Novacoin\n",
      "Figure 5.6: Visualisation of five clusters 0, 1, 2, 3, 4 of cryptos based on the prices\n",
      "Blockchain_mechanism_clustering\n",
      "Most of coins are close to each others in a three-dimensional space, as seen in Figure\n",
      "5.6. Except Dash, all the altcoins are in a different clusters than Bitcoin. Bitcoin Cash\n",
      "and Bitcoin Gold, which principally inherit the protocol architecture from Bitcoin,\n",
      "are clustered together, but not centred around with other coins. However, Bitcoin\n",
      "SV–which is a fork from Bitcoin Cash and mainly increases the designed block size to104 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "lower the transaction fee as a main software change–is not in the same cluster. This\n",
      "indicates that even as a crypto adopts a similar blockchain mechanism with the other\n",
      "crypto, it might have different price dynamics than its origin.\n",
      "XRP, Monero, Peercoin, Reddcoin, and Blackcoin which apply significantly different\n",
      "blockchain protocols in their governance types and consensus mechanisms are in the\n",
      "same cluster. Specifically, XRP, Monero and Peercoin are private based blockchain\n",
      "which possesses a stronger moderator to control the entrants (users or investors) to\n",
      "their network. Peercoin, Reddcoin, and Blackcoin, instead of using PoW as their\n",
      "consensus mechanisms, employ PoS which does not depends on miners’ effort to create\n",
      "a block. So that, coin supply and demand can reach an equilibrium without the\n",
      "interference of miners, which leads to higher transaction costs. Moreover, the forks\n",
      "from Litecoin–Vertcoin, Reddcoin and Feathercoin are within the same cluster with\n",
      "Litecoin.\n",
      "Ethereum Classic is, in fact, the version of Ethereum that existed before the hard\n",
      "fork of Ethereum resulting after the DAO attack, but it is not within the cluster with\n",
      "Ethereum.\n",
      "5.4.2 Clustering with Actual Block Time\n",
      "The block time here is measured in minutes. Likewise, we apply the characteristic\n",
      "based clustering on the data and conclude them into 5 clusters as below.\n",
      "0. Dogecoin, Feathercoin\n",
      "1. Ethereum, Litecoin, Ethereum Classic, Dash, Zcash, Monero, Blackcoin\n",
      "2. Bitcoin, Bitcoin Cash, Vertcoin\n",
      "3. Bitcoin SV, Bitcoin Gold, Novacoin\n",
      "4. Peercoin, Reddcoin\n",
      "The result is correspondingly visualised in Figure 5.4. The Figure shows that Peercoin\n",
      "and Reddcoin lie far away from other coins (marked by cyan cluster). They are clustered\n",
      "in the same group because they both use PoS and their initial block takes the maximum\n",
      "time to be added, as shown by the maximum and intercept characteristics in table 5.2.\n",
      "This shows that even though the coins have lower actual block time later (with low\n",
      "mean), their behaviour is still the similar, resulting them in the same cluster. Also,\n",
      "the cryptos using PoS tend to lower the complexity of their hashing algorithms since\n",
      "it is not required for miners to spend computational effort on them. The difficulty\n",
      "adjustment algorithms of theirs are purely used as a mechanism for maintaining the5.4. EMPIRICAL EVIDENCE 105\n",
      "certain service level for users without considering hashrate from miners. Their block\n",
      "time performance is relatively stable after the initialisation. Here we emphasise that the\n",
      "initial price, block time and block size that are usually characterised by the underlying\n",
      "mechanism play a pivotal role in determining the price behaviour of cryptos. This is\n",
      "why we did not truncate the time series, as mentioned in the section 4.\n",
      "Figure 5.7: Visualisation of five clusters 0, 1, 2, 3, 4 of cryptos based on block time\n",
      "Blockchain_mechanism_clustering\n",
      "Though Bitcoin, Bitcoin Gold, Bitcoin Cash and Bitcoin SV are not completely grouped\n",
      "into the same cluster, they are close to each others in the three dimensional space as\n",
      "seen in Figure 5.4. They apply the same hashing algorithm–SHA-256 and also with\n",
      "the same expected block time for their difficulty adjustment algorithms. Let’s call\n",
      "attention to forks again. Dogecoin and Feathercoin are both forked from Litecoin with\n",
      "the Script-based hashing algorithm and difficulty adjustment frequency after large\n",
      "number of blocks–240 and 504 blocks. Litecoin is in a different cluster because the\n",
      "frequency is much higher as 2016 blocks. Given the cryptos forked from the same\n",
      "origin coins, their block time can be found in the same group, likewise Ethereum and\n",
      "Ethereum Classic.106 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "5.4.3 Clustering with Actual Block Size\n",
      "As previously done for price and block time, we use the characteristics based clustering\n",
      "and grouped these cryptos into 5 clusters according to the characteristics of their time\n",
      "series. The block size here is measured in bytes for a better data representation. As\n",
      "stated before in section 3, XRP and Peercoin data are missing due to the mechanism\n",
      "design and incomplete data from the source, respectively. The clustering result is\n",
      "shown as below and the corresponding visualisation is in Figure 5.5.\n",
      "0. Zcash, Bitcoin Gold, Reddcoin, Novacoin\n",
      "1. Ethereum, Ethereum Classic, Dogecoin\n",
      "2. Bitcoin Cash, Bitcoin SV\n",
      "3. Bitcoin, Dash, Monero, Feathercoin\n",
      "4. Litecoin, Vertcoin, Blackcoin\n",
      "Figure 5.8: Visualisation of five clusters 0, 1, 2, 3, 4 of cryptos based on block size\n",
      "Blockchain_mechanism_clustering\n",
      "The actual block size (usage) of these cryptos does rarely meet their designed block5.5. CONCLUSION 107\n",
      "size limit (capacity), except for Bitcoin that it nearly outstretches its limit, 1 megabyte,\n",
      "as seen in table 5.3. In this case, it raises an issue: Can increasing crypto’s block size\n",
      "limit improves scalability? For example, Bitcoin SV enlarges dramatically its limit\n",
      "to 128 megabytes but it is out of the necessity for such a design. Likewise, Bitcoin\n",
      "Cash, which Bitcoin SV forks from, has its limit as 32 megabytes. These two coins\n",
      "are, therefore, clustered together. Moreover, instead of having a static block size limit,\n",
      "Ethereum and Ethereum Classic grouped in the same cluster apply block gas limit,\n",
      "which is the energy consumption limit for a block, to adaptively regulate its block\n",
      "size. Both Monero and Blackcoin have a dynamic mechanisms to control the block size,\n",
      "however, it does not represent in the clustering result.\n",
      "5.5 Conclusion\n",
      "In this paper we investigate the relationship between crypto behaviours and their un-\n",
      "derlying mechanisms. We specify the crypto behaviour with their price and operational\n",
      "features defined by actual block time and block size. We calculate the distributional\n",
      "characteristics to define the behaviour of time series. Using a characteristics based\n",
      "spectral clustering technique, we cluster the selected coins into a number of clusters\n",
      "and scrutinise the blockchain mechanism in each group. We find that the underlying\n",
      "mechanism of cryptos are reflected in the clustering results. We observe that cryptos\n",
      "forked from same origin and same consensus mechanism tend to become part of same\n",
      "clustering group. Furthermore, the clusters obtained by the time series of block time\n",
      "have same hashing algorithms and difficulty adjustment algorithms. Also, a similar\n",
      "nature (static or dynamic) of block size was observed within clusters obtained by the\n",
      "time series of actual block size. We conclude with empirical evidence that the crypto\n",
      "behaviour is indeed linked with their blockchain protocol architectures. As a result,\n",
      "cryptocurrency users and investors can have a better understanding and explanation\n",
      "of price and operational features through cryptocurrency mechanism. In the future\n",
      "research, we would elaborate the relation of price and operational features to underlying\n",
      "mechanism with an economic model and conduct relevant simulations. We would also\n",
      "like to investigate the impact of versions revisions on the dynamics of cryptos.108 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "5.6 Appendix\n",
      "Characteristic Bitcoin Ethereum LitecoinBitcoin\n",
      "CashEthereum\n",
      "ClassicXRP\n",
      "mean 2659.127 178.966 34.394 537.723 9.381 0.192\n",
      "standard_deviation 3798.466 222.452 48.645 509.244 7.827 0.302\n",
      "skewness 1.338 1.950 2.389 2.322 1.491 4.193\n",
      "kurtosis 0.672 4.654 7.272 6.157 2.239 29.471\n",
      "maximum 19401.000 1356.000 352.799 3526.000 43.765 3.649\n",
      "minimum 0.050 0.401 0.032 58.626 0.687 0.003\n",
      "lowerquant 20.193 7.975 3.153 233.404 4.364 0.007\n",
      "median 455.892 136.557 8.618 324.646 6.571 0.024\n",
      "upperquant 5128.000 250.965 53.128 620.947 13.813 0.291\n",
      "VaR99 0.062 0.578 0.040 107.426 0.809 0.004\n",
      "VaR95 0.393 0.696 0.072 129.491 1.105 0.005\n",
      "slope 2.781 0.163 0.032 -0.876 -0.002 0.000\n",
      "intercept 0.050 2.820 0.033 63.765 0.892 0.006\n",
      "autocorrelation 0.998 0.998 0.997 0.992 0.994 0.991\n",
      "self_similarity 1.574 1.611 1.596 1.609 1.564 1.551\n",
      "chaos 0.088 0.093 0.091 0.086 0.087 0.085\n",
      "CharacteristicBitcoin\n",
      "SVDash Zcash Monero DogecoinBitcoin\n",
      "Gold\n",
      "mean 145.401 113.910 135.596 57.588 0.006 43.167\n",
      "standard_deviation 66.784 187.915 125.654 75.569 0.193 70.420\n",
      "skewness 0.678 3.126 1.756 2.145 49.692 2.879\n",
      "kurtosis 0.079 11.777 3.208 5.300 2469.511 8.351\n",
      "maximum 370.647 1436.000 728.159 439.391 9.608 513.293\n",
      "minimum 52.683 0.516 23.940 0.233 0.000 5.093\n",
      "lowerquant 87.323 3.950 50.251 1.100 0.000 9.710\n",
      "median 135.217 66.508 72.251 44.090 0.001 15.869\n",
      "upperquant 191.739 133.239 199.807 84.834 0.003 29.706\n",
      "VaR99 53.377 0.711 27.767 0.272 0.000 5.357\n",
      "VaR95 62.111 1.833 31.842 0.417 0.000 6.604\n",
      "slope 0.218 0.083 -0.134 0.053 0.000 -0.147\n",
      "intercept 111.700 1.380 286.297 1.911 0.000 513.293\n",
      "autocorrelation 0.990 0.997 0.995 0.997 0.002 0.961\n",
      "self_similarity 1.628 1.642 1.573 1.577 1.024 1.431\n",
      "chaos 0.077 0.090 0.092 0.091 0.086 0.073\n",
      "CharacteristicPeer\n",
      "coinVertcoinRedd-\n",
      "coinFeather-\n",
      "coinBlack-\n",
      "coinNova-\n",
      "coin\n",
      "mean 1.004 0.670 0.001 0.062 0.095 2.185\n",
      "standard_deviation 1.238 1.319 0.003 0.102 0.127 2.989\n",
      "skewness 2.511 3.637 4.175 3.379 3.397 3.102\n",
      "kurtosis 7.017 14.792 24.526 17.172 15.251 12.916\n",
      "maximum 9.118 9.386 0.029 1.203 1.108 24.777\n",
      "minimum 0.110 0.006 0.000 0.002 0.014 0.078\n",
      "lowerquant 0.291 0.043 0.000 0.008 0.030 0.507\n",
      "median 0.445 0.237 0.001 0.019 0.045 0.901\n",
      "upperquant 1.275 0.626 0.001 0.072 0.088 3.301\n",
      "VaR99 0.125 0.009 0.000 0.003 0.015 0.156\n",
      "VaR95 0.168 0.015 0.000 0.004 0.020 0.187\n",
      "slope 0.000 0.000 0.000 0.000 0.000 -0.001\n",
      "intercept 0.382 6.315 0.000 0.559 0.035 0.078\n",
      "autocorrelation 0.993 0.992 0.988 0.983 0.993 0.994\n",
      "self_similarity 1.577 1.603 1.548 1.523 1.537 1.596\n",
      "chaos 0.088 0.085 0.079 0.078 0.084 0.091\n",
      "Table 5.1: Characteristics of prices of different cryptocurrencies5.6. APPENDIX 109\n",
      "Characteristic Bitcoin Ethereum LitecoinBitcoin\n",
      "CashEthereum\n",
      "ClassicXRP\n",
      "mean 10.453 0.257 2.507 11.167 0.246 NA\n",
      "standard_deviation 8.814 0.045 0.385 11.009 0.032 NA\n",
      "skewness 21.779 3.098 5.003 11.597 5.144 NA\n",
      "kurtosis 701.717 11.987 54.589 160.209 61.066 NA\n",
      "maximum 360.000 0.509 8.521 205.714 0.800 NA\n",
      "minimum 2.081 0.208 0.149 1.275 0.153 NA\n",
      "lowerquant 8.623 0.235 2.357 9.664 0.235 NA\n",
      "median 9.474 0.241 2.474 9.931 0.238 NA\n",
      "upperquant 10.435 0.268 2.599 10.360 0.242 NA\n",
      "VaR99 5.923 0.220 1.710 2.331 0.215 NA\n",
      "VaR95 7.129 0.222 2.111 8.479 0.218 NA\n",
      "slope -0.001 0.000 0.000 -0.007 0.000 NA\n",
      "intercept 102.857 0.208 0.149 160.000 0.208 NA\n",
      "autocorrelation 0.494 0.981 0.705 0.395 0.818 NA\n",
      "self_similarity 1.027 1.522 0.787 0.704 1.249 NA\n",
      "chaos 0.012 0.070 0.012 0.003 0.068 NA\n",
      "CharacteristicBitcoin\n",
      "SVDash Zcash Monero DogecoinBitcoin\n",
      "Gold\n",
      "mean 10.195 2.659 2.409 1.686 1.048 9.823\n",
      "standard_deviation 1.639 0.805 0.345 0.541 0.043 0.741\n",
      "skewness 12.504 19.831 -3.025 3.258 -9.220 -5.375\n",
      "kurtosis 221.950 409.827 7.261 57.807 222.460 60.686\n",
      "maximum 40.000 22.500 2.618 10.992 1.288 11.250\n",
      "minimum 7.310 0.348 1.240 0.829 0.100 0.254\n",
      "lowerquant 9.600 2.609 2.487 1.025 1.038 9.664\n",
      "median 10.000 2.623 2.509 1.951 1.044 9.931\n",
      "upperquant 10.511 2.637 2.531 2.020 1.050 10.141\n",
      "VaR99 8.361 2.476 1.248 0.947 0.980 7.767\n",
      "VaR95 9.034 2.571 1.258 0.984 1.031 8.623\n",
      "slope -0.001 0.000 0.000 0.001 0.000 0.001\n",
      "intercept 40.000 0.348 2.286 1.627 0.100 0.254\n",
      "autocorrelation -0.115 0.707 0.982 0.805 0.787 0.378\n",
      "self_similarity 0.367 0.811 1.121 0.922 1.044 0.494\n",
      "chaos 0.023 0.003 0.010 0.001 0.011 -0.001\n",
      "CharacteristicPeer-\n",
      "coinVert-\n",
      "coinRedd-\n",
      "coinFeather-\n",
      "coinBlack-\n",
      "coinNova-\n",
      "coin\n",
      "mean 10.085 2.502 4.646 2.005 1.090 6.819\n",
      "standard_deviation 47.070 0.180 68.175 6.443 0.105 2.295\n",
      "skewness 30.324 -1.782 20.761 11.521 -4.368 24.326\n",
      "kurtosis 919.356 30.015 434.280 157.793 18.525 891.281\n",
      "maximum 1440.000 4.079 1440.000 130.909 1.335 96.000\n",
      "minimum 1.377 0.151 0.646 0.148 0.442 0.451\n",
      "lowerquant 7.742 2.412 0.986 1.042 1.111 6.154\n",
      "median 8.372 2.500 1.007 1.048 1.114 6.606\n",
      "upperquant 9.057 2.590 1.028 1.171 1.117 7.164\n",
      "VaR99 5.464 2.144 0.935 1.034 0.551 4.364\n",
      "VaR95 6.545 2.289 0.957 1.036 0.949 5.390\n",
      "slope -0.003 0.000 -0.010 -0.002 0.000 -0.001\n",
      "intercept 1440.000 0.151 1440.000 0.291 1.309 1.765\n",
      "autocorrelation 0.667 0.154 0.821 0.914 0.976 0.373\n",
      "self_similarity 0.717 0.437 1.051 1.210 1.337 0.697\n",
      "chaos 0.002 0.008 -0.001 0.032 0.006 0.009\n",
      "Table 5.2: Characteristics of Block time of different cryptocurrencies110 CHAPTER 5. BLOCKCHAIN MECHANISM\n",
      "Characteristic Bitcoin Ethereum LitecoinBitcoin\n",
      "CashEthereum\n",
      "ClassicXRP\n",
      "mean 407162.152 14376.916 12909.684 138173.724 1297.638 NA\n",
      "standard_deviation 363245.372 11337.562 15590.195 284058.956 340.581 NA\n",
      "skewness 0.241 0.285 4.309 9.176 0.679 NA\n",
      "kurtosis -1.583 -0.819 31.780 109.791 2.106 NA\n",
      "maximum 998092.000 58953.000 206020.000 4710539.000 3594.000 NA\n",
      "minimum 134.000 575.164 134.000 4982.000 575.164 NA\n",
      "lowerquant 21246.000 1627.750 4004.750 60455.500 1054.750 NA\n",
      "median 310990.000 17024.000 7016.000 94775.000 1310.500 NA\n",
      "upperquant 777369.500 23068.750 19366.500 122827.500 1492.250 NA\n",
      "VaR99 134.548 658.423 561.630 15574.520 653.404 NA\n",
      "VaR95 134.952 788.678 800.306 27169.700 775.052 NA\n",
      "slope 266.541 17.464 8.806 -89.253 0.189 NA\n",
      "intercept 204.000 643.886 199.000 385996.000 643.886 NA\n",
      "autocorrelation 0.985 0.981 0.872 0.626 0.850 NA\n",
      "self_similarity 1.067 1.310 1.148 1.074 1.131 NA\n",
      "chaos 0.058 0.058 0.065 0.027 0.045 NA\n",
      "CharacteristicBitcoin\n",
      "SVDash Zcash Monero DogecoinBitcoin\n",
      "Gold\n",
      "mean 1100149.254 12999.389 23802.102 39874.397 10523.242 25312.953\n",
      "standard_deviation 1278250.457 26340.294 38911.209 47310.430 6607.125 67527.275\n",
      "skewness 6.673 27.654 8.711 1.703 5.917 6.269\n",
      "kurtosis 84.455 1040.743 117.847 4.063 68.981 45.828\n",
      "maximum 20460199.000 1059232.000 687685.000 347816.000 116605.000 739259.000\n",
      "minimum 5005.000 226.545 379.573 375.434 143.000 133.000\n",
      "lowerquant 257789.500 3038.000 7189.500 3047.250 6775.000 6512.500\n",
      "median 996071.500 9240.000 11670.000 20980.000 9510.000 9316.000\n",
      "upperquant 1573243.000 19193.000 28242.000 62002.000 12022.000 14118.000\n",
      "VaR99 6435.000 1312.960 2605.530 1058.990 3432.400 2727.870\n",
      "VaR95 14660.750 1736.200 3103.900 1320.350 4491.000 3983.600\n",
      "slope 2318.003 14.357 -25.267 26.939 1.018 -67.625\n",
      "intercept 10871172.000 226.545 379.573 375.434 143.000 133.000\n",
      "autocorrelation 0.377 0.298 0.836 0.958 0.798 0.618\n",
      "self_similarity 1.004 0.947 1.138 1.214 1.070 1.015\n",
      "chaos 0.009 0.018 0.030 0.041 0.021 -0.012\n",
      "CharacteristicPeer-\n",
      "coinVert-\n",
      "coinRedd-\n",
      "coinFeather-\n",
      "coinBlack-\n",
      "coinNova-\n",
      "coin\n",
      "mean NA 2641.881 772.025 806.556 687.622 539.712\n",
      "standard_deviation NA 3611.409 634.442 1621.154 3441.373 1223.175\n",
      "skewness NA 3.420 3.613 10.605 28.388 38.218\n",
      "kurtosis NA 16.189 21.857 158.924 894.526 1712.453\n",
      "maximum NA 36709.000 7808.000 36789.000 120169.000 57527.000\n",
      "minimum NA 105.000 105.000 109.625 252.514 110.835\n",
      "lowerquant NA 682.104 388.361 359.746 286.296 360.352\n",
      "median NA 1149.000 526.043 460.827 386.251 436.181\n",
      "upperquant NA 3185.000 937.696 598.841 627.727 542.228\n",
      "VaR99 NA 248.950 317.797 126.333 255.520 262.588\n",
      "VaR95 NA 310.697 337.320 247.907 261.297 284.524\n",
      "slope NA -0.586 -0.475 -0.739 -0.025 -0.204\n",
      "intercept NA 130.000 175.000 109.625 464.500 141.000\n",
      "autocorrelation NA 0.894 0.609 0.705 0.360 0.069\n",
      "self_similarity NA 1.129 1.007 1.063 0.959 0.951\n",
      "chaos NA 0.100 0.034 0.034 0.039 0.011\n",
      "Table 5.3: Characteristics of Block size of different cryptocurrenciesBibliography 111\n",
      "Bibliography\n",
      "Aghabozorgi, S., Shirkhorshidi, A. S., & Wah, T. Y. (2015). Time-series clustering–a\n",
      "decade review. Information Systems ,53, 16–38.\n",
      "Blau, B., Griffith, T., & Whitby, R. (2020). Comovement in the Cryptocurrency Market.\n",
      "Economics Bulletin ,40(1), 448–455.\n",
      "Brunton, S. L., & Kutz, J. N. (2019). Data-driven science and engineering: Machine\n",
      "learning, dynamical systems, and control . Cambridge University Press. https:\n",
      "//doi.org/10.1017/9781108380690\n",
      "Buterin, V. (2014). A next-generation smart contract and decentralized application\n",
      "platform. white paper .\n",
      "Ciaian, P., Rajcaniova, M., & d’Artis Kancs. (2016). The economics of bitcoin price\n",
      "formation. Applied Economics ,48(19), 1799–1815. https://doi.org/10.1080/\n",
      "00036846.2015.1109038\n",
      "de Souza, M. (2019). Var and persistence of risk shocks in cryptocurrencies market.\n",
      "The Empirical Economics Letters ,18, 1–12.\n",
      "Garriga, M., Dalla Palma, S., Arias, M., Derenzis, A., Pareschi, R., & Tamburri, D.\n",
      "(2020). Blockchain and cryptocurrencies: A classification and comparison of\n",
      "architecture drivers. Concurrency and Computation Practice and Experience .\n",
      "https://doi.org/10.1002/cpe.5992\n",
      "Guo, L., Tao, Y., & Härdle, W. (2018). Understanding latent group structure of\n",
      "cryptocurrencies market: A dynamic network perspective. SSRN Electronic\n",
      "Journal. https://doi.org/10.2139/ssrn.3658206\n",
      "Guo, X., & Donev, P. (2020). Bibliometrics and network analysis of cryptocurrency\n",
      "research. Journal of Systems Science and Complexity , 1–26.\n",
      "Härdle, W. K., Harvey, C. R., & Reule, R. C. G. (2020). Understanding Cryptocurren-\n",
      "cies*.Journal of Financial Econometrics ,18(2), 181–208. https://doi.org/10.\n",
      "1093/jjfinec/nbz033\n",
      "Hou, A. J., Wang, W., Chen, C. Y. H., & Härdle, W. K. (2020). Pricing Cryptocurrency\n",
      "Options*. Journal of Financial Econometrics ,18(2), 250–279. https://doi.org/\n",
      "10.1093/jjfinec/nbaa006\n",
      "Iwamura, M., Kitamura, Y., Matsumoto, T., & Saito, K. (2019). Can we stabilize the\n",
      "price of a cryptocurrency?: Understanding the design of bitcoin and its potential\n",
      "to compete with central bank money. Hitotsubashi Journal of Economics ,60(1),\n",
      "41–60.\n",
      "Katsiampa,P.,Corbet,S.,&Lucey,B.(2019).Highfrequencyvolatilityco-movementsin\n",
      "cryptocurrencymarkets. Journal of International Financial Markets, Institutions\n",
      "and Money ,62, 35–52. https://doi.org/https://doi.org/10.1016/j.intfin.2019.05.\n",
      "003112 Bibliography\n",
      "King, S., & Nadal, S. (2012). Ppcoin: Peer-to-peer crypto-currency with proof-of-stake.\n",
      "self-published paper, August ,19, 1.\n",
      "Pele, D. T., Wesselhöfft, N., Härdle, W. K., Kolossiatis, M., & Yatracos, Y. (2020). A\n",
      "statistical classification of cryptocurrencies. Available at SSRN 3548462 .\n",
      "Sovbetov, Y. (2018). Factors influencing cryptocurrency prices: Evidence from bitcoin,\n",
      "ethereum, dash, litcoin, and monero. Journal of Economics and Financial\n",
      "Analysis,2(2), 1–27.\n",
      "Trimborn, S., & Härdle, W. K. (2018). Crix an index for cryptocurrencies. Journal of\n",
      "Empirical Finance ,49, 107–122. https://doi.org/https://doi.org/10.1016/j.\n",
      "jempfin.2018.08.004\n",
      "von Luxburg, U. (2006). A tutorial on spectral clustering (tech. rep. No. 149). Max\n",
      "Planck Institute for Biological Cybernetics, Tübingen.\n",
      "Wang, X., Smith-Miles, K., & Hyndman, R. (2005). Characteristic-based clustering for\n",
      "time series data. Data Mining and Knowledge Discovery ,13, 335–364.\n",
      "Zimmerman, P. (2020). Blockchain structure and cryptocurrency prices. Bank of\n",
      "England Working Paper .Declaration\n",
      "I hereby declare that I completed this work without any improper help from a third\n",
      "party and without using any aids other than those cited. All ideas derived directly\n",
      "or indirectly from other sources are identified as such. Chapter 2 a joint work with\n",
      "Chen Huang, and Wolfgang Karl Härdle. Chapter 3 is a joint work with Danial Saef,\n",
      "Sergej Sizov, and Wolfgang Karl Härdle. Chapter 4 is in collaboration with Mykhaylo\n",
      "Shcherbatyy and Wolfgang Karl Härdle. Finally, Chapter 5 is joint work with Min-bin\n",
      "Lin, Cathy Chen and Wolfgang Karl Härdle.\n",
      "I testify through my signature that all information that I have provided about resources\n",
      "used in the writing of my doctoral thesis, about the resources and support provided to\n",
      "me as well as in earlier assessments of my doctoral thesis correspond in every aspect to\n",
      "the truth.\n",
      "Berlin, den 29.07.22 Kainat Khowaja\n",
      "113Declaration on Contribution\n",
      "Cumulative dissertation – declaration on co-authors, own contribution, and\n",
      "publication status\n",
      "No Paper titleNames of\n",
      "co-authorsDeclaration\n",
      "of\n",
      "own\n",
      "contributionPublication\n",
      "status (when/where)\n",
      "1Uniform Confidence\n",
      "Bands for\n",
      "Generalized Random\n",
      "ForestsChen Huang,\n",
      "and\n",
      "Wolfgang Härdle2/3 To be submitted\n",
      "2Data Analytics\n",
      "Driven Controlling:\n",
      "bridging statistical modeling\n",
      "and managerial intuitionDanial Saef,\n",
      "Sergej Sizov,\n",
      "and\n",
      "Wolfgang Härdle1/2Submitted:\n",
      "Management Science\n",
      "(November 2021)\n",
      "3Surrogate Models\n",
      "for Optimization\n",
      "of Dynamical SystemsMykhaylo\n",
      "Shcherbatyy\n",
      "and\n",
      "Wolfgang Härdle4/5Accepted:\n",
      "Foundations of\n",
      "Modern Statistics:\n",
      "Springer Proceedings\n",
      "in Mathematics and\n",
      "Statistics\n",
      "(July 2021)\n",
      "4Blockchain Mechanism\n",
      "and Distributional\n",
      "Characteristics\n",
      "of CryptosMin-bin Lin,\n",
      "Cathy Chen\n",
      "and\n",
      "Wolfgang Härdle1/2Published:\n",
      "Advances in Quantitative\n",
      "Analysis of Finance\n",
      "& Accounting (AQAFA),\n",
      "Vol. 18,\n",
      "DOI: 10.6293/\n",
      "AQAFA.202112_(18).0006\n",
      "(December 2021)\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 as pdf\n",
    "reader = pdf.PdfFileReader('20220820 K2 K Khowaja DISS.pdf',strict=False)\n",
    "fulltext = ''\n",
    "for page_num in range(reader.getNumPages()):\n",
    "    page = reader.getPage(page_num)\n",
    "    text = page.extractText()\n",
    "    fulltext += str(text)\n",
    "\n",
    "print(fulltext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x75c6fd for key /Lang\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2 as pdf\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def create_string(file_path):\n",
    "    '''Transform a PDF file to a list of string pages'''\n",
    "\n",
    "    # convert PDF to readable file\n",
    "    transformed_pdf = pdf.PdfFileReader(file_path, strict=False)\n",
    "    \n",
    "    # get number of pages\n",
    "    totalpages = transformed_pdf.numPages\n",
    "    \n",
    "    # read the data and store in a list\n",
    "    pdf_output = [transformed_pdf.getPage(i) for i in range(totalpages)]\n",
    "\n",
    "    # extract result\n",
    "    pdf_output = [pdf_output[i].extractText() for i in range(totalpages)]\n",
    "    \n",
    "    return pdf_output, totalpages \n",
    "\n",
    "def cleaning(file_path):\n",
    "\n",
    "    '''Initial PDF cleaning procedure'''\n",
    "    \n",
    "    pdf_output, totalpages = create_string(file_path)\n",
    "    # # cleaning urls\n",
    "    pdf_output = [re.sub(pattern = \"http[^ ]*\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    # # cleaning symbols\n",
    "    pdf_output = [re.sub(pattern = \"\\\\n\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \"\\W|\\d\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \"[^a-zA-Z]\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # cleaning multispaces\n",
    "    pdf_output = [re.sub(pattern = \"\\s{2,}\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # cleaning out 1-2-worders\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # lower-casing\n",
    "    pdf_output = [pdf_output[i].lower() for i in range(totalpages)]\n",
    "    pdf_output = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in pdf_output]\n",
    "    pdf_output = [' '.join(pdf_output[i]) for i in range(len(pdf_output))]\n",
    "    \n",
    "    return pdf_output\n",
    "\n",
    "def extract_cleantext_from_folder(folder_path):\n",
    "    '''Extract cleaned pdf text from folder'''\n",
    "    cleantext = ''\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.lower().endswith('.pdf'):\n",
    "            cleantext += str(cleaning(file_path))\n",
    "            \n",
    "    return cleantext\n",
    "\n",
    "pdf_folder_path = 'test'\n",
    "#extract_text_from_pdf('20170120 SN Sergey Nasekin DISS.pdf')\n",
    "\n",
    "\n",
    "extracted_text = extract_cleantext_from_folder(pdf_folder_path)\n",
    "\n",
    "text_file = open(\"cleantext.txt\", \"w\")\n",
    "text_file.write(extracted_text)\n",
    " \n",
    "#close file\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEDA-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
